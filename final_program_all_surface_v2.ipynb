{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1001361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gv/mb3m1prj1p9_15n7kqzsv6zc0000gn/T/ipykernel_20116/59993403.py:4: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_origin = pd.read_csv('wimbeldon_dataset_all_surfaces_v2.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>OddsProbDiff</th>\n",
       "      <th>WinRateA_x_Rank</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Gold Flake Open</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Agenor R.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Norman M.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.030108</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Gold Flake Open</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Golmard J.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Gold Flake Open</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Jonsson F.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Gold Flake Open</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Pioline C.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATP  Location                          Tournament        Date  \\\n",
       "0    2   Chennai                     Gold Flake Open  2000-01-03   \n",
       "1    1  Adelaide  Australian Hardcourt Championships  2000-01-03   \n",
       "2    2   Chennai                     Gold Flake Open  2000-01-03   \n",
       "3    2   Chennai                     Gold Flake Open  2000-01-03   \n",
       "4    2   Chennai                     Gold Flake Open  2000-01-03   \n",
       "\n",
       "          Series  Court  Surface      Round  Best of      Winner  ...  \\\n",
       "0  International      1        3  1st Round      3.0   Agenor R.  ...   \n",
       "1  International      1        3  1st Round      3.0   Norman M.  ...   \n",
       "2  International      1        3  1st Round      3.0  Golmard J.  ...   \n",
       "3  International      1        3  1st Round      3.0  Jonsson F.  ...   \n",
       "4  International      1        3  1st Round      3.0  Pioline C.  ...   \n",
       "\n",
       "  OddsProbDiff  WinRateA_x_Rank WinRateB_x_Rank  EfficiencyDiff  EloA_Global  \\\n",
       "0          0.0         0.005319        0.000500        0.004819       1500.0   \n",
       "1          0.0         0.003226        0.033333       -0.030108       1500.0   \n",
       "2          0.0         0.026316        0.002500        0.023816       1500.0   \n",
       "3          0.0         0.003937        0.004854       -0.000917       1500.0   \n",
       "4          0.0         0.035714        0.001208        0.034507       1500.0   \n",
       "\n",
       "   EloB_Global  EloA_Surface  EloB_Surface  EloDiff_Global  EloDiff_Surface  \n",
       "0       1500.0        1500.0        1500.0             0.0              0.0  \n",
       "1       1500.0        1500.0        1500.0             0.0              0.0  \n",
       "2       1500.0        1500.0        1500.0             0.0              0.0  \n",
       "3       1500.0        1500.0        1500.0             0.0              0.0  \n",
       "4       1500.0        1500.0        1500.0             0.0              0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_origin = pd.read_csv('wimbeldon_dataset_all_surfaces_v2.csv')\n",
    "df_origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "547ab399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mida del df:  69079\n"
     ]
    }
   ],
   "source": [
    "# Ens tenim que quedar amb només les dades de tots aquests partits que la seva data és anterior al 2025-06-29\n",
    "df = df_origin.copy()\n",
    "#df = df_origin[df_origin['Date'] < '2025-06-29'].copy()\n",
    "df.head()\n",
    "print(\"Mida del df: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6daa8a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ACCURACY FINAL TEST CRONOLÓGIC: 0.6729\n",
      "Brier Score: 0.2053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6618    0.6976    0.6793      6859\n",
      "           1     0.6851    0.6486    0.6663      6957\n",
      "\n",
      "    accuracy                         0.6729     13816\n",
      "   macro avg     0.6735    0.6731    0.6728     13816\n",
      "weighted avg     0.6735    0.6729    0.6727     13816\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "\n",
    "features = [\n",
    "    'LogRankDiff',      # ranking\n",
    "    'DiffWR',           # diferencia de winrate históric en herva\n",
    "    'DiffForm',         # últims 10\n",
    "    'H2HDiff',          # head-to-head\n",
    "    'OddsProbDiff',     # diferencia de probabilitat implícita de quotas\n",
    "    'DiffRest',         # dies de rest\n",
    "    'EfficiencyDiff',   # winrate / rank → jugador que rendeix per sobre del seu ranking\n",
    "    'RankDiff',         # diferencia de ranking\n",
    "    'EloDiff_Global',   # diferencia de elo global\n",
    "    'EloDiff_Surface'   # diferencia de elo en superfície\n",
    "]\n",
    "\n",
    "df = df.sort_values(\"Date\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df[features], df['WinnerBinary'], test_size=0.2, random_state=42)\n",
    "X = df[features]\n",
    "y = df[\"WinnerBinary\"]\n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "base_model = XGBClassifier(\n",
    "    n_estimators=500,                    # Nombre total d'arbres (boosting rounds) que es construiran. 500 és un valor força alt, bo per a un bon rendiment si es controla l'overfitting.\n",
    "    max_depth=6,                         # Profunditat màxima de cada arbre. 6 és un valor moderat: permet interaccions complexes sense fer els arbres excessivament profunds.\n",
    "    learning_rate=0.02,                  # Taxa d'aprenentatge (eta). 0.02 és bastant baixa → aprenentatge lent i estable, ideal quan tens molts estimators (500).\n",
    "    subsample=0.85,                      # Percentatge de mostres (files) que s'utilitzen per entrenar cada arbre. 0.85 = 85% → ajuda a reduir overfitting i afegeix variància (com bagging).\n",
    "    colsample_bytree=0.85,               # Percentatge de columnes (variables) que s'agafen aleatòriament per cada arbre. 85% → també redueix overfitting i millora la generalització.\n",
    "    min_child_weight=5,                  # Suma mínima del pes Hessiana en un node fill. Valors >1 fan el model més conservador: evita dividir nodes amb poca informació.\n",
    "    gamma=0.1,                           # Minimització mínima de la funció de pèrdua necessària per fer una partició addicional (regularització per poda). 0.1 afavoreix arbres més simples.\n",
    "    reg_alpha=0.1,                       # Terme de regularització L1 sobre els pesos de les fulles. Ajuda a fer sparseness i és útil quan hi ha moltes variables irrellevants.\n",
    "    reg_lambda=1.0,                      # Terme de regularització L2 (més suau que L1). 1.0 és el valor per defecte i sol funcionar bé en la majoria de casos.\n",
    "    random_state=42,                     # Llavor per a la reproductibilitat dels resultats (aleatorietat controlada).\n",
    "    n_jobs=-1,                           # Utilitza tots els nuclis disponibles del processador per entrenar en paral·lel → molt més ràpid.\n",
    "    eval_metric='logloss'                # Mètrica d'avaluació durant l'entrenament (per classificació binària/multiclasse). 'logloss' = logarithmic loss (cross-entropy).\n",
    ")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "model = CalibratedClassifierCV(base_model, method='isotonic', cv=5)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "pred = model.predict(X_test_sc)\n",
    "prob_model_con_tscv = model.predict_proba(X_test_sc)[:, 1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "brier = brier_score_loss(y_test, prob_model_con_tscv)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ACCURACY FINAL TEST CRONOLÓGIC: {acc:.4f}\")\n",
    "print(f\"Brier Score: {brier:.4f}\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "283bc940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "xgb_model = model.calibrated_classifiers_[0].estimator\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_train_sc)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89275cad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a144df43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "      <th>SurfaceText</th>\n",
       "      <th>RoundOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Escude N.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>-0.011737</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisnard J.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Petrovic D.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sekulov J.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Australian Hardcourt Championships</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gambill J.M.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1499.25</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>1498.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATP  Location                          Tournament        Date  \\\n",
       "0    1  Adelaide  Australian Hardcourt Championships  2000-01-03   \n",
       "1    1  Adelaide  Australian Hardcourt Championships  2000-01-03   \n",
       "2    1  Adelaide  Australian Hardcourt Championships  2000-01-03   \n",
       "3    1  Adelaide  Australian Hardcourt Championships  2000-01-03   \n",
       "4    1  Adelaide  Australian Hardcourt Championships  2000-01-03   \n",
       "\n",
       "          Series  Court  Surface      Round  Best of        Winner  ...  \\\n",
       "0  International      1        3  1st Round      3.0     Escude N.  ...   \n",
       "1  International      1        3  1st Round      3.0    Lisnard J.  ...   \n",
       "2  International      1        3  1st Round      3.0   Petrovic D.  ...   \n",
       "3  International      1        3  1st Round      3.0    Sekulov J.  ...   \n",
       "4  International      1        3  1st Round      3.0  Gambill J.M.  ...   \n",
       "\n",
       "  WinRateB_x_Rank  EfficiencyDiff EloA_Global  EloB_Global  EloA_Surface  \\\n",
       "0        0.012500       -0.011737     1499.25      1499.25        1498.5   \n",
       "1        0.001425       -0.001425     1499.25      1499.25        1498.5   \n",
       "2        0.002404        0.001695     1499.25      1499.25        1498.5   \n",
       "3        0.003521        0.002808     1499.25      1499.25        1498.5   \n",
       "4        0.000000        0.004762     1499.25      1499.25        1498.5   \n",
       "\n",
       "   EloB_Surface  EloDiff_Global  EloDiff_Surface  SurfaceText  RoundOrder  \n",
       "0        1498.5             0.0              0.0       Carpet         1.0  \n",
       "1        1498.5             0.0              0.0       Carpet         1.0  \n",
       "2        1498.5             0.0              0.0       Carpet         1.0  \n",
       "3        1498.5             0.0              0.0       Carpet         1.0  \n",
       "4        1498.5             0.0              0.0       Carpet         1.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# ============================\n",
    "# 1. MAPEO SUPERFICIES SI ESTÁN NUMERIZADAS\n",
    "# ============================\n",
    "\n",
    "# Si Surface es numérica (LabelEncoder), necesitamos mapearlo a strings\n",
    "surface_map = {\n",
    "    0: \"Hard\",\n",
    "    1: \"Clay\",\n",
    "    2: \"Grass\",\n",
    "    3: \"Carpet\"\n",
    "}\n",
    "\n",
    "# Detectar si Surface es numérica\n",
    "if np.issubdtype(df[\"Surface\"].dtype, np.number):\n",
    "    df[\"SurfaceText\"] = df[\"Surface\"].map(surface_map)\n",
    "else:\n",
    "    df[\"SurfaceText\"] = df[\"Surface\"]\n",
    "\n",
    "# ============================\n",
    "# 2. ORDEN CORRECTO DE RONDAS\n",
    "# ============================\n",
    "\n",
    "round_order = {\n",
    "    \"1st Round\": 1,\n",
    "    \"2nd Round\": 2,\n",
    "    \"3rd Round\": 3,\n",
    "    \"4th Round\": 4,\n",
    "    \"Round of 16\": 5,\n",
    "    \"Quarterfinals\": 6,\n",
    "    \"Semifinals\": 7,\n",
    "    \"The Final\": 8\n",
    "}\n",
    "\n",
    "df[\"RoundOrder\"] = df[\"Round\"].map(round_order)\n",
    "\n",
    "# Ordenar completamente en orden real cronológico\n",
    "df = df.sort_values([\"Date\", \"Tournament\", \"RoundOrder\"]).reset_index(drop=True)\n",
    "\n",
    "# ============================\n",
    "# 3. CONFIGURACIÓN DEL ELO\n",
    "# ============================\n",
    "\n",
    "ELO_START = 1500\n",
    "DECAY_GLOBAL = 0.9995\n",
    "DECAY_SURFACE = 0.999\n",
    "\n",
    "def dynamic_k(diff):\n",
    "    \"\"\"K depende de diferencia de Elo (más cerca → más grande K).\"\"\"\n",
    "    if diff < 25:\n",
    "        return 40\n",
    "    elif diff < 75:\n",
    "        return 32\n",
    "    elif diff < 150:\n",
    "        return 24\n",
    "    else:\n",
    "        return 16\n",
    "\n",
    "# Importancia del torneo\n",
    "tournament_weights = {\n",
    "    \"ATP250\": 1.00,\n",
    "    \"ATP500\": 1.10,\n",
    "    \"Masters 1000\": 1.20,\n",
    "    \"Grand Slam\": 1.30,\n",
    "    \"International\": 1.00   # por compatibilidad con tus datos antiguos\n",
    "}\n",
    "\n",
    "# ============================\n",
    "# 4. INICIALIZAR ELO\n",
    "# ============================\n",
    "\n",
    "elo_global = defaultdict(lambda: ELO_START)\n",
    "elo_surface = defaultdict(lambda: {\"Hard\": ELO_START, \"Clay\": ELO_START, \"Grass\": ELO_START, \"Carpet\": ELO_START})\n",
    "\n",
    "# Columnas de salida\n",
    "df[\"EloA_Global\"] = 0.0\n",
    "df[\"EloB_Global\"] = 0.0\n",
    "df[\"EloA_Surface\"] = 0.0\n",
    "df[\"EloB_Surface\"] = 0.0\n",
    "\n",
    "# ============================\n",
    "# 5. EXPECTED SCORE\n",
    "# ============================\n",
    "\n",
    "def expected_score(r1, r2):\n",
    "    return 1 / (1 + 10 ** ((r2 - r1) / 400))\n",
    "\n",
    "# ============================\n",
    "# 6. CALCULAR ELO SIN DATA LEAKAGE\n",
    "# ============================\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    \n",
    "    A = row[\"PlayerA\"]\n",
    "    B = row[\"PlayerB\"]\n",
    "    surf = row[\"SurfaceText\"]\n",
    "    series = row[\"Series\"]\n",
    "\n",
    "    # --- Decaimiento temporal (antes del partido)\n",
    "    elo_global[A] *= DECAY_GLOBAL\n",
    "    elo_global[B] *= DECAY_GLOBAL\n",
    "    elo_surface[A][surf] *= DECAY_SURFACE\n",
    "    elo_surface[B][surf] *= DECAY_SURFACE\n",
    "\n",
    "    # --- Elo ANTES DEL PARTIDO (features pre-partido)\n",
    "    eloA_g = elo_global[A]\n",
    "    eloB_g = elo_global[B]\n",
    "    eloA_s = elo_surface[A][surf]\n",
    "    eloB_s = elo_surface[B][surf]\n",
    "\n",
    "    df.at[i, \"EloA_Global\"] = eloA_g\n",
    "    df.at[i, \"EloB_Global\"] = eloB_g\n",
    "    df.at[i, \"EloA_Surface\"] = eloA_s\n",
    "    df.at[i, \"EloB_Surface\"] = eloB_s\n",
    "\n",
    "    # --- Resultado del partido\n",
    "    winner = row[\"WinnerBinary\"]\n",
    "    scoreA = 1 if winner == 1 else 0\n",
    "    scoreB = 1 - scoreA\n",
    "\n",
    "    # --- Expected score\n",
    "    expA_g = expected_score(eloA_g, eloB_g)\n",
    "    expA_s = expected_score(eloA_s, eloB_s)\n",
    "\n",
    "    # --- K dinámico + importancia de torneo\n",
    "    diff = abs(eloA_g - eloB_g)\n",
    "    K = dynamic_k(diff)\n",
    "    weight = tournament_weights.get(series, 1.00)\n",
    "    K_final = K * weight\n",
    "\n",
    "    # --- Actualización GLOBAL\n",
    "    elo_global[A] = eloA_g + K_final * (scoreA - expA_g)\n",
    "    elo_global[B] = eloB_g + K_final * (scoreB - (1 - expA_g))\n",
    "\n",
    "    # --- Actualización SUPERFICIE\n",
    "    elo_surface[A][surf] = eloA_s + K_final * (scoreA - expA_s)\n",
    "    elo_surface[B][surf] = eloB_s + K_final * (scoreB - (1 - expA_s))\n",
    "\n",
    "# ============================\n",
    "# 7. DIFERENCIAS FINALES COMO FEATURES\n",
    "# ============================\n",
    "\n",
    "df[\"EloDiff_Global\"] = df[\"EloA_Global\"] - df[\"EloB_Global\"]\n",
    "df[\"EloDiff_Surface\"] = df[\"EloA_Surface\"] - df[\"EloB_Surface\"]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1effa54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ade1480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños:\n",
      "Train: (48355, 12) Val: (6908, 12) Test: (13816, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_series = LabelEncoder()\n",
    "df[\"Series\"] = le_series.fit_transform(df[\"Series\"])\n",
    "\n",
    "# ======== FEATURES ========\n",
    "features = [\n",
    "    # Diferencias estadísticas base\n",
    "    'LogRankDiff',\n",
    "    'DiffWR',\n",
    "    'DiffForm',\n",
    "    'H2HDiff',\n",
    "    'OddsProbDiff',\n",
    "    'DiffRest',\n",
    "    'EfficiencyDiff',\n",
    "    'RankDiff',\n",
    "\n",
    "    # Elo avanzado\n",
    "    'EloDiff_Global',\n",
    "    'EloDiff_Surface',\n",
    "\n",
    "    # Contexto\n",
    "    'Series',       # codificada con LabelEncoder\n",
    "    'RoundOrder'    # orden real de la ronda\n",
    "]\n",
    "\n",
    "# Aseguramos orden temporal\n",
    "df = df.sort_values(\"Date\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"WinnerBinary\"].values\n",
    "\n",
    "n = len(df)\n",
    "idx_train_end = int(n * 0.7)   # 70% train\n",
    "idx_val_end   = int(n * 0.8)   # 10% val (70–80)\n",
    "# 20% restante = test\n",
    "\n",
    "X_train = X.iloc[:idx_train_end]\n",
    "y_train = y[:idx_train_end]\n",
    "\n",
    "X_val   = X.iloc[idx_train_end:idx_val_end]\n",
    "y_val   = y[idx_train_end:idx_val_end]\n",
    "\n",
    "X_test  = X.iloc[idx_val_end:]\n",
    "y_test  = y[idx_val_end:]\n",
    "\n",
    "print(\"Tamaños:\")\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# ======== ESCALADO (solo con TRAIN) ========\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_val_sc   = scaler.transform(X_val)\n",
    "X_test_sc  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d557e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo con n_estimators = 200\n",
      "VAL → ACC=0.6671, BRIER=0.2070\n",
      "\n",
      "Entrenando modelo con n_estimators = 350\n",
      "VAL → ACC=0.6695, BRIER=0.2067\n",
      "\n",
      "Entrenando modelo con n_estimators = 500\n",
      "VAL → ACC=0.6702, BRIER=0.2065\n",
      "\n",
      "Entrenando modelo con n_estimators = 750\n",
      "VAL → ACC=0.6701, BRIER=0.2068\n",
      "\n",
      "Entrenando modelo con n_estimators = 1000\n",
      "VAL → ACC=0.6692, BRIER=0.2070\n",
      "\n",
      "Entrenando modelo con n_estimators = 1300\n",
      "VAL → ACC=0.6655, BRIER=0.2076\n",
      "\n",
      "==============================\n",
      "MEJOR n_estimators EN VALIDACIÓN:\n",
      "n_estimators=500, ACC_VAL=0.6702, BRIER_VAL=0.2065\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Valores a probar para número de árboles\n",
    "n_estimators_grid = [200, 350, 500, 750, 1000, 1300]\n",
    "\n",
    "results = []\n",
    "\n",
    "for n_est in n_estimators_grid:\n",
    "    print(f\"\\nEntrenando modelo con n_estimators = {n_est}\")\n",
    "\n",
    "    model_tmp = XGBClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.02,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.1,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "    model_tmp.fit(X_train_sc, y_train)\n",
    "\n",
    "    prob_val = model_tmp.predict_proba(X_val_sc)[:, 1]\n",
    "    pred_val = (prob_val >= 0.5).astype(int)\n",
    "\n",
    "    acc_val = accuracy_score(y_val, pred_val)\n",
    "    brier_val = brier_score_loss(y_val, prob_val)\n",
    "\n",
    "    results.append((n_est, acc_val, brier_val))\n",
    "    print(f\"VAL → ACC={acc_val:.4f}, BRIER={brier_val:.4f}\")\n",
    "\n",
    "# Elegir el mejor por Brier y, en empate, por accuracy\n",
    "results_sorted = sorted(results, key=lambda x: (x[2], -x[1]))\n",
    "best_n, best_acc_val, best_brier_val = results_sorted[0]\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"MEJOR n_estimators EN VALIDACIÓN:\")\n",
    "print(f\"n_estimators={best_n}, ACC_VAL={best_acc_val:.4f}, BRIER_VAL={best_brier_val:.4f}\")\n",
    "print(\"==============================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c72559d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTADOS SIN CALIBRACIÓN =====\n",
      "Accuracy TEST: 0.6749\n",
      "Brier TEST:    0.2049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6675    0.6879    0.6775      6859\n",
      "           1     0.6827    0.6622    0.6723      6957\n",
      "\n",
      "    accuracy                         0.6749     13816\n",
      "   macro avg     0.6751    0.6750    0.6749     13816\n",
      "weighted avg     0.6752    0.6749    0.6749     13816\n",
      "\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "# ======== REENTRENAR SCALER EN TRAIN+VAL ========\n",
    "X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_val = np.concatenate([y_train, y_val])\n",
    "\n",
    "scaler_final = StandardScaler()\n",
    "X_train_val_sc = scaler_final.fit_transform(X_train_val)\n",
    "X_test_sc_final = scaler_final.transform(X_test)\n",
    "\n",
    "# ======== MODELO XGBOOST FINAL (SIN CALIBRACIÓN) ========\n",
    "base_model_final = XGBClassifier(\n",
    "    n_estimators=best_n,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.02,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "base_model_final.fit(X_train_val_sc, y_train_val)\n",
    "\n",
    "# ======== EVALUACIÓN SIN CALIBRACIÓN ========\n",
    "prob_test_base = base_model_final.predict_proba(X_test_sc_final)[:, 1]\n",
    "pred_test_base = (prob_test_base >= 0.5).astype(int)\n",
    "\n",
    "acc_base = accuracy_score(y_test, pred_test_base)\n",
    "brier_base = brier_score_loss(y_test, prob_test_base)\n",
    "\n",
    "print(\"\\n===== RESULTADOS SIN CALIBRACIÓN =====\")\n",
    "print(f\"Accuracy TEST: {acc_base:.4f}\")\n",
    "print(f\"Brier TEST:    {brier_base:.4f}\")\n",
    "print(classification_report(y_test, pred_test_base, digits=4))\n",
    "print(\"=======================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86da84c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RESULTADOS CON CALIBRACIÓN ISOTÓNICA =====\n",
      "Accuracy TEST: 0.6741\n",
      "Brier TEST:    0.2049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6649    0.6924    0.6784      6859\n",
      "           1     0.6838    0.6560    0.6697      6957\n",
      "\n",
      "    accuracy                         0.6741     13816\n",
      "   macro avg     0.6744    0.6742    0.6740     13816\n",
      "weighted avg     0.6745    0.6741    0.6740     13816\n",
      "\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "# ======== CALIBRACIÓN ISOTÓNICA SOBRE TRAIN+VAL ========\n",
    "cal_model = CalibratedClassifierCV(\n",
    "    estimator=deepcopy(base_model_final),\n",
    "    method=\"isotonic\",\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "cal_model.fit(X_train_val_sc, y_train_val)\n",
    "\n",
    "prob_test_cal = cal_model.predict_proba(X_test_sc_final)[:, 1]\n",
    "pred_test_cal = (prob_test_cal >= 0.5).astype(int)\n",
    "\n",
    "acc_cal = accuracy_score(y_test, pred_test_cal)\n",
    "brier_cal = brier_score_loss(y_test, prob_test_cal)\n",
    "\n",
    "print(\"\\n===== RESULTADOS CON CALIBRACIÓN ISOTÓNICA =====\")\n",
    "print(f\"Accuracy TEST: {acc_cal:.4f}\")\n",
    "print(f\"Brier TEST:    {brier_cal:.4f}\")\n",
    "print(classification_report(y_test, pred_test_cal, digits=4))\n",
    "print(\"================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349085c3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5507500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños:\n",
      "Train: (48355, 12) Val: (6908, 12) Test: (13816, 12)\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "features = [\n",
    "    # Diferencias estadísticas base\n",
    "    'LogRankDiff',\n",
    "    'DiffWR',\n",
    "    'DiffForm',\n",
    "    'H2HDiff',\n",
    "    'OddsProbDiff',\n",
    "    'DiffRest',\n",
    "    'EfficiencyDiff',\n",
    "    'RankDiff',\n",
    "\n",
    "    # Elo avanzado\n",
    "    'EloDiff_Global',\n",
    "    'EloDiff_Surface',\n",
    "\n",
    "    # Contexto\n",
    "    'Series',       # codificada con LabelEncoder\n",
    "    'RoundOrder'    # orden real de la ronda\n",
    "]\n",
    "\n",
    "# Aseguramos orden temporal\n",
    "df = df.sort_values(\"Date\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"WinnerBinary\"].values\n",
    "\n",
    "n = len(df)\n",
    "idx_train_end = int(n * 0.7)   # 70% train\n",
    "idx_val_end   = int(n * 0.8)   # +10% val\n",
    "\n",
    "X_train = X.iloc[:idx_train_end]\n",
    "y_train = y[:idx_train_end]\n",
    "\n",
    "X_val   = X.iloc[idx_train_end:idx_val_end]\n",
    "y_val   = y[idx_train_end:idx_val_end]\n",
    "\n",
    "X_test  = X.iloc[idx_val_end:]\n",
    "y_test  = y[idx_val_end:]\n",
    "\n",
    "print(\"Tamaños:\")\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce39df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando LGBM con: num_leaves=31, lr=0.05, n_estimators=400, min_data_in_leaf=30, feature_fraction=0.9, bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 24500, number of negative: 23855\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2282\n",
      "[LightGBM] [Info] Number of data points in the train set: 48355, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506669 -> initscore=0.026679\n",
      "[LightGBM] [Info] Start training from score 0.026679\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "VAL → ACC=0.6692, BRIER=0.2072\n",
      "\n",
      "Entrenando LGBM con: num_leaves=31, lr=0.03, n_estimators=800, min_data_in_leaf=30, feature_fraction=0.9, bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 24500, number of negative: 23855\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2282\n",
      "[LightGBM] [Info] Number of data points in the train set: 48355, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506669 -> initscore=0.026679\n",
      "[LightGBM] [Info] Start training from score 0.026679\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "VAL → ACC=0.6684, BRIER=0.2075\n",
      "\n",
      "Entrenando LGBM con: num_leaves=63, lr=0.03, n_estimators=800, min_data_in_leaf=50, feature_fraction=0.9, bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Number of positive: 24500, number of negative: 23855\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2282\n",
      "[LightGBM] [Info] Number of data points in the train set: 48355, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506669 -> initscore=0.026679\n",
      "[LightGBM] [Info] Start training from score 0.026679\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "VAL → ACC=0.6688, BRIER=0.2089\n",
      "\n",
      "Entrenando LGBM con: num_leaves=63, lr=0.02, n_estimators=1200, min_data_in_leaf=50, feature_fraction=0.9, bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Number of positive: 24500, number of negative: 23855\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2282\n",
      "[LightGBM] [Info] Number of data points in the train set: 48355, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506669 -> initscore=0.026679\n",
      "[LightGBM] [Info] Start training from score 0.026679\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "VAL → ACC=0.6636, BRIER=0.2099\n",
      "\n",
      "Entrenando LGBM con: num_leaves=127, lr=0.02, n_estimators=1400, min_data_in_leaf=80, feature_fraction=0.8, bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] Number of positive: 24500, number of negative: 23855\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2282\n",
      "[LightGBM] [Info] Number of data points in the train set: 48355, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506669 -> initscore=0.026679\n",
      "[LightGBM] [Info] Start training from score 0.026679\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "VAL → ACC=0.6569, BRIER=0.2151\n",
      "\n",
      "=============== MEJOR CONFIGURACIÓN EN VALIDACIÓN ===============\n",
      "num_leaves=31, lr=0.05, n_estimators=400, min_data_in_leaf=30, feature_fraction=0.9, bagging_fraction=0.9\n",
      "ACC_VAL=0.6692, BRIER_VAL=0.2072\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    # (num_leaves, learning_rate, n_estimators, min_data_in_leaf, feature_fraction, bagging_fraction)\n",
    "    (31,  0.05, 400, 30, 0.9, 0.9),\n",
    "    (31,  0.03, 800, 30, 0.9, 0.9),\n",
    "    (63,  0.03, 800, 50, 0.9, 0.9),\n",
    "    (63,  0.02, 1200, 50, 0.9, 0.8),\n",
    "    (127, 0.02, 1400, 80, 0.8, 0.8),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for (num_leaves, lr, n_estimators, min_data, feat_frac, bag_frac) in param_grid:\n",
    "    print(f\"\\nEntrenando LGBM con: \"\n",
    "          f\"num_leaves={num_leaves}, lr={lr}, n_estimators={n_estimators}, \"\n",
    "          f\"min_data_in_leaf={min_data}, feature_fraction={feat_frac}, bagging_fraction={bag_frac}\")\n",
    "\n",
    "    lgbm = LGBMClassifier(\n",
    "        objective='binary',\n",
    "        num_leaves=num_leaves,\n",
    "        learning_rate=lr,\n",
    "        n_estimators=n_estimators,\n",
    "        min_data_in_leaf=min_data,\n",
    "        feature_fraction=feat_frac,\n",
    "        bagging_fraction=bag_frac,\n",
    "        bagging_freq=1,\n",
    "        subsample_for_bin=200000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    lgbm.fit(X_train, y_train)\n",
    "\n",
    "    prob_val = lgbm.predict_proba(X_val)[:, 1]\n",
    "    pred_val = (prob_val >= 0.5).astype(int)\n",
    "\n",
    "    acc_val = accuracy_score(y_val, pred_val)\n",
    "    brier_val = brier_score_loss(y_val, prob_val)\n",
    "\n",
    "    results.append({\n",
    "        \"num_leaves\": num_leaves,\n",
    "        \"learning_rate\": lr,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"min_data_in_leaf\": min_data,\n",
    "        \"feature_fraction\": feat_frac,\n",
    "        \"bagging_fraction\": bag_frac,\n",
    "        \"acc_val\": acc_val,\n",
    "        \"brier_val\": brier_val\n",
    "    })\n",
    "\n",
    "    print(f\"VAL → ACC={acc_val:.4f}, BRIER={brier_val:.4f}\")\n",
    "\n",
    "# Elegir el mejor: minimizamos Brier, y en empate maximizamos ACC\n",
    "results_sorted = sorted(results, key=lambda r: (r[\"brier_val\"], -r[\"acc_val\"]))\n",
    "best = results_sorted[0]\n",
    "\n",
    "print(\"\\n=============== MEJOR CONFIGURACIÓN EN VALIDACIÓN ===============\")\n",
    "print(f\"num_leaves={best['num_leaves']}, \"\n",
    "      f\"lr={best['learning_rate']}, \"\n",
    "      f\"n_estimators={best['n_estimators']}, \"\n",
    "      f\"min_data_in_leaf={best['min_data_in_leaf']}, \"\n",
    "      f\"feature_fraction={best['feature_fraction']}, \"\n",
    "      f\"bagging_fraction={best['bagging_fraction']}\")\n",
    "print(f\"ACC_VAL={best['acc_val']:.4f}, BRIER_VAL={best['brier_val']:.4f}\")\n",
    "print(\"=================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b3b4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 27995, number of negative: 27268\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 55263, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506578 -> initscore=0.026312\n",
      "[LightGBM] [Info] Start training from score 0.026312\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "\n",
      "===== RESULTADOS LGBM EN TEST (SIN CALIBRAR) =====\n",
      "Accuracy TEST: 0.6731\n",
      "Brier TEST:    0.2058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.6830    0.6748      6859\n",
      "           1     0.6798    0.6634    0.6715      6957\n",
      "\n",
      "    accuracy                         0.6731     13816\n",
      "   macro avg     0.6732    0.6732    0.6731     13816\n",
      "weighted avg     0.6733    0.6731    0.6731     13816\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Unimos train + val para entrenar el modelo final\n",
    "X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_val = np.concatenate([y_train, y_val])\n",
    "\n",
    "best_lgbm = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    num_leaves=best['num_leaves'],\n",
    "    learning_rate=best['learning_rate'],\n",
    "    n_estimators=best['n_estimators'],\n",
    "    min_data_in_leaf=best['min_data_in_leaf'],\n",
    "    feature_fraction=best['feature_fraction'],\n",
    "    bagging_fraction=best['bagging_fraction'],\n",
    "    bagging_freq=1,\n",
    "    subsample_for_bin=200000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_lgbm.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Evaluación en TEST\n",
    "prob_test = best_lgbm.predict_proba(X_test)[:, 1]\n",
    "pred_test = (prob_test >= 0.5).astype(int)\n",
    "\n",
    "acc_test = accuracy_score(y_test, pred_test)\n",
    "brier_test = brier_score_loss(y_test, prob_test)\n",
    "\n",
    "print(\"\\n===== RESULTADOS LGBM EN TEST (SIN CALIBRAR) =====\")\n",
    "print(f\"Accuracy TEST: {acc_test:.4f}\")\n",
    "print(f\"Brier TEST:    {brier_test:.4f}\")\n",
    "print(classification_report(y_test, pred_test, digits=4))\n",
    "print(\"==================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f7be097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 22396, number of negative: 21814\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2257\n",
      "[LightGBM] [Info] Number of data points in the train set: 44210, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506582 -> initscore=0.026330\n",
      "[LightGBM] [Info] Start training from score 0.026330\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 22396, number of negative: 21814\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 44210, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506582 -> initscore=0.026330\n",
      "[LightGBM] [Info] Start training from score 0.026330\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 22396, number of negative: 21814\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2281\n",
      "[LightGBM] [Info] Number of data points in the train set: 44210, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506582 -> initscore=0.026330\n",
      "[LightGBM] [Info] Start training from score 0.026330\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 22396, number of negative: 21815\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2280\n",
      "[LightGBM] [Info] Number of data points in the train set: 44211, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506571 -> initscore=0.026285\n",
      "[LightGBM] [Info] Start training from score 0.026285\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 22396, number of negative: 21815\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2282\n",
      "[LightGBM] [Info] Number of data points in the train set: 44211, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506571 -> initscore=0.026285\n",
      "[LightGBM] [Info] Start training from score 0.026285\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "\n",
      "===== RESULTADOS LGBM EN TEST (CALIBRADO ISOTÓNICO) =====\n",
      "Accuracy TEST: 0.6740\n",
      "Brier TEST:    0.2053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6660    0.6887    0.6772      6859\n",
      "           1     0.6824    0.6595    0.6708      6957\n",
      "\n",
      "    accuracy                         0.6740     13816\n",
      "   macro avg     0.6742    0.6741    0.6740     13816\n",
      "weighted avg     0.6743    0.6740    0.6739     13816\n",
      "\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from copy import deepcopy\n",
    "\n",
    "cal_lgbm = CalibratedClassifierCV(\n",
    "    estimator=deepcopy(best_lgbm),\n",
    "    method=\"isotonic\",\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "cal_lgbm.fit(X_train_val, y_train_val)\n",
    "\n",
    "prob_test_cal = cal_lgbm.predict_proba(X_test)[:, 1]\n",
    "pred_test_cal = (prob_test_cal >= 0.5).astype(int)\n",
    "\n",
    "acc_test_cal = accuracy_score(y_test, pred_test_cal)\n",
    "brier_test_cal = brier_score_loss(y_test, prob_test_cal)\n",
    "\n",
    "print(\"\\n===== RESULTADOS LGBM EN TEST (CALIBRADO ISOTÓNICO) =====\")\n",
    "print(f\"Accuracy TEST: {acc_test_cal:.4f}\")\n",
    "print(f\"Brier TEST:    {brier_test_cal:.4f}\")\n",
    "print(classification_report(y_test, pred_test_cal, digits=4))\n",
    "print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed0948d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "      <th>SurfaceText</th>\n",
       "      <th>RoundOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69074</th>\n",
       "      <td>51</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Shanghai Masters</td>\n",
       "      <td>2025-10-10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Medvedev D.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038809</td>\n",
       "      <td>0.051916</td>\n",
       "      <td>1691.504127</td>\n",
       "      <td>1651.284548</td>\n",
       "      <td>1590.408179</td>\n",
       "      <td>1579.838578</td>\n",
       "      <td>40.219579</td>\n",
       "      <td>10.569601</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69075</th>\n",
       "      <td>51</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Shanghai Masters</td>\n",
       "      <td>2025-10-10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Rinderknech A.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>1634.259004</td>\n",
       "      <td>1554.345741</td>\n",
       "      <td>1546.515563</td>\n",
       "      <td>1446.534097</td>\n",
       "      <td>79.913263</td>\n",
       "      <td>99.981466</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69076</th>\n",
       "      <td>51</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Shanghai Masters</td>\n",
       "      <td>2025-10-11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Vacherot V.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.164670</td>\n",
       "      <td>1820.576800</td>\n",
       "      <td>1534.866613</td>\n",
       "      <td>1708.158399</td>\n",
       "      <td>1561.914822</td>\n",
       "      <td>285.710187</td>\n",
       "      <td>146.243578</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69077</th>\n",
       "      <td>51</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Shanghai Masters</td>\n",
       "      <td>2025-10-11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Rinderknech A.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008885</td>\n",
       "      <td>0.029954</td>\n",
       "      <td>1671.860940</td>\n",
       "      <td>1571.214670</td>\n",
       "      <td>1598.022873</td>\n",
       "      <td>1463.502294</td>\n",
       "      <td>100.646269</td>\n",
       "      <td>134.520579</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69078</th>\n",
       "      <td>51</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Shanghai Masters</td>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>The Final</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Vacherot V.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>1588.878377</td>\n",
       "      <td>1550.184011</td>\n",
       "      <td>1481.731639</td>\n",
       "      <td>1573.757482</td>\n",
       "      <td>38.694366</td>\n",
       "      <td>-92.025843</td>\n",
       "      <td>Carpet</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ATP  Location        Tournament        Date  Series  Court  Surface  \\\n",
       "69074   51  Shanghai  Shanghai Masters  2025-10-10       6      1        3   \n",
       "69075   51  Shanghai  Shanghai Masters  2025-10-10       6      1        3   \n",
       "69076   51  Shanghai  Shanghai Masters  2025-10-11       6      1        3   \n",
       "69077   51  Shanghai  Shanghai Masters  2025-10-11       6      1        3   \n",
       "69078   51  Shanghai  Shanghai Masters  2025-10-12       6      1        3   \n",
       "\n",
       "               Round  Best of          Winner  ... WinRateB_x_Rank  \\\n",
       "69074  Quarterfinals      3.0     Medvedev D.  ...        0.038809   \n",
       "69075  Quarterfinals      3.0  Rinderknech A.  ...        0.008836   \n",
       "69076     Semifinals      3.0     Vacherot V.  ...        0.002451   \n",
       "69077     Semifinals      3.0  Rinderknech A.  ...        0.008885   \n",
       "69078      The Final      3.0     Vacherot V.  ...        0.002640   \n",
       "\n",
       "       EfficiencyDiff  EloA_Global  EloB_Global  EloA_Surface  EloB_Surface  \\\n",
       "69074        0.051916  1691.504127  1651.284548   1590.408179   1579.838578   \n",
       "69075        0.037754  1634.259004  1554.345741   1546.515563   1446.534097   \n",
       "69076        0.164670  1820.576800  1534.866613   1708.158399   1561.914822   \n",
       "69077        0.029954  1671.860940  1571.214670   1598.022873   1463.502294   \n",
       "69078        0.006294  1588.878377  1550.184011   1481.731639   1573.757482   \n",
       "\n",
       "       EloDiff_Global  EloDiff_Surface  SurfaceText  RoundOrder  \n",
       "69074       40.219579        10.569601       Carpet         6.0  \n",
       "69075       79.913263        99.981466       Carpet         6.0  \n",
       "69076      285.710187       146.243578       Carpet         7.0  \n",
       "69077      100.646269       134.520579       Carpet         7.0  \n",
       "69078       38.694366       -92.025843       Carpet         8.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d42df",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f7679ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "      <th>SurfaceText</th>\n",
       "      <th>RoundOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68190</th>\n",
       "      <td>34</td>\n",
       "      <td>Eastbourne</td>\n",
       "      <td>Eastbourne International</td>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Brooksby J.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026619</td>\n",
       "      <td>-0.022634</td>\n",
       "      <td>1580.340441</td>\n",
       "      <td>1571.101191</td>\n",
       "      <td>1517.798627</td>\n",
       "      <td>1513.089812</td>\n",
       "      <td>9.239250</td>\n",
       "      <td>4.708815</td>\n",
       "      <td>Grass</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68191</th>\n",
       "      <td>35</td>\n",
       "      <td>Mallorca</td>\n",
       "      <td>Mallorca Championships</td>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Moutet C.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>1500.165431</td>\n",
       "      <td>1469.266775</td>\n",
       "      <td>1536.528132</td>\n",
       "      <td>1509.352359</td>\n",
       "      <td>30.898655</td>\n",
       "      <td>27.175773</td>\n",
       "      <td>Grass</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68192</th>\n",
       "      <td>35</td>\n",
       "      <td>Mallorca</td>\n",
       "      <td>Mallorca Championships</td>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Griekspoor T.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015519</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>1546.282583</td>\n",
       "      <td>1633.460846</td>\n",
       "      <td>1568.580267</td>\n",
       "      <td>1533.644120</td>\n",
       "      <td>-87.178263</td>\n",
       "      <td>34.936147</td>\n",
       "      <td>Grass</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68193</th>\n",
       "      <td>34</td>\n",
       "      <td>Eastbourne</td>\n",
       "      <td>Eastbourne International</td>\n",
       "      <td>2025-06-28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The Final</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119915</td>\n",
       "      <td>-0.115902</td>\n",
       "      <td>1599.008808</td>\n",
       "      <td>1672.325062</td>\n",
       "      <td>1535.990054</td>\n",
       "      <td>1634.801117</td>\n",
       "      <td>-73.316253</td>\n",
       "      <td>-98.811062</td>\n",
       "      <td>Grass</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68194</th>\n",
       "      <td>35</td>\n",
       "      <td>Mallorca</td>\n",
       "      <td>Mallorca Championships</td>\n",
       "      <td>2025-06-28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The Final</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Griekspoor T.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>1641.690200</td>\n",
       "      <td>1485.942629</td>\n",
       "      <td>1545.299875</td>\n",
       "      <td>1525.074702</td>\n",
       "      <td>155.747571</td>\n",
       "      <td>20.225173</td>\n",
       "      <td>Grass</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ATP    Location                Tournament        Date  Series  Court  \\\n",
       "68190   34  Eastbourne  Eastbourne International  2025-06-27       0      1   \n",
       "68191   35    Mallorca    Mallorca Championships  2025-06-27       0      1   \n",
       "68192   35    Mallorca    Mallorca Championships  2025-06-27       0      1   \n",
       "68193   34  Eastbourne  Eastbourne International  2025-06-28       0      1   \n",
       "68194   35    Mallorca    Mallorca Championships  2025-06-28       0      1   \n",
       "\n",
       "       Surface       Round  Best of         Winner  ... WinRateB_x_Rank  \\\n",
       "68190        2  Semifinals      3.0    Brooksby J.  ...        0.026619   \n",
       "68191        2  Semifinals      3.0      Moutet C.  ...        0.005183   \n",
       "68192        2  Semifinals      3.0  Griekspoor T.  ...        0.015519   \n",
       "68193        2   The Final      3.0       Fritz T.  ...        0.119915   \n",
       "68194        2   The Final      3.0  Griekspoor T.  ...        0.005221   \n",
       "\n",
       "       EfficiencyDiff  EloA_Global  EloB_Global  EloA_Surface  EloB_Surface  \\\n",
       "68190       -0.022634  1580.340441  1571.101191   1517.798627   1513.089812   \n",
       "68191        0.010843  1500.165431  1469.266775   1536.528132   1509.352359   \n",
       "68192        0.006743  1546.282583  1633.460846   1568.580267   1533.644120   \n",
       "68193       -0.115902  1599.008808  1672.325062   1535.990054   1634.801117   \n",
       "68194        0.010367  1641.690200  1485.942629   1545.299875   1525.074702   \n",
       "\n",
       "       EloDiff_Global  EloDiff_Surface  SurfaceText  RoundOrder  \n",
       "68190        9.239250         4.708815        Grass         7.0  \n",
       "68191       30.898655        27.175773        Grass         7.0  \n",
       "68192      -87.178263        34.936147        Grass         7.0  \n",
       "68193      -73.316253       -98.811062        Grass         8.0  \n",
       "68194      155.747571        20.225173        Grass         8.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[df['Date'] < '2025-06-29'].copy()\n",
    "test = df[(df['Date'] >= '2025-06-29') & (df['Date'] <= '2025-07-13')].copy()\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f6c942bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mida train:  68195\n",
      "Mida test:  127\n"
     ]
    }
   ],
   "source": [
    "print(\"Mida train: \", len(train))\n",
    "print(\"Mida test: \", len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c38edd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mida first round:  64\n",
      "Mida second round:  32\n",
      "Mida third round:  16\n",
      "Mida fourth round:  8\n",
      "Mida quarter finals:  4\n",
      "Mida semi finals:  2\n",
      "Mida finals:  1\n"
     ]
    }
   ],
   "source": [
    "# First round \n",
    "first_round = test[test['Round'] == '1st Round']\n",
    "# Second round\n",
    "second_round = test[test['Round'] == '2nd Round']\n",
    "# Third round\n",
    "third_round = test[test['Round'] == '3rd Round']\n",
    "# Fourth round\n",
    "fourth_round = test[test['Round'] == '4th Round']\n",
    "# Quarter finals\n",
    "quarter_finals = test[test['Round'] == 'Quarterfinals']\n",
    "# Semi finals\n",
    "semi_finals = test[test['Round'] == 'Semifinals']\n",
    "# Finals\n",
    "finals = test[test['Round'] == 'The Final']\n",
    "\n",
    "print(\"Mida first round: \", len(first_round))\n",
    "print(\"Mida second round: \", len(second_round))\n",
    "print(\"Mida third round: \", len(third_round))\n",
    "print(\"Mida fourth round: \", len(fourth_round))\n",
    "print(\"Mida quarter finals: \", len(quarter_finals))\n",
    "print(\"Mida semi finals: \", len(semi_finals))\n",
    "print(\"Mida finals: \", len(finals))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f9eeb",
   "metadata": {},
   "source": [
    "## First Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "280bb83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ACCURACY FINAL TEST CRONOLÓGIC: 0.6406\n",
      "Brier Score: 0.2285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6364    0.6562    0.6462        32\n",
      "           1     0.6452    0.6250    0.6349        32\n",
      "\n",
      "    accuracy                         0.6406        64\n",
      "   macro avg     0.6408    0.6406    0.6405        64\n",
      "weighted avg     0.6408    0.6406    0.6405        64\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    # Diferencias estadísticas base\n",
    "    'LogRankDiff',\n",
    "    'DiffWR',\n",
    "    'DiffForm',\n",
    "    'H2HDiff',\n",
    "    'OddsProbDiff',\n",
    "    'DiffRest',\n",
    "    'EfficiencyDiff',\n",
    "    'RankDiff',\n",
    "\n",
    "    # Elo avanzado\n",
    "    'EloDiff_Global',\n",
    "    'EloDiff_Surface',\n",
    "\n",
    "    # Contexto\n",
    "    'Series',       # codificada con LabelEncoder\n",
    "    'RoundOrder'    # orden real de la ronda\n",
    "]\n",
    "\n",
    "df = df.sort_values(\"Date\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "X_train = train[features].fillna(0)\n",
    "X_test = first_round[features].fillna(0)\n",
    "y_train = train['WinnerBinary']\n",
    "y_test = first_round['WinnerBinary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "base_model = XGBClassifier(\n",
    "    n_estimators=500,                    # Nombre total d'arbres (boosting rounds) que es construiran. 500 és un valor força alt, bo per a un bon rendiment si es controla l'overfitting.\n",
    "    max_depth=6,                         # Profunditat màxima de cada arbre. 6 és un valor moderat: permet interaccions complexes sense fer els arbres excessivament profunds.\n",
    "    learning_rate=0.02,                  # Taxa d'aprenentatge (eta). 0.02 és bastant baixa → aprenentatge lent i estable, ideal quan tens molts estimators (500).\n",
    "    subsample=0.85,                      # Percentatge de mostres (files) que s'utilitzen per entrenar cada arbre. 0.85 = 85% → ajuda a reduir overfitting i afegeix variància (com bagging).\n",
    "    colsample_bytree=0.85,               # Percentatge de columnes (variables) que s'agafen aleatòriament per cada arbre. 85% → també redueix overfitting i millora la generalització.\n",
    "    min_child_weight=5,                  # Suma mínima del pes Hessiana en un node fill. Valors >1 fan el model més conservador: evita dividir nodes amb poca informació.\n",
    "    gamma=0.1,                           # Minimització mínima de la funció de pèrdua necessària per fer una partició addicional (regularització per poda). 0.1 afavoreix arbres més simples.\n",
    "    reg_alpha=0.1,                       # Terme de regularització L1 sobre els pesos de les fulles. Ajuda a fer sparseness i és útil quan hi ha moltes variables irrellevants.\n",
    "    reg_lambda=1.0,                      # Terme de regularització L2 (més suau que L1). 1.0 és el valor per defecte i sol funcionar bé en la majoria de casos.\n",
    "    random_state=42,                     # Llavor per a la reproductibilitat dels resultats (aleatorietat controlada).\n",
    "    n_jobs=-1,                           # Utilitza tots els nuclis disponibles del processador per entrenar en paral·lel → molt més ràpid.\n",
    "    eval_metric='logloss'                # Mètrica d'avaluació durant l'entrenament (per classificació binària/multiclasse). 'logloss' = logarithmic loss (cross-entropy).\n",
    ")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "model = CalibratedClassifierCV(base_model, method='isotonic', cv=5)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "pred = model.predict(X_test_sc)\n",
    "prob = model.predict_proba(X_test_sc)[:, 1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "brier = brier_score_loss(y_test, prob)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ACCURACY FINAL TEST CRONOLÓGIC: {acc:.4f}\")\n",
    "print(f\"Brier Score: {brier:.4f}\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "725f1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def analyze_predictions(\n",
    "    df,\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    y_prob,\n",
    "    date_col=\"Date\",\n",
    "    player_a_col=\"PlayerA\",\n",
    "    player_b_col=\"PlayerB\",\n",
    "    true_col_name=\"WinnerBinary\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Analiza predicciones fila a fila, mostrando:\n",
    "      - Fecha, jugadores, etiqueta real, predicción, probabilidad\n",
    "      - Resumen de aciertos/fallos\n",
    "      - Tabla de predicciones fallidas\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original (por ejemplo, first_round).\n",
    "    y_true : array-like\n",
    "        Valores verdaderos (mismo orden que df).\n",
    "    y_pred : array-like\n",
    "        Predicciones (0/1) alineadas con y_true.\n",
    "    y_prob : array-like\n",
    "        Probabilidad predicha de la clase positiva (mismo orden).\n",
    "    date_col, player_a_col, player_b_col : str\n",
    "        Nombres de columnas en df para mostrar contexto.\n",
    "    true_col_name : str\n",
    "        Nombre con el que quieres que aparezca la columna de verdad en el output.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame con todas las filas y columnas extra (Predicted, Probability, Correct, Result).\n",
    "    failed_df : pd.DataFrame\n",
    "        Subconjunto con solo las predicciones fallidas.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copia de las columnas de contexto\n",
    "    results_df = df[[date_col, player_a_col, player_b_col]].copy()\n",
    "    results_df[true_col_name] = y_true\n",
    "\n",
    "    # Añadir predicciones y probabilidades\n",
    "    results_df[\"Predicted\"] = y_pred\n",
    "    results_df[\"Probability\"] = y_prob\n",
    "\n",
    "    # Aciertos / fallos\n",
    "    results_df[\"Correct\"] = (results_df[true_col_name] == results_df[\"Predicted\"])\n",
    "    results_df[\"Result\"] = results_df[\"Correct\"].map({True: \"✓ Correct\", False: \"✗ Failed\"})\n",
    "\n",
    "    # Resumen global\n",
    "    total = len(results_df)\n",
    "    correct = results_df[\"Correct\"].sum()\n",
    "    incorrect = total - correct\n",
    "    acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "    print(\"RESULTADOS DETALLADOS POR FILA:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"\\nTotal de predicciones: {total}\")\n",
    "    print(f\"Correctas: {correct} ({acc*100:.2f}%)\")\n",
    "    print(f\"Fallidas: {incorrect} ({(1-acc)*100:.2f}%)\")\n",
    "    print(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "\n",
    "    # Mostrar todas las filas\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.width\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "    display(results_df[[date_col, player_a_col, player_b_col,\n",
    "                        true_col_name, \"Predicted\", \"Probability\", \"Result\"]])\n",
    "\n",
    "    # Mostrar solo fallos\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"PREDICCIONES FALLIDAS:\")\n",
    "    print(\"=\" * 100)\n",
    "    failed_df = results_df[~results_df[\"Correct\"]]\n",
    "\n",
    "    if len(failed_df) > 0:\n",
    "        display(failed_df[[date_col, player_a_col, player_b_col,\n",
    "                           true_col_name, \"Predicted\", \"Probability\"]])\n",
    "    else:\n",
    "        print(\"¡Todas las predicciones han sido correctas!\")\n",
    "\n",
    "    return results_df, failed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7005c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DETALLADOS POR FILA:\n",
      "====================================================================================================\n",
      "\n",
      "Total de predicciones: 64\n",
      "Correctas: 41 (64.06%)\n",
      "Fallidas: 23 (35.94%)\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68195</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Kopriva V.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.268098</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68196</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Fery A.</td>\n",
       "      <td>Popyrin A.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275337</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68197</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Quinn E.</td>\n",
       "      <td>Searle H.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685398</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68198</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>Rune H.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240102</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68199</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Misolic F.</td>\n",
       "      <td>Struff J.L.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360912</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68200</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Bellucci M.</td>\n",
       "      <td>Crawford O.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751155</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68201</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Garin C.</td>\n",
       "      <td>Rodesch C.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484618</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68202</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Borges N.</td>\n",
       "      <td>Cerundolo F.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429620</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68203</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Davidovich Fokina A.</td>\n",
       "      <td>Holt B.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795220</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68204</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Darderi L.</td>\n",
       "      <td>Safiullin R.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266239</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68205</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Berrettini M.</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.897215</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68206</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Auger-Aliassime F.</td>\n",
       "      <td>Duckworth J.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814956</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68207</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Fognini F.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982424</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68208</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Bergs Z.</td>\n",
       "      <td>Harris L.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744967</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68209</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Fearnley J.</td>\n",
       "      <td>Fonseca J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360020</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68210</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Royer V.</td>\n",
       "      <td>Tsitsipas S.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265524</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68211</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Basavareddy N.</td>\n",
       "      <td>Tien L.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371042</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68212</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Brooksby J.</td>\n",
       "      <td>Griekspoor T.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.356450</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68213</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Bonzi B.</td>\n",
       "      <td>Medvedev D.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069562</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68214</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>McDonald M.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792940</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68215</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Moller E.</td>\n",
       "      <td>Tiafoe F.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056571</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68216</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Mannarino A.</td>\n",
       "      <td>O Connell C.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730104</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68217</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Dellien H.</td>\n",
       "      <td>Lehecka J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049540</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68218</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Riedi L.</td>\n",
       "      <td>Tarvet O.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611982</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68219</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Djere L.</td>\n",
       "      <td>Rublev A.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209271</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68220</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Altmaier D.</td>\n",
       "      <td>Diallo G.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221172</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68221</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Harris B.</td>\n",
       "      <td>Lajovic D.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736240</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68222</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Bautista Agut R.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552807</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68223</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Monday J.</td>\n",
       "      <td>Paul T.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031518</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68224</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Etcheverry T.</td>\n",
       "      <td>Pinnington Jones J.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588140</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68225</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Halys Q.</td>\n",
       "      <td>Holmgren A.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.827861</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68226</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Nardi L.</td>\n",
       "      <td>Sinner J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68227</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Opelka R.</td>\n",
       "      <td>Shevchenko A.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739525</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68228</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Faria J.</td>\n",
       "      <td>Sonego L.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237376</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68229</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Loffhagen G.</td>\n",
       "      <td>Martinez P.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714695</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68230</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Baez S.</td>\n",
       "      <td>Draper J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049540</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68231</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Dzumhur D.</td>\n",
       "      <td>Machac T.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191161</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68232</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Medjedovic H.</td>\n",
       "      <td>Ofner S.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645908</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68233</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Carballes Baena R.</td>\n",
       "      <td>De Minaur A.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053707</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68234</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Marozsan F.</td>\n",
       "      <td>McCabe J.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702877</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68235</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Comesana F.</td>\n",
       "      <td>Moutet C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.404810</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68236</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Dimitrov G.</td>\n",
       "      <td>Nishioka Y.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775881</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68237</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Basilashvili N.</td>\n",
       "      <td>Musetti L.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.264163</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68238</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Cilic M.</td>\n",
       "      <td>Collignon R.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.850964</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68239</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Bolt A.</td>\n",
       "      <td>Shelton B.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.241240</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68240</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Rinderknech A.</td>\n",
       "      <td>Zverev A.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128128</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68241</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Arnaldi M.</td>\n",
       "      <td>Van De Zandschulp B.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646269</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68242</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Humbert U.</td>\n",
       "      <td>Monfils G.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708137</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68243</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Navone M.</td>\n",
       "      <td>Shapovalov D.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138167</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68244</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Muller A.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981145</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68245</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Bublik A.</td>\n",
       "      <td>Munar J.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834141</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68246</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Goffin D.</td>\n",
       "      <td>Hijikata R.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347395</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68247</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Fucsovics M.</td>\n",
       "      <td>Kovacevic A.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.796674</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68248</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Cazaux A.</td>\n",
       "      <td>Walton A.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547537</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68249</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Tseng C.H.</td>\n",
       "      <td>Vukic A.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259092</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68250</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Kecmanovic M.</td>\n",
       "      <td>Michelsen A.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330384</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68251</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Mochizuki S.</td>\n",
       "      <td>Zeppieri G.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651035</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68252</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Giron M.</td>\n",
       "      <td>Ugo Carabelli C.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892478</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68253</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Gaston H.</td>\n",
       "      <td>Mensik J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071988</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68254</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Mpetshi G.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.832148</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68255</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>Zhukayev B.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740478</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68256</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>De Jong J.</td>\n",
       "      <td>Eubanks C.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594326</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68257</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Clarke J.</td>\n",
       "      <td>Evans D.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248331</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68262</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Bu Y.</td>\n",
       "      <td>Nakashima B.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171233</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date               PlayerA               PlayerB  WinnerBinary  \\\n",
       "68195  2025-06-30            Kopriva V.           Thompson J.             0   \n",
       "68196  2025-06-30               Fery A.            Popyrin A.             1   \n",
       "68197  2025-06-30              Quinn E.             Searle H.             1   \n",
       "68198  2025-06-30              Jarry N.               Rune H.             1   \n",
       "68199  2025-06-30            Misolic F.           Struff J.L.             0   \n",
       "68200  2025-06-30           Bellucci M.           Crawford O.             1   \n",
       "68201  2025-06-30              Garin C.            Rodesch C.             1   \n",
       "68202  2025-06-30             Borges N.          Cerundolo F.             1   \n",
       "68203  2025-06-30  Davidovich Fokina A.               Holt B.             1   \n",
       "68204  2025-06-30            Darderi L.          Safiullin R.             1   \n",
       "68205  2025-06-30         Berrettini M.          Majchrzak K.             0   \n",
       "68206  2025-06-30    Auger-Aliassime F.          Duckworth J.             1   \n",
       "68207  2025-06-30            Alcaraz C.            Fognini F.             1   \n",
       "68208  2025-06-30              Bergs Z.             Harris L.             0   \n",
       "68209  2025-06-30           Fearnley J.            Fonseca J.             0   \n",
       "68210  2025-06-30              Royer V.          Tsitsipas S.             1   \n",
       "68211  2025-06-30        Basavareddy N.               Tien L.             0   \n",
       "68212  2025-06-30           Brooksby J.         Griekspoor T.             1   \n",
       "68213  2025-06-30              Bonzi B.           Medvedev D.             1   \n",
       "68214  2025-06-30          Khachanov K.           McDonald M.             1   \n",
       "68215  2025-06-30             Moller E.             Tiafoe F.             0   \n",
       "68216  2025-06-30          Mannarino A.          O Connell C.             1   \n",
       "68217  2025-06-30            Dellien H.            Lehecka J.             0   \n",
       "68218  2025-06-30              Riedi L.             Tarvet O.             0   \n",
       "68219  2025-06-30              Djere L.             Rublev A.             0   \n",
       "68220  2025-06-30           Altmaier D.             Diallo G.             0   \n",
       "68221  2025-06-30             Harris B.            Lajovic D.             1   \n",
       "68222  2025-06-30      Bautista Agut R.             Norrie C.             0   \n",
       "68223  2025-07-01             Monday J.               Paul T.             0   \n",
       "68224  2025-07-01         Etcheverry T.   Pinnington Jones J.             0   \n",
       "68225  2025-07-01              Halys Q.           Holmgren A.             0   \n",
       "68226  2025-07-01              Nardi L.             Sinner J.             0   \n",
       "68227  2025-07-01             Opelka R.         Shevchenko A.             1   \n",
       "68228  2025-07-01              Faria J.             Sonego L.             0   \n",
       "68229  2025-07-01          Loffhagen G.           Martinez P.             0   \n",
       "68230  2025-07-01               Baez S.             Draper J.             0   \n",
       "68231  2025-07-01            Dzumhur D.             Machac T.             0   \n",
       "68232  2025-07-01         Medjedovic H.              Ofner S.             0   \n",
       "68233  2025-07-01    Carballes Baena R.          De Minaur A.             0   \n",
       "68234  2025-07-01           Marozsan F.             McCabe J.             1   \n",
       "68235  2025-07-01           Comesana F.             Moutet C.             0   \n",
       "68236  2025-07-01           Dimitrov G.           Nishioka Y.             1   \n",
       "68237  2025-07-01       Basilashvili N.            Musetti L.             1   \n",
       "68238  2025-07-01              Cilic M.          Collignon R.             1   \n",
       "68239  2025-07-01               Bolt A.            Shelton B.             0   \n",
       "68240  2025-07-01        Rinderknech A.             Zverev A.             1   \n",
       "68241  2025-07-01            Arnaldi M.  Van De Zandschulp B.             0   \n",
       "68242  2025-07-01            Humbert U.            Monfils G.             0   \n",
       "68243  2025-07-01             Navone M.         Shapovalov D.             1   \n",
       "68244  2025-07-01           Djokovic N.             Muller A.             1   \n",
       "68245  2025-07-01             Bublik A.              Munar J.             0   \n",
       "68246  2025-07-01             Goffin D.           Hijikata R.             0   \n",
       "68247  2025-07-01          Fucsovics M.          Kovacevic A.             1   \n",
       "68248  2025-07-01             Cazaux A.             Walton A.             1   \n",
       "68249  2025-07-01            Tseng C.H.              Vukic A.             0   \n",
       "68250  2025-07-01         Kecmanovic M.          Michelsen A.             1   \n",
       "68251  2025-07-01          Mochizuki S.           Zeppieri G.             1   \n",
       "68252  2025-07-01              Giron M.      Ugo Carabelli C.             1   \n",
       "68253  2025-07-01             Gaston H.             Mensik J.             0   \n",
       "68254  2025-07-01              Fritz T.            Mpetshi G.             1   \n",
       "68255  2025-07-01            Cobolli F.           Zhukayev B.             1   \n",
       "68256  2025-07-01            De Jong J.            Eubanks C.             1   \n",
       "68257  2025-07-01             Clarke J.              Evans D.             0   \n",
       "68262  2025-07-02                 Bu Y.          Nakashima B.             0   \n",
       "\n",
       "       Predicted  Probability     Result  \n",
       "68195          0     0.268098  ✓ Correct  \n",
       "68196          0     0.275337   ✗ Failed  \n",
       "68197          1     0.685398  ✓ Correct  \n",
       "68198          0     0.240102   ✗ Failed  \n",
       "68199          0     0.360912  ✓ Correct  \n",
       "68200          1     0.751155  ✓ Correct  \n",
       "68201          0     0.484618   ✗ Failed  \n",
       "68202          0     0.429620   ✗ Failed  \n",
       "68203          1     0.795220  ✓ Correct  \n",
       "68204          0     0.266239   ✗ Failed  \n",
       "68205          1     0.897215   ✗ Failed  \n",
       "68206          1     0.814956  ✓ Correct  \n",
       "68207          1     0.982424  ✓ Correct  \n",
       "68208          1     0.744967   ✗ Failed  \n",
       "68209          0     0.360020  ✓ Correct  \n",
       "68210          0     0.265524   ✗ Failed  \n",
       "68211          0     0.371042  ✓ Correct  \n",
       "68212          0     0.356450   ✗ Failed  \n",
       "68213          0     0.069562   ✗ Failed  \n",
       "68214          1     0.792940  ✓ Correct  \n",
       "68215          0     0.056571  ✓ Correct  \n",
       "68216          1     0.730104  ✓ Correct  \n",
       "68217          0     0.049540  ✓ Correct  \n",
       "68218          1     0.611982   ✗ Failed  \n",
       "68219          0     0.209271  ✓ Correct  \n",
       "68220          0     0.221172  ✓ Correct  \n",
       "68221          1     0.736240  ✓ Correct  \n",
       "68222          1     0.552807   ✗ Failed  \n",
       "68223          0     0.031518  ✓ Correct  \n",
       "68224          1     0.588140   ✗ Failed  \n",
       "68225          1     0.827861   ✗ Failed  \n",
       "68226          0     0.014851  ✓ Correct  \n",
       "68227          1     0.739525  ✓ Correct  \n",
       "68228          0     0.237376  ✓ Correct  \n",
       "68229          1     0.714695   ✗ Failed  \n",
       "68230          0     0.049540  ✓ Correct  \n",
       "68231          0     0.191161  ✓ Correct  \n",
       "68232          1     0.645908   ✗ Failed  \n",
       "68233          0     0.053707  ✓ Correct  \n",
       "68234          1     0.702877  ✓ Correct  \n",
       "68235          0     0.404810  ✓ Correct  \n",
       "68236          1     0.775881  ✓ Correct  \n",
       "68237          0     0.264163   ✗ Failed  \n",
       "68238          1     0.850964  ✓ Correct  \n",
       "68239          0     0.241240  ✓ Correct  \n",
       "68240          0     0.128128   ✗ Failed  \n",
       "68241          1     0.646269   ✗ Failed  \n",
       "68242          1     0.708137   ✗ Failed  \n",
       "68243          0     0.138167   ✗ Failed  \n",
       "68244          1     0.981145  ✓ Correct  \n",
       "68245          1     0.834141   ✗ Failed  \n",
       "68246          0     0.347395  ✓ Correct  \n",
       "68247          1     0.796674  ✓ Correct  \n",
       "68248          1     0.547537  ✓ Correct  \n",
       "68249          0     0.259092  ✓ Correct  \n",
       "68250          0     0.330384   ✗ Failed  \n",
       "68251          1     0.651035  ✓ Correct  \n",
       "68252          1     0.892478  ✓ Correct  \n",
       "68253          0     0.071988  ✓ Correct  \n",
       "68254          1     0.832148  ✓ Correct  \n",
       "68255          1     0.740478  ✓ Correct  \n",
       "68256          1     0.594326  ✓ Correct  \n",
       "68257          0     0.248331  ✓ Correct  \n",
       "68262          0     0.171233  ✓ Correct  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "PREDICCIONES FALLIDAS:\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68196</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Fery A.</td>\n",
       "      <td>Popyrin A.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68198</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>Rune H.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68201</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Garin C.</td>\n",
       "      <td>Rodesch C.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68202</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Borges N.</td>\n",
       "      <td>Cerundolo F.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68204</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Darderi L.</td>\n",
       "      <td>Safiullin R.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68205</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Berrettini M.</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.897215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68208</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Bergs Z.</td>\n",
       "      <td>Harris L.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68210</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Royer V.</td>\n",
       "      <td>Tsitsipas S.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68212</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Brooksby J.</td>\n",
       "      <td>Griekspoor T.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.356450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68213</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Bonzi B.</td>\n",
       "      <td>Medvedev D.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68218</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Riedi L.</td>\n",
       "      <td>Tarvet O.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68222</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>Bautista Agut R.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68224</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Etcheverry T.</td>\n",
       "      <td>Pinnington Jones J.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68225</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Halys Q.</td>\n",
       "      <td>Holmgren A.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.827861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68229</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Loffhagen G.</td>\n",
       "      <td>Martinez P.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68232</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Medjedovic H.</td>\n",
       "      <td>Ofner S.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68237</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Basilashvili N.</td>\n",
       "      <td>Musetti L.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.264163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68240</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Rinderknech A.</td>\n",
       "      <td>Zverev A.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68241</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Arnaldi M.</td>\n",
       "      <td>Van De Zandschulp B.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.646269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68242</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Humbert U.</td>\n",
       "      <td>Monfils G.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68243</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Navone M.</td>\n",
       "      <td>Shapovalov D.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68245</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Bublik A.</td>\n",
       "      <td>Munar J.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68250</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>Kecmanovic M.</td>\n",
       "      <td>Michelsen A.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date           PlayerA               PlayerB  WinnerBinary  \\\n",
       "68196  2025-06-30           Fery A.            Popyrin A.             1   \n",
       "68198  2025-06-30          Jarry N.               Rune H.             1   \n",
       "68201  2025-06-30          Garin C.            Rodesch C.             1   \n",
       "68202  2025-06-30         Borges N.          Cerundolo F.             1   \n",
       "68204  2025-06-30        Darderi L.          Safiullin R.             1   \n",
       "68205  2025-06-30     Berrettini M.          Majchrzak K.             0   \n",
       "68208  2025-06-30          Bergs Z.             Harris L.             0   \n",
       "68210  2025-06-30          Royer V.          Tsitsipas S.             1   \n",
       "68212  2025-06-30       Brooksby J.         Griekspoor T.             1   \n",
       "68213  2025-06-30          Bonzi B.           Medvedev D.             1   \n",
       "68218  2025-06-30          Riedi L.             Tarvet O.             0   \n",
       "68222  2025-06-30  Bautista Agut R.             Norrie C.             0   \n",
       "68224  2025-07-01     Etcheverry T.   Pinnington Jones J.             0   \n",
       "68225  2025-07-01          Halys Q.           Holmgren A.             0   \n",
       "68229  2025-07-01      Loffhagen G.           Martinez P.             0   \n",
       "68232  2025-07-01     Medjedovic H.              Ofner S.             0   \n",
       "68237  2025-07-01   Basilashvili N.            Musetti L.             1   \n",
       "68240  2025-07-01    Rinderknech A.             Zverev A.             1   \n",
       "68241  2025-07-01        Arnaldi M.  Van De Zandschulp B.             0   \n",
       "68242  2025-07-01        Humbert U.            Monfils G.             0   \n",
       "68243  2025-07-01         Navone M.         Shapovalov D.             1   \n",
       "68245  2025-07-01         Bublik A.              Munar J.             0   \n",
       "68250  2025-07-01     Kecmanovic M.          Michelsen A.             1   \n",
       "\n",
       "       Predicted  Probability  \n",
       "68196          0     0.275337  \n",
       "68198          0     0.240102  \n",
       "68201          0     0.484618  \n",
       "68202          0     0.429620  \n",
       "68204          0     0.266239  \n",
       "68205          1     0.897215  \n",
       "68208          1     0.744967  \n",
       "68210          0     0.265524  \n",
       "68212          0     0.356450  \n",
       "68213          0     0.069562  \n",
       "68218          1     0.611982  \n",
       "68222          1     0.552807  \n",
       "68224          1     0.588140  \n",
       "68225          1     0.827861  \n",
       "68229          1     0.714695  \n",
       "68232          1     0.645908  \n",
       "68237          0     0.264163  \n",
       "68240          0     0.128128  \n",
       "68241          1     0.646269  \n",
       "68242          1     0.708137  \n",
       "68243          0     0.138167  \n",
       "68245          1     0.834141  \n",
       "68250          0     0.330384  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df, failed_df = analyze_predictions(\n",
    "    df=first_round,\n",
    "    y_true=first_round[\"WinnerBinary\"].values,\n",
    "    y_pred=pred,\n",
    "    y_prob=prob,\n",
    "    date_col=\"Date\",\n",
    "    player_a_col=\"PlayerA\",\n",
    "    player_b_col=\"PlayerB\",\n",
    "    true_col_name=\"WinnerBinary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69d1122e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJsCAYAAABgcDW0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAeRJJREFUeJzt3Qm8TWX////PMc+zZMgUIhKSORLRbQwpFQkpUbdE7rqbEHXLmAaklFBJKpESoaKQsUE0KMmQIjOZ9v/xvr6/tf/77LMP+1hnPq/n43GcY+2111577bX3vj7rc32uKyYQCAQMAAAAAHzI5OfOAAAAAEBgAQAAACBRkLEAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWSFYvvviinTx5kqMOAACQzhBYAAAAAPCNwAIAAACAbwQWAAAAAHwjsAAAAADgG4EFAAAAAN8ILAAAAAD4RmABAAAAwDcCCwAAAAC+EVgAAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWAAAAAHyLCQQCAf+bAaI84Uaf4lABAACch8CgLJaakbEAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPAtXQUWd955p7Vt2zaqdefNm2e1a9e2NWvWWGo3efJkt687d+5M0sfRYwwZMiTWsjNnzrjHb9++vdWtW9et41m8eLHdfPPN1rBhwzRzLAEAAJA0Unww3MOHD9ubb75pS5cute3bt9vp06etRIkS1qhRI+vatasVLlzYUpvQxrVky5bNihUrZldddZX16tXL8ufPbylJwdWuXbuC/8+ZM6fly5fPLr74YmvQoIG1bt3a8ubNG9W25s+fb1OmTLF27dpZrVq1LFOm/4tFt23bZg8//LBVr17dHnjgAXcMypUrl2TPCQAAAKlbigYWapzee++9rhHctGlTd1U8S5Ys9s0339gbb7xh77//vo0bN841XlObSpUqucBHDh48aCtWrLDXX3/dVq1aZTNmzLCsWbOm6P4p0OnXr5/7+8SJE/bnn3/a2rVrbfTo0TZ16lQbMWKEXXnllbHuo+eQOXPmWMv0fPLkyWOPPvqoxcTEBJdrWwoCBw4caJUrV06mZwUAAIDUKsUCi+PHj9uAAQNsz549LnhQhsLTsWNH69y5s/Xt29c1XJXRSG2ZiwsuuMBatWoV/H+XLl3c8/n888/t008/tebNm8f7vBU86Scp5c6dO9b+Se/evV1AcP/997vjOnPmTLvooouCt2fPnj3Odvbu3euyG6FBhbdclAkBAAAAUqzG4r333rPffvvN9dEPDSo8l156qbvi/vfff9v06dNj3aYMwfDhw61Zs2buvqqt+P777+N9rHfffdc6depk9evXt+uvv95lFgKBQJz1Dhw4YGPGjHGZE3UZ0vaVlXjttdeiek716tVzv9WlS1SvoG5Teg5Dhw61Fi1auO5SCqZENRPKBGi59k2P+/zzz7vgI5Jjx47ZqFGjrGXLlq6uoXv37rZ69WpLiCuuuMIFQEePHrVXX3013hoL1Ut4dRPKKOlv73b9Vt2FqIuU/h9tbQsAAADSpxTLWCxZsiSYnYiPGqtq6Gvd++67zy07deqU3XPPPbZp0yZ3Rf6yyy6zH374wWU3ItU2KIgYO3as67qkQEWNdnVVKliwYJx1H3zwQVu3bp0LQipWrGj//POP/fLLL+4q/2233XbO5+QFFAUKFIi1XI+rjIvqLxQc5MqVyzXWFRioxuSGG26w0qVLu8d55ZVXbOPGjfbCCy/EyWo8/vjjrsZB+6LA4J133nFdySZMmOAKq6Ol4/b000+7rk/xUb3EsGHDXLep/fv3uyyHlCpVyurUqeNqYvSj5Xq+ek4AAADIuFIssPj5559dd53QrjjhcuTIYWXLlrWffvrJNaTVeFXdhYIKdeu56667YjWEFUAUL148uOzQoUOuga7b1EDW9ryARY35UGrgf/XVV2754MGDz7n/CnDU4PYyKOoC9fbbb7t6hCZNmsRaV0XTTzzxRKxlqnVQJmP8+PHBjI26fz3zzDMuQ6OiaWVXQqn+4aWXXgrWbyhboP1VFkOPHS0VWiuQ0XE9cuSIex3CKRBSAKLMkgKs0G5VqnlREKXA4uqrr3bF9gAAAMjYUqwrlBryaoSfi9fo1fqybNky18C+9dZbY62nBnZ4A3nlypUuQ6EGuxdUeIXN1113Xax1VV+gBve3334b1bCu2rbqKPSjrIvqRMqXL2/PPfecFSpUKNa6XpF36BCun332mV1yySVxuoHdfvvtLiuh5xnulltuiVUU7j2PX3/91WVWEsI7VgosAAAAgDSbsVBQ4QULZ+M1fL0gZMeOHVakSJE4QYmCgpIlS7oshUfrirIe4RQEhFKDXd161PVKmQDdrtoBXZFX159w1apVs7vvvjv42MqUXHjhhRGfQ5kyZWL9X5kKZWDC90HUnUvPz9v3UJGGc/W2ofUTMtyrd1wjZSsAAACANBNYqHuQ6hnUpSa+7lDKNuhqvLraJEcffmU9FEgsX77c1Tt88skn9tZbb9m1115rTz31VKx1VVcQbV1DaLYkNdDwsyqcVwBDYAEAAIA03RVK81aI+vDHR3UGqmXw1hVlJf7666842Q41lsOv8mtdUXASbuvWrREfU41t1TaoJmLBggVuBKZFixbZd999Z4lFheNq0EfaB9Vr6Pl5+x4qUncnbxuR1o+PnpeOV6TRuAAAAIA0FVio8a5MheZS+OKLL+LcvnnzZjf0qhrh3bp1Cy5XYbQmZtP9Qql4ObxeQBkF1U7Mnj071hCuf/zxhy1cuDDWuro9fJhX1XJodCivwZ9YVEOhYWe3bNkS57lrCFjVYChzEmmEq5MnT8Z5HupqFW03KGViVA+iwEb1HAAAAECa7gqVM2dON4qThkvVULLXXHONm2NBjXllB3RVXd2fNHqSsgge1T9oXoopU6a4DIVGKFIDffHixW4oVAUdHk3epjoIjbzUs2dPN7KRggcN06qgRvcLnQVc82EoO6JuWpoUTpkOBSzKBtSsWTNRn7+GoNWs1oMGDXJdsLQ/6hqm7EitWrWsTZs2ce6j53bHHXe4LIpqNObMmeNGbHrggQfirKsgS8dQlJ1QFkRzUiiwUHG5Zt7W8QIAAADSdGAhusquWbXfeOMNN3Sp5lXQ1XoVQd90001uNKXQoMIrslYmQ8OyaoZrzXGhyfS0TAGE5ocIpW0oiFGGQ+toJCUtU/G35mnwaLmCFjW8NSKTMgNFixa1Dh06uPkmErtOQsXeyk5MmjTJPvzwQ1d0rn3o0aOHm+8i0szcmmRPwcS0adPc+hUqVHBzW3gT84VSNuOxxx5zfytro5oQBUyacbt169YucAIAAAASS0wg0hTUQBKJGX2KYwsAAHAeAoNSNCeQemssAAAAAKQfBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL6l7sFwke5MzjfVTQKoiQ4BAACQfpCxAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMC3mEAgEPC/GSDKE270KQ4VgAQJDMrCEQOANICMBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWAAAAADJGYHH8+HEbNWqUtW7d2urUqWNt27YN3jZ79mzr1KmT1a9f32rXrm07d+60yZMnB/9OKD/3Tcvie95btmyxu+++25o2bepu13qyf/9+e+yxx+y6665zy++8884U2nMAAACkBik269CaNWusT58+8d6eOXNmW7Vqlft72rRpNmvWLOvWrZtVqFDBcufOHdzGyJEjrUmTJta9e3fLkiWLFSxY0DKyefPm2dChQ2Mdxzx58tiFF15oVatWtVatWlmNGjWi2tapU6ds8ODB7rdeq7x581rFihXdbePGjbNFixZZz549rWTJklaoUKEke04AAABI/VJ8OtOWLVtaw4YN4yzPlOn/T6YowFBA0b9//1jreIGHrpznz58/uLxXr152++23W7Zs2RK8P37um5p06dLFLr30Ujtz5owdPnzYfv75Z1u6dKm98847Lsvw+OOPW9asWc/6vHfs2OF+7rvvPrvpppviHPt69epZ7969k/V5AQAAIHVK8cCicuXK7ir62ezdu9eKFSsWZ/lff/3lfocGFaLMhX7Oh5/7pibKSjRv3jzWsoEDB9oTTzxhH330kcv6PPTQQ2d93jrukY6vd1uk5QAAAMiYMqX2bj3qv6+r5uvWrXN/62fIkCHut24Xb7nXzz++egFduX/++efthhtusAYNGlizZs3clfqFCxcG1znbfSdMmGDXX3+9q+dQo/2///2v/f777xH3+auvvrLp06db+/bt3fodO3a0+fPnR3ye6tKlbIz2R/ul+wwbNszVMezbt89lBh555JGI91VXsCuvvDKqmpAcOXK4Y6euS++9916s+4Q/bx1L73iqa1X4sQ8EAu75eMu91wIAAAAZU5bUUJitBnQ4XT2vWbOma2CPHTvWChQo4Przi7pFqYj73XfftfXr17t15Gz9/A8dOuSCiK1bt7oGvIKL06dPu+Lk5cuXuy5Z8VFQocfevXu3tWvXzsqXL++yJW+//bbrPqQAonjx4rHuowDmn3/+cQGFuhdpXTXKS5UqFavGYc6cOfa///3PLrjgAleEru3ocT7//HP7448/7JJLLrHGjRu7bkx6Dqpz8Gj7yj7oWJQoUSKq463uT8oQTZkyxb788kv3mJHo+V5++eX2yiuvWIcOHdxrEXrs1f1My3SbVK9eParHBwAAQPqU4oGFrpR7Iw2FatSokY0fP941xCdOnOiChtAuU5UqVbLVq1e7wOJcXam8hr6CCmUZ1NgPpTqEs5k0aZLLmqiRrcf1aHQq1TJo/xU0hDpx4oS99tprwToGBTPKRLz11lvBwEKBw+jRo61s2bI2derUWEGDRmLy9kv7u2TJEhdEdO7cObiOlinYUBYlIbwC7N9++y3edZQlUXCn56ygIfzYK7BQ5iOaYw8AAID0L8UDC13xDq8FkMQc3UkN9I8//tjKlSsXJ6gILxQPpy4/H374obs6r6xCaHYlZ86cVq1aNVu5cmWc+ykACC2O1n1Lly5t27dvDy5bvHixnTx50hVAhwYV4ftVt25d14ifO3durMBC/1edw9VXX20J4Y2qdeTIkQTdDwAAAEi1gYUa22o4JyUFAwcPHnS1Dgn1999/24EDB1zwECkAii8wUSAQTkGAujl5vCBD3Z3OJiYmxmU7XnjhBdd1S+urtmPt2rUuYxIawETDCyi8AAMAAABI84FFaqeMhaiuQHNlRCu+LIi3vYRSbYe6XClLobkl3n//fbethHaDkh9//NH9LlOmzHntCwAAAJAhAwsVfufLly/YoE4IdclSNyVd5U/szIqyNfLDDz+cs5FfpEgRV8StOot7773XjcikblgXX3xxgh5TXa8WLFjgJs47nwwOAAAAkOaGm00syh5o1CcVb2uY1YRkEXRfTSj33XffuZqISDQk7PlQQbe6MWmEJo08da79UnZCXbqefPJJ27NnT4KzFRqBS0XmKkRXrUn4SFYAAABAms1YbN682V1Bj0RFybly5UqUx9EoS5pbYvjw4W7WaA2lKqpZOHXqlJs4Lj79+vWzjRs3ugnlPvnkE7vssstcQLBr1y5bsWKFValSJc6oUNHQpH+atE5zUahWonXr1q6xr6Dh008/dSMvhdZfKMOg21VMruPSokWLeLe9YcMGNzKVgpPQmbdVM/Kvf/3LPS4AAACQbgILTU4XOkFdKM1TkViBhbpCaehUDeuqBrZ+VLyskaJuuumms943T5487n4zZsywRYsW2Weffea6EmmkJw0dez51Dh7Np6EhdTU07Ztvvum6KhUtWtRNehc+27iyJyri1vC3KiQ/27HRtkT7qfUUkDRt2tQFL15QBQAAACSWmMD5VhMjRUybNs2effZZF+ikxUnpYkafSuldAJDGBAal+DUwAEAUMkSNRXqhLlvvvPOOm/06LQYVAAAASL+4DJQGqNj6m2++cXUX+nvEiBEpvUsAAABALAQWacC6dets6NChbthczdKtEa4AAACA1IQaCyTvCUeNBYAEosYCANIGaiwAAAAA+EZgAQAAAMA3AgsAAAAAvlG8jWQ1Od9U69Gjh5u5HAAAAOkHGQsAAAAAvhFYAAAAAPCNwAIAAAAAgQUAAACAlEfGAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL7FBAKBgP/NAFGecKNPcagQFBiUhaMBAEA6QcYCAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYpBF33nmntW3bNsm2P2/ePKtdu7atWbMm1vIdO3bYwIEDrXnz5u72IUOGuOXHjx+3UaNGWevWra1OnTpJum8AAABI/VL97FRq6Pbp08f69+9v3bp1S5HHDpUzZ04rXbq0tWrVym666SbLkiV1HcLwfc6UKZPlzp3bihYtalWqVLGWLVta/fr1LSYmJqrtDR061H788Ufr2bOnFS5c2EqVKuWWT5s2zWbNmuVekwoVKrjHAAAAQMaVulrFqZQa4w0bNjRNUr5371774IMPbNy4cfbrr7/aww8/bKl9n48ePWrbtm2zZcuWuX1XhmHkyJGWN2/e4PoKlFq0aGFZs2YNLjtx4oStX7/ebrzxxjhB3apVq1xAoYAPAAAAILCIQuXKlV3D29O5c2e74YYb7L333rO+fftawYIFU/0+y4ABA2zChAk2c+ZMFxDpb0/mzJndT6h9+/a5wCRfvnxxtq8Aq1ixYkn4DAAAAJCWpJsai3Xr1rlGfpMmTdyV+ltvvdU1/CP55JNP7Oabb7YGDRq4GoEXX3zRXYFXDYFqDc5F3aGqVavmGt2///57cPmZM2fs5Zdftt69e7uMQb169dz2n3rqKdu/f3+sbezcudM93uTJk+3zzz+32267ze2P7vfMM8/YqVOnzrkf2maPHj3cc169evU511fgoOCiRo0a9sUXX9iGDRvirbFQLUWbNm3c31OmTHG3ecdHv1V7oWPuLdfzAAAAQMaVLjIWn332mT3wwAOuBqBr166WK1cu+/jjj2348OGuAdyvX7/gulquq/WqFVAAoMb2/PnzXeM+IbyAIvRq/smTJ2369Ol2zTXXuMZ+jhw5bNOmTTZ37lzXiJ8xY0asrkayYsUKe/vtt61Tp07Wrl07+/TTT9021E1JdQ3x0fO69957XTcnBUaXXHJJ1Pvevn17tz/Lly93QUYkHTt2tEqVKtnYsWOtadOm7kdUXzJs2DC3vECBAsF9rFixYtSPDwAAgPQnzQcWp0+ftqefftplEVRQrCJlUV3AXXfd5ZZpxCI1iJUFUG2Eui5puRcUqFuTMhjx0QhIyg54NRZz5syxLVu2WNWqVa1MmTLB9bJly2YfffSRCyhCVa9e3QU5qnG49tprY922detWe+utt6xEiRLu/wowVBSuwuj4AovNmze72oY8efLY1KlTg/eNlhcEqO4iPtrnIkWKuABCtRSh3aqUrZk4caIVKlQoTncrAAAAZExpvivU999/b7t373ZX+72gQpQZUPcidU9SFsBrkP/555+ui09opkEZDl2hj4+6+Wi4VQUFXbp0sdmzZ7sr+GPGjIm1nkZa8oIKBTyHDh1yAcmVV17pln377bdxtn311VfHCgy0DXUtUgCjbEQ4ddlSwKT7qNtVQoMK8UZwOnLkSILvCwAAAKTLjIVqFaR8+fJxbrv44ouD3YZCf4dmGTyRlnk6dOjgAgtlPH766Sd77bXXbM+ePZY9e/Y46y5atMh1eVJGI7xO4uDBg3HWL1myZJxl+fPnd78PHDjggp7QYmplKvRclTEIz4xEywsoGCIWAAAAiSXNBxbJQd2o6tat6/5WYbjqEu644w578sknXWG2Z8mSJfbQQw+5LlKDBg1yoyape5SyJqqHUFeqcJpnIj7h6yvLotGeVBvx4YcfuoDnfGheCilbtux53R8AAABId4GFd8VftQrhvGXeOl63oUi1BWerNwh3+eWXu9oCzQmhrlH6vyxYsMBlMdR1KjSboPkuEoMm49Ns1wpeFNQoI6KhbxNKxeRekAQAAAAkhjRfY6Er+BdeeKEbBvWvv/4KLlejW6MrqWZBIzSJZp5WQbJGgQrtlqRahnfeeSdBj6uMhUaUCh1m1cs+KEMRmnVQLURiUXChLEmzZs3cJHdvvPFG1PdV3cf48ePdiFBe5gUAAADIUBmLr776yv755584yzXk6eDBg91ws927d3fdg1SXoFqHb775xs3zoK5MXqP8vvvus0ceecStq2FXFRwoKFFdg2owFIhE46KLLnIzVatLkmanrlmzpmvsqztUnz593PwVCm5UOK5RpRKTnseIESPcbxWQK2DQMLuhVKiuDIqEzry9a9cuN7+G7g8AAABkuMBCE7rpJ1LRtYZ/feGFF1xmQFkKzSeh+gEFENdff32s9a+77jrXIH/ppZdctkFDpirA0BCsCk4iFWTHR8PBLly40CZNmuS2pcnt1Ih//fXX3SR3mouicePGds8997igIzEpINJ8EnouykLoOSuI8mi/9KMsiobiVb1HrVq13D5qIj4AAAAgMcUEIlUUZ0AayUkN9FdeecUuu+yylN6ddCtm9LlnFEfGERiUZq5tAACA9F5jkVC6sq+uQ6GUZdDcFOoOpZoNAAAAAAmT4S4Xqo7i3//+t6uP0ChRKvjW6E5a/uCDD7qJ9QAAAAAkTIYLLFTsXa1aNVd0/ffff7tahQoVKrg6CM2sDQAAACDhqLFAsqLGAqGosQAAIP3IcDUWAAAAABIfgQUAAAAA3wgsAAAAAPiW4Yq3kbIm55vqJvJj9C0AAID0hYwFAAAAAN8ILAAAAAD4RmABAAAAwDcCCwAAAAC+EVgAAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL7FBAKBgP/NAFGecKNPcajSuMCgLCm9CwAAIBUiYwEAAADANwILAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAID0E1jUrl3bhgwZkioe98yZMzZ58mRr37691a1b163jWbx4sd18883WsGFDt3zNmjVJun/z5s3z9Th+7382Om6hxwYAAAAZV5LOdKXGbJ8+feK9PXPmzLZq1apEeay2bdvarl27gv/PmTOn5cuXzy6++GJr0KCBtW7d2vLmzRvVtubPn29Tpkyxdu3aWa1atSxTpv+Lv7Zt22YPP/ywVa9e3R544AHLli2blStXLkH7+c8//9j7779vn3zyif3000926NAht6+lS5d2jXQ9ZtmyZRP47AEAAICUlSxT6LZs2dJd4Q/nNdgTS7Fixaxfv37u7xMnTtiff/5pa9eutdGjR9vUqVNtxIgRduWVV8a6z4oVK1yAE0rBTp48eezRRx+1mJiY4HJt6/Tp0zZw4ECrXLlygvfv999/twEDBtgvv/ziApZbbrnFihQpYkePHrUffvjBBRwzZsxwgc0FF1xw3scBAAAASJeBhRrhrVq1SvLHyZ07d5zH6d27twsI7r//fhcQzJw50y666KLg7dmzZ4+znb1797rsRmhQ4S0XZUIS6vjx43bfffe54GLUqFHWtGnTiNmM119/Pc7jAgAAAKldsgQWfrz33ns2e/Zs+/XXXy1LlixWrVo1FyzUqFEj6m1cccUVLlMwfPhwe/XVV10mwqPuR23atHH1AuFdt7z6Ad2uLIJH3ZWkePHiroYh2ueh59CjR4+IQYUX5Oj2aOzfv9/VgXz22Wcu4ClcuLA1btzY7rrrLitQoECc9ZVp0fraX61fpkwZ91jKJoVauXKlzZ071zZt2mR//fWXZc2a1apWrWo9e/Z0xxEAAABIscBCV+vVEI7z4FmyuC5H8ZkwYYK99tprrmHbt29f12Xo3XffdY3nMWPGWKNGjaLeB2Uynn76adf1KT6qlxg2bJjrNqX9VZZDSpUqZXXq1LGlS5e6Hy1X4z1XrlxRP/6SJUvc7+uvv978Onz4sGvob9++3QU5yght2bLF3n77bfvqq69s2rRpLnsT6tlnn7Vjx47ZDTfc4P6vAEP1IuoypvoUj5YfOHDAHS91LduzZ48LNHT8J02aZDVr1vS9/wAAAEh/kiWw0JVy/YRTYDB+/PiI99HV/enTp9vll1/uGrS6cu41zDt37mwjR460+vXrx6mPiI8KrVUgrYLpI0eOxGl4i676q0Gt7IK6JYV2q1LBthryCiyuvvpqK1GiRAKOgNnPP//sHrNkyZJxMgkq4A6VI0cO9xMfBQ6//fab/ec//3HHwlOpUiUXPCkYu/vuu2PdR4HSm2++GQzkFGB06dLFxo0bZ9dee23w8R555BFXTB6qU6dOduONN9orr7xCYAEAAICUCyw6dOhgzZs3j7O8YMGC8d7n008/tUAgYLfddlswqJCiRYu6K+xvvPGGu0p/6aWXRr0fXjARX2CRlJRlUKF2OBVyq4Efqn///tatW7d4t7Vs2TJ37HRcQ3Xs2NGNZqXgJzywUCARmh3S3woYnn/+eVeD4hXXhwYVyhApo6HgTV3Qvv322/N45gAAAMgIkiWwUKZA80EkxM6dO91vDRcbzlu2Y8eOBAUWCigkuYMKryGv4CKcMhhq3MuPP/4YbwYn/NhUqVLFdSULpf/rWG/evDnOfSINYesNlavj6FFxufZHtRbhmRSKygEAAJBmi7cTi668q/uQsgYpEVgoGFq3bp1rxId2h1KGwAu6ou3WlVSUoVBhvGoxNAlghQoV3LFSQKGid9VvAAAAAKl65u1wXuNbtQnhtm7dGmudaCxYsMAFFwkp+E5M11xzjfut+g2/9Lw1Wd+pU6diLdf/FTxFOi6qWYnUDcvbnqxevdrN/aHidBXIN2vWzOrVq+cCHwUbAAAAQJoLLDR0qq6Uq4A7tAGtIVA1cpGGer3kkkui2pZqCFSkrKvvt99+u6UEFZ2rO5Kej2og/GjSpIn9/fffcYIU/V/LIw1nqxGjQrti6e85c+a4+Tq8YWS9jIlqW0KpWxT1FQAAAEjxrlDq86+MQSQaYSnSsK1qhKuAWSMcqXuORi7yhpvV7yeeeCJO1yHVUHiPo+yEghDNTaHAolChQm7mbQ0dmxI06pLqJzSfxgMPPOAa88oGaCQq7bcyCosWLXLPScO8nk337t3tk08+cSNAqYBdAZZ+a1hYzU+hgvdwGh5X9/OGllVwtnv3bjcKlDcilOYG0f5oP3ft2uVm/9aM4Dqm6halEbUAAACAFAssFi5c6H4iUaAQ33wQ//73v90s2Zog77nnngtO1qaJ7iLNp/DHH3/YY489FpxsTo1p1TZoxu3WrVu7q/MpSUGNMhbvv/++CwxmzJjhMgeqs9DzbN++vfuJVGgdXgj+8ssvByfI0/YUEGiUJ3VhilRDcu+999qGDRvcsdy3b58r8tZxvO6664Lr6PjoOGv+kFmzZrmhcDVHxjPPPOOCFgILAAAAxCcmEN7vBUhCMaNj14Ug7QkMyjBjPgAAgPRQYwEAAAAg7eDSow8nT560AwcOnHM9TWaX0kPJAgAAAEmJwMKHjRs3Wp8+fc65nmogSpQo4eehAAAAgFSNwMKHSpUqBWfNPhsVVgMAAADpGYGFD/ny5QvOmg0AAABkZBRvAwAAAPCNwAIAAACAb3SFQrKanG+q9ejRw012CAAAgPSDjAUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMC3mEAgEPC/GSDKE270KQ5VGhMYlCWldwEAAKQBZCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWAAAAAHwjsAAAAACQugOL2rVr25AhQ5LyIaJ+3DNnztjkyZOtffv2VrduXbeOZ/HixXbzzTdbw4YN3fI1a9ZYanf8+HEbNWqUtW7d2urUqWNt27ZN6V0CAABABpbgma/U6O7Tp0+8t2fOnNlWrVpliUGN5V27dgX/nzNnTsuXL59dfPHF1qBBA9eozps3b1Tbmj9/vk2ZMsXatWtntWrVskyZ/i+m2rZtmz388MNWvXp1e+CBByxbtmxWrly5qPfx999/t2nTptm6dets9+7d7v6FCxe2qlWruv0PDWASkx5z1qxZ1q1bN6tQoYLlzp07SR4HAAAAiMZ5T6nbsmVLd4U/nNdgTyzFihWzfv36ub9PnDhhf/75p61du9ZGjx5tU6dOtREjRtiVV14Z6z4rVqxwAU4oBTt58uSxRx991GJiYoLLta3Tp0/bwIEDrXLlygnat02bNtmdd95pWbJkcUFO+fLl7Z9//rHt27fbypUrLVeuXEkWWOj5KKDo379/kmwfAAAASJbAQo3wVq1aWVLTlfjwx+ndu7cLCO6//34XEMycOdMuuuii4O3Zs2ePs529e/e67EZoUOEtF2VCEkoZEHVJev31161SpUpxbv/rr78sMemxFMToR/utoAsAAADIsMXb7733nt16660u49GkSROXkdiwYUOCtnHFFVfYgAED7OjRo/bqq6/GW2Ohrlte3YS6Velv73b9Vt2FqIuU/p+QWoXffvvN8ufPHzGokCJFigT/3rlzZ6zHC6Vluk3reLz9+/vvv23o0KHWokULu+qqq+zDDz90y3fs2OG6X3nPx9uuMiUPPfSQqyXR8b366qvd8VUgFomyK9q+grd69erZdddd5wK277//Pk52ZtCgQdasWTOrX7++dezY0V5++WU7depU1McLAAAA6VcWP1fP9+/fH3eDWbK4LkfxmTBhgr322muuBqFv374uMHj33XftrrvusjFjxlijRo2i3gc1hp9++mnX9Sk+qpcYNmyY6zal/VWjWUqVKuWKnpcuXep+tLxAgQKu+1K0tA3VaCxZssSuueYaSwoKClSz0atXLzt27Fjw+YwdO9btb8+ePd16FStWdL/nzZtnBw4ccMdGGY09e/bY3Llz3bGeNGmS1axZM1awcPfdd7vgQIGIalcOHjzoApaNGzdalSpV3HrLly939SfKCnXt2tVld7755hsXzPzwww82cuTIJHnuAAAAyACBhRqVka6+KzAYP358xPv8+uuvNn36dLv88stdIzdr1qxu+fXXX2+dO3d2DVRdDQ+vj4iPCqVLly5tP/30kx05ciRiAbMa5WpkK0ui+ofQblUq2NYVewUWurJfokSJBBwBc4191ToMHjzY7YeelwImZVMSUgB+NmrsP/HEE7GWVatWzSZOnGiFChWK003skUcecUXuoTp16mQ33nijvfLKK8HAIhAIuKzIyZMnXSG4F5hIjx493ChaomOmx/ceU4Gjt03dZ9y4ccGsEAAAADKu8w4sOnToYM2bN4+zvGDBgvHe59NPP3UN2ttuuy0YVEjRokVdF6Q33njDtmzZYpdeemnU++EFE/EFFklJgcmMGTPczxdffOGyBfoRNeAff/xxl9XwQxmChAgNKpQNUsG7AjUFBt9++23wNh3nrVu3BgOE+IrwFTipnkOZk8OHD8daR12tFFhoHQILAACAjO28Awtdodd8EAnh1RDoKnw4b5lqBxISWCigkJQablUjM3n1HKrhUC2Duh6tX7/eFZYr6AgNohKqTJkyCVpfw98+//zzrtbi0KFDsW4LLVxXpkYuueSSs27vl19+cb/V/So+XgE8AAAAMq7zDixSA12NVwG1iqRTwzwOxYsXtzZt2rihZ++44w5Xp/Ddd99ZjRo14oxGFUrD3cYnR44cUT++MhQaMUu1GJrwz5vfQo+tAvevvvoqwc9JGSbRsLbxFakr4wQAAICMLVkDi5IlS7rfP//8c5wuQuqWE7pONBYsWOCCi4QUfCcHNeTV9UiBhYqnQ4ezVXF0OGVpEsPq1avdPB+PPfaYG+UqlOojwjNOouLrs/HWUxerhGaoAAAAkHEk63CzjRs3do1uFXCHDlOq+R5Um6Ar/ufqmuNRlyP179cV+dtvv91SgrobRRpuVSNm6TbRpHmi/VQhubIGXhbA67q0bNmyRNkfr+g9dPvefobWV4iyD9q3999/3wV64bxtqJheReLKeGi0qUjP1euOBgAAgIzrvDMWmzdvdhmDSDTCUqRhW8uWLWvdunVzw82qy861114bHG5WvzX6UPiIUGq0eo+j7ISCEI1CpMBCDV7NvO23QPp8achXNbYVMKnbkbot/fHHH/bRRx+5LlrqEqXlHo3MpMzBv//9bzd/h57LnDlzXH2Jhn71S12uFLxoVC7Ve1xwwQUuI6Hjp/3Q6FkeBXgqLtcwtN27dw8ON6u6DA03q4CiS5cuLlOheS40h4UKvZUJ0bCzWk+jfGlErVGjRlG8DQAAkMGdd2CxcOFC9xOJAoX45oNQo1oN09mzZ9tzzz3nCps1ROvw4cNjzbHgUUNdXXu8GbU1d4MawCqMVsNds2mnFM19oZGuNLmf5rLQqEmaw0ONeDXWwyfb0zKto4a+AiMNSfvoo4+6yegSI7DQsdAx1Vwhs2bNcrUbmiH9mWeecQXloYGF6LhrqFlNdLd48WIX5Oj4armCFI+CDK2nH03Qp0n71LVLAZ0mOow0qhQAAAAylphAeL8ZIClPuNHM1J3WBAal6TEeAABAeqyxAAAAAJA+cSkyjGaijlSkHGkiwGhnCAcAAADSOwKLMBoitk+fPuc8cBpNqUSJEkn1ugAAAABpCoFFGA3Dqpmrz0WjLwEAAAD4PwQWYTTaERPBAQAAAAlD8TYAAAAA3wgsAAAAAPhGVygkq8n5plqPHj3cxIgAAABIP8hYAAAAAPCNwAIAAACAbwQWAAAAAHwjsAAAAADgG4EFAAAAAN8ILAAAAAD4RmABAAAAwDcCCwAAAAC+EVgAAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOBbTCAQCPjfDBDlCTf6FIcqTGBQFo4JAABI88hYAAAAAPCNwAIAAACAbwQWAAAAAHwjsAAAAADgG4EFAAAAAN8ILAAAAAD4RmABAAAAwDcCi2Q0b948q127tq1ZsybW8h07dtjAgQOtefPm7vYhQ4a45cePH7dRo0ZZ69atrU6dOta2bdvk3F0AAAAgaszMdZ4UHPTp0yf4/0yZMlnu3LmtaNGiVqVKFWvZsqXVr1/fYmJizrmtoUOH2o8//mg9e/a0woULW6lSpdzyadOm2axZs6xbt25WoUIFt3258847bd26dcH7Z86c2QoWLGg1a9a0Xr16uXWT0rJly2zLli121113JenjAAAAIO0gsPBJAUTDhg1NE5gfPXrUtm3b5hreH3zwgcsyjBw50vLmzevWbdWqlbVo0cKyZs0avP+JEyds/fr1duONN7oAItSqVatckNC/f/84j5stWzZ75JFH3N///POPff/99y4jsmLFCnvttdesbNmyllT0/ObPn09gAQAAgCACC58qV67sAoZQAwYMsAkTJtjMmTPt4Ycfdn97mQX9hNq3b58LSvLlyxdn23v37rVixYpFfFxtJ/RxO3ToYOXLl7fRo0fbW2+9ZYMHD/b71AAAAICoUWORBNToV3BRo0YN++KLL2zDhg0RayxUS9GmTRv395QpU9xt+vHWU+2Fujx5yydPnnzWx73yyivd7+3bt8e57eOPP3bdpBo3buwyLN27d7fFixfHWW/58uWuq1WzZs3ceqrveOCBB1wmRnSbshXi7Ze3zwAAAMi4yFgkofbt27ugQo11BRnhOnbsaJUqVbKxY8da06ZN3Y+ULl3ahg0b5pYXKFDA1V5IxYoVz/p4v//+u/sdnv144YUXbOrUqdagQQNXF6J6kKVLl9qDDz7oMhvqhiVr1661+++/3y6++GLr0aOH5cmTx/766y9bvXq1C1bKlCnj9kUZFnXf0j56qlevnghHDAAAAGkVgUUS8gIB72p/ODXGixQp4gII1VKEdm2qVq2aTZw40QoVKhSnq5Vn//79wdGjNm/ebGPGjHH//9e//hVcR8sVVChQ6NevX3B5ly5d3EhUzz//vMtKqDD8008/tTNnzrhlelzPHXfcEfy7Xr169tFHH7nAIr79AgAAQMZDYJGEvFGcjhw5kujbPnbsmBueNpSCFHWvatSoUXDZhx9+6EamUvDgBSIedYtSMPHNN9+4gEEZClmyZIldf/31liULpwcAAACiQ8sxCXkBhRdgJKbs2bO7TIccPHjQjUKlUaTUTSnUL7/84pbdcMMN8W5LReKiLlEKNP73v//Zs88+a5dffrnrPqWRrzScLQAAABAfAoskpLkpJCmGflWdRN26dYP/V7H1fffdZyNGjHAjVYXWYyhjoZGpdJ9IVFMhqufQULXq5qQgRb8VvKho/JlnnqGOAgAAAPEisEhCc+fOdb81ulJSU9AwaNAg69y5s40fP97VSchFF13kRqa68MILrVy5clGNaOWN9OQFR127drWXX37ZBRcSzaR/AAAAyFgYbjYJnD592jXuNSKUgopII0IlBY0mdd1117lsgzfErVdgrUBD+xVfNygJr8Hwsi05cuRw3a08OXPmdL8PHDiQJM8DAAAAaQ8ZC5806tKCBQvc36Ezb+/atcsVRKtrUnLS6E8q2Fb3JY0qVbVqVTf3xIsvvmi33HKLK/guWrSoG0ZWs3Vrpu6VK1e6+w4fPtz27NnjulgVL17czei9aNEiVyui4m/PZZdd5ibhUy2GCsVV5K1RrEqWLJmszxUAAACpB4GFTwsXLnQ/6oqkK/maKbtWrVqu4FmFz8lNGQYFD5oQT/NSXHHFFS6wuPTSS+3NN9+0N954w40opeFkVVuh7lMeZTc00Z0Kwf/++29XdK7ZvEeOHOlqODx6blu2bHGP8cknn7ghah9//HECCwAAgAwsJhA+jBCQlCfc6FMc3zCBQcT3AAAg7aPGAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADAN8a5RLKanG+qm8Qva9asHHkAAIB0hIwFAAAAAN8ILAAAAAD4RmABAAAAwDcCCwAAAAC+EVgAAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL7FBAKBgP/NAFGecKNPpetDFRiUJaV3AQAAIEWQsQAAAADgG4EFAAAAAN8ILAAAAAD4RmABAAAAwDcCCwAAAAC+EVgAAAAA8I3AAgAAAIBvBBZpxJ133mlt27ZNsu3PmzfPateubWvWrIm1fMeOHTZw4EBr3ry5u33IkCFu+fHjx23UqFHWunVrq1OnTpLuGwAAAFI/ZvM6BzW0+/TpE2tZzpw5rXTp0taqVSu76aabLEuWLKl2fzNlymS5c+e2okWLWpUqVaxly5ZWv359i4mJiWp7Q4cOtR9//NF69uxphQsXtlKlSrnl06ZNs1mzZlm3bt2sQoUK7jEAAACQcaWeFnEqpwZ5w4YNTROV79271z744AMbN26c/frrr/bwww9bat7fo0eP2rZt22zZsmVuv5VhGDlypOXNmze4voKkFi1aWNasWYPLTpw4YevXr7cbb7zRBRChVq1a5QKK/v37J+vzAgAAQOpEYBGlypUru8a3p3PnznbDDTfYe++9Z3379rWCBQtaat5fGTBggE2YMMFmzpzpgiH97cmcObP7CbVv3z4XmOTLly/O9hVcFStWLAmfAQAAANISaizOk7pDVatWzTW8f//9d7fszJkz9vLLL1vv3r1dxqBevXquBuGpp56y/fv3x7r/zp07Xc3C5MmT7fPPP7fbbrvNGjRo4O73zDPP2KlTp865D9pmjx49rEmTJrZ69epzrq/AQcFFjRo17IsvvrANGzbEW2OhWoo2bdq4v6dMmeJu04+3nmov1q1bF1yu5wEAAICMi4yFD15A4V3RP3nypE2fPt2uueYa19jPkSOHbdq0yebOnesa8TNmzIjV1UhWrFhhb7/9tnXq1MnatWtnn376qduGuimpriE+atjfe++9rpvTiy++aJdccknU+92+fXu3P8uXL3dBRiQdO3a0SpUq2dixY61p06buR1RbMmzYMLe8QIECwX2sWLFi1I8PAACA9IfAIkoaBUkZAq/GYs6cObZlyxarWrWqlSlTxq2TLVs2++ijj1xAEap69eo2fPhwV+Nw7bXXxrpt69at9tZbb1mJEiXc/xVgqCBchdHxBRabN292tQ158uSxqVOnBu8bLS8IUN1FfLTPRYoUcQGEailCu1UpUzNx4kQrVKhQnO5WAAAAyJgILKKkrj7h3X10Ff8///lP8P8aackLKk6fPu2yCfp95ZVXumXffvttnMDi6quvjhUYaBvqWqRgQ/fPlStXnKLpwYMHW/ny5V3xuLIGCeWN4HTkyJEE3xcAAACIhMAiSh06dHBzOaj24aeffrLXXnvN9uzZY9mzZ4+13qJFi1yXJ2UzwuskDh48GGe7JUuWjLMsf/787veBAwdiBRYqplamQkGFMgbhmZFoeQEFQ8QCAAAgsRBYREm1BXXr1nV/axhX1Sbccccd9uSTT7ribFmyZIk99NBDrnvUoEGD3KhJ6h6lom7VQ6gbVTjNMxGf8PVVy6HRnlQb8eGHH7pg53xoXgopW7bsed0fAAAACEdgcZ4uv/xyV1+geSG6dOni/r9gwQKXwVCXqdBsgua6SAyaiE+zXSt4UUCjjIiGvU0oFZN7ARIAAACQGBhu1gdlLDSEq1d74WUflKEIzTpoCNrEouBCGZJmzZq5Se7eeOONqO+reo/x48e7EaG8rAsAAACQGMhY+HDRRRe52arVLUkzVKuxr+5Qffr0cfNXKKOg4WM1olRiUnAxYsQI93vMmDEuYOjatWuckaOUQZHQmbd37drl5tfQ/QEAAIDEQmDhk4aEXbhwoU2aNMllLtSIf/31190kd5qLonHjxnbPPfe4oCMxKVOi+SQUXCgLoTk0NFmeR/ukH2VRNJmf6j1q1arlJuDTRHwAAABAYooJRKooBpJIzOhzzyielgUGEasDAICMiRoLAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+Mag+0hWk/NNdRP5Zc2alSMPAACQjpCxAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMC3mEAgEPC/GSDKE270qXR1qAKDsqT0LgAAAKQKZCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWAAAAAHwjsAAAAADgG4FFKjNv3jyrXbu2rVmzJtbyHTt22MCBA6158+bu9iFDhrjlx48ft1GjRlnr1q2tTp061rZt2xTacwAAAGRkzO6VhBQc9OnTJ/j/TJkyWe7cua1o0aJWpUoVa9mypdWvX99iYmLOua2hQ4fajz/+aD179rTChQtbqVKl3PJp06bZrFmzrFu3blahQgW3/dtvv922bNliS5cutRw5csTazr333mtffvml207fvn1j3fbNN99Yjx497MYbb7TBgwe7ZQpiQmXNmtWKFStmV111lfXq1csKFCjg6xgBAAAgfSCwSAYKIBo2bGia5Pzo0aO2bds2W7ZsmX3wwQcuyzBy5EjLmzevW7dVq1bWokUL14D3nDhxwtavX+8a/AogQq1atcoFFP379w8u+/bbb93Pxo0brW7dusHlp06dsg0bNljmzJlt7dq1cfbTy5KEBxOVKlWyrl27ur8PHjzoHvONN95wv2fOnBlrXwEAAJAx0RUqGVSuXNkFDOqu1LlzZxs0aJDNnTvXbr31Vlu9erU9/PDDwXXV6M+ePbvLbnj27dvngpJ8+fLF2fbevXvjLPcCg/DgYdOmTXbs2DG3L/pb3ahCaX1lT2rVqhVr+QUXXODuo58uXbrYuHHj7Oqrr7atW7faZ5995vPoAAAAID0gsEghCiAGDBhgNWrUsC+++MJlEiLVWKiWok2bNu7vKVOmuNv0462n2ot169YFl0+ePNkuv/xyy5IlS5w6DQUOuXLlcgHNyZMng4/pZTOU4VD2I5ruTcq0yPbt2xP1uAAAACBtoitUCmvfvr1r4C9fvtwFGeE6duzouiKNHTvWmjZt6n6kdOnSNmzYMLdcgYBqJqRixYqWM2dOq1q1qn333XcuQ6H/e4GFgg4FD6rT0P/r1asXK5sR3g0qPr///rv7HSmLAgAAgIyHwCKFKRAQ1V1EUr16dStSpIgLIBQQqDuSp1q1ajZx4kQrVKhQrOWiAEEZCP0oePAyEiq4FnV3Cu0q5f19xRVXxNkH3Xf//v3u70OHDrni79mzZ7vsh7pEAQAAAAQWKUyjOMmRI0cSdbsKLF5++eVgVsLLSHj1E/o9ZsyYYEZD66muI7y+QlauXOmGuQ2vG3nwwQddUAMAAAAQWKQwL6DwAozEokxHtmzZgnUWChw09Oyll17q/q8Awhsl6sorrwzWV0Tq2qTMyN133+0KyHfv3m2vv/667dmzx9VxAAAAAELLMIVpbgopW7Zsom5XI0spIFDAoCFuFVgo2PCCgfLly7vaDC1XUHO2+gqtFzpsreo8NDrUf/7zHzeHRvhcGQAAAMh4GBUqhWnYWdE8F4lNgcLp06dd8KAAI7Sbk4aVrVmzpstoePUV0RZu58+f32UwNCKVshcAAAAAgUUKUYN//PjxriuSgopII0L55QUK06dPdxmJ8MJs/f/777+3zz//PN76ivioWLxkyZI2Y8YMO3z4cKLvOwAAANIWukIlg82bN9uCBQvc36Ezb+/atcsVVo8YMSJJHveyyy5zXaI0z4V+awjaUAokFOB8/fXXVqVKFcuTJ0/U21aXqh49etjw4cPtzTfftDvuuCMJngEAAADSCgKLZLBw4UL3o6yARmAqVqyYa9S3bNnSGjRokGSPmzVrVjdvhWb3Vr2FirlDecXaBw8ejDjM7Llo4r6XXnrJZs6c6WouEhKYAAAAIH2JCWioHyC5TrjRp9LVsQ4MIjYHAAAQaiwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWAAAAAHxjrEwkq8n5prqJ9TTHBgAAANIPMhYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+BYTCAQC/jcDRHnCjT6Vqg5VYFCWlN4FAACAdIGMBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWAAAAAHwjsEgC8+bNs9q1a9uaNWtiLd+xY4cNHDjQmjdv7m4fMmSIW378+HEbNWqUtW7d2urUqWNt27ZNit0CAAAAkgyzg52DgoM+ffoE/58pUybLnTu3FS1a1KpUqWItW7a0+vXrW0xMzDkP9tChQ+3HH3+0nj17WuHCha1UqVJu+bRp02zWrFnWrVs3q1Chgtu+3HnnnbZu3bqI29JjPvvsswl5rQEAAIAkQ2ARJQUQDRs2NE1UfvToUdu2bZstW7bMPvjgA5dlGDlypOXNm9et26pVK2vRooVlzZo1eP8TJ07Y+vXr7cYbb3QBRKhVq1a5gKJ///5xHjdbtmz2yCOPxFmuwAYAAABILQgsolS5cmUXMIQaMGCATZgwwWbOnGkPP/yw+1syZ87sfkLt27fPBSX58uWLs+29e/dasWLFIj6uthP+uIlJ+3Ts2DHLlStXkj0GAAAA0j9qLHxQo1/BRY0aNeyLL76wDRs2RKyxUC1FmzZt3N9Tpkxxt+nHW0+1F+ry5C2fPHlygvZDgcFzzz1n7du3d12klF157LHHbNeuXbHW0/54j/vWW29Z586drUGDBjZ9+nTbuXNn8LEXLVpkt9xyi8vQXH/99fb++++7++/evdsGDx5s11xzjTVu3NgeffRRO3LkiJ9DCAAAgHSCjEUiUINeQcXy5ctdkBGuY8eOVqlSJRs7dqw1bdrU/Ujp0qVt2LBhbnmBAgVc7YVUrFgx1v33798fZ5vqdqXA5tSpU3bPPffYxo0brVmzZta1a1f77bffbM6cOa6L1WuvvRYnG/LGG2/YgQMHXNCgWo/Q2/Uc3nnnHbvhhhtcdmXu3LluH9Wt6/nnn7crr7zS+vbta5s2bXIBh7pqKcAAAABAxkZgkQi8QEB1F5FUr17dihQp4gII1VKEdm2qVq2aTZw40QoVKhSxy5OyERpFKtzbb79tZcuWddkHBRWq2wit0ahbt67dd999LpPxxBNPxLqvMg+6vx7To4yF/PLLLzZ79mwrXry4+79qRTRalTIg2r4CF8+hQ4dcjYlGuqIrFQAAQMZGYJEIvFGckqJbUPbs2V1AEu7CCy90v5cuXepGqurRo0es2xs1auSyJJ999pmdOXPGreNRoBAaVIS6+uqrg0GFFCxY0MqUKWNbt251heehlJ3R4ysoUcAEAACAjIvAIhF4AYUXYCQmBQTKPsRHjXqNEBWpKPziiy+2H374wXWlCg0k1AUrPiVLlozY7UoZF3V7CuU9prpVAQAAIGOjeDsRaG4KUdektCBHjhzx3haa2YhmuTeyFAAAADI2AotEoAJn0ShKyU0Zhj///NPVO4RT9yVlUVQYDgAAACQlAgsfTp8+bePHj3cjQimoiDQiVFJTTYRqKF599dVYy1esWGFbtmxxw8KeLdsAAAAAJAZqLKK0efNmW7Bggfs7dOZtzRVRr149GzFihKWEtm3b2vz5823atGmu3qJWrVq2fft2N+qThpLt169fiuwXAAAAMhYCiygtXLjQ/ejqf86cOd3cD2rEazI6TTKXUrJkyeKGlH355ZfdxHYapUnF1prTQvNNeKNHAQAAAEkpJkDlLZJRzOhTqep4BwYRWwMAACQGOt8DAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwbxR7KanG+q9ejRw7JmzcqRBwAASEfIWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWAAAAAHwjsAAAAADgW0wgEAj43wwQ5Qk3+lSKHarAoCwp9tgAAADpHRkLAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAAILAAAAACkPDIWAAAAAHwjsMgA1qxZY7Vr17Z58+al9K4AAAAgnWJg/xTw+++/27Rp02zdunW2e/duy5YtmxUuXNiqVq1qbdu2dUEAAAAAkJYQWCSzTZs22Z133mlZsmSx1q1bW/ny5e2ff/6x7du328qVKy1XrlyJHljUqlXLVqxY4R4TAAAASAq0NJPZlClT7Pjx4/b6669bpUqV4tz+119/JdpjHTlyxHLnzm2ZMmWy7NmzJ9p2AQAAgHAEFsnst99+s/z580cMKqRIkSKx/r9q1Sp77bXX7LvvvrMTJ05Y6dKl7YYbbnA/odSFqnjx4nb//ffbc889Z9988417nPfff9/VWPTp08cef/xxt54nEAjYnDlz7L333rNffvnFBSCXXnqp9e7dO07WZP78+fbWW2+5/T916pTrunXZZZfZwIEDrWDBgol6jAAAAJD2EFgks1KlStm2bdtsyZIlds0115x13Xfeeceeeuop14Dv2bOn5cyZ0wUa//vf/2zHjh3Wv3//WOv/8ccfdvfdd1vz5s3dto8ePXrW7T/22GO2cOFCa9asmQs4Tp48aR9++KH169fPnn76aWvSpIlb74MPPrAhQ4ZYzZo1XYCi7IceS92r9u3bR2ABAAAAAovk1qtXLxccDB482GUfLr/8cle0fcUVV1i5cuVidYkaPXq0tWjRwkaMGBFc3rlzZ7d85syZ1qlTJxeoeBRsPPLII3b99defcz+WLl3qgoj//ve/1rFjx+DyLl26WI8ePWzMmDHWuHFji4mJsWXLlrkuVRMnToxVp6EgAwAAABCGm01m1atXtxkzZlibNm3s8OHDbghYZSAUMKgLkkaMksWLF7uuT+3bt7f9+/fH+rnqqqvszJkztnr16ljbVten0K5OZ7NgwQIXLFx99dWxtq190vZ37tzpuj1Jnjx5XF3I8uXLXfcpAAAAIBxdoVJAhQoVXNci2bVrl61du9bmzp1r69evdzULCjx+/fVXd3vfvn3j3Y66IYUqWbKkZc6cOap90PZV3K2MyNm2X6ZMGZfB0NC4gwYNcsGLRplq2LChXXvttS44AQAAAAgsUpgKrpW90NCzd9xxh23cuNEVanuZgaFDh8Yp6A4NJELlyJEj6sfV9lV0PXz48HjXufjii91vddmaPXu2y5B89dVXLsjQ/SZPnuxGuQrtjgUAAICMicAilVAtQ7Vq1VxgsWfPHrvooovc8gIFCljdunUT/fG0fXV1UmG45s44F03i16hRI/cj6hZ13333uVqP//znP4m+fwAAAEhbqLFIZpoET8O1hlMNg24TTZqnbkZqzCsroNvCqRZCNRjnSxkS1WloaNpI9u7dG/xbtRfhKleu7H4fOHDgvPcBAAAA6QcZi2Q2duxY1xjXiEuqtVD3JQ3d+tFHH7kMghr8Wi4PPvig63Kkwu5WrVq5blN///23/fTTT26kJnVPKlGixHnth4akVaG35qbYvHmzK9hWdkTZkq+//toVkavuQzT8bN68ed1ws8WKFbNDhw65onNlWbRfAAAAAIFFMtMEdp9++qlt2LDBzWWhzINGXVIw0b1791ijOrVr187VN6iYW3NaqEGvxr8KqjVfhSap80MT5mkivHfffddeffVVN4+FtqlshIIJjybjW7RokdsHBUUq4L7kkkvckLnhE+kBAAAgY4oJMH4okvOEGx23G1hyCQwijgYAAEgq1FgAAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwb2R7KanG+q9ejRw7JmzcqRBwAASEfIWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWAAAAAHwjsAAAAADgW0wgEAj43wwQ5Qk3+lSSHarAoCy8DAAAACmEjAUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7CA07ZtW7vzzjvjHI3Zs2dbp06drH79+la7dm3buXOnW75mzRq7/fbbrXHjxm75vHnzOJIAAAAZGDOKnSc1rPv06WP9+/e3bt26RVxHDe5GjRrZ+PHjTfMQfvjhh/b555/b999/b3/++acVKFDAKlWqZL169bJq1ar52r5HwcG6deuC/8+ePbvlzZvXypcv79Zv166dFSlSJOrnOHLkSGvSpIl1797dsmTJYgULFrSDBw/aAw88YBdccIHdd999liNHDqtevXqURw4AAADpEYFFMjlx4oQ99thjLpBo0aKFlShRwv766y975513rEePHjZ06FBr1apVojxWtmzZ7JFHHnF/nzx50vbt22cbN260yZMn27Rp0+y///2vtWzZMtZ95syZYzExMbGWrVq1yv3WfufPnz+4XNs6dOiQPfroo3bNNdckyj4DAAAgbSOwSCaZM2d2Dfsrrrgi1vIOHTrYjTfe6LIO1113nWXKlClRHitSkPLTTz+5DIgChWLFilmNGjViBSPhFPhIaFARujxfvny+9xUAAADpA4FFch3oLFniBBVSuHBhq1Wrli1dutRlFqLtpnQ+KlSo4IKKfv362YsvvmgvvPBCrBqL4sWLu+Wqo1CXKY+6UIn2c9euXe5H1FUrtNsUAAAAMi4CC5+OHz9u+/fv97WNPXv2WNasWV0tRFJsP1TdunVdALF27Vo7duyY5cyZM846qqMYNmyYvfvuu7Z+/Xr3txQqVMjtz4oVK9xt6sJVrly5RNs3AAAApF0EFj6pe5N+ztfy5cvtu+++c12XVGid2NuPL3OhrMOOHTvc3+EUbGh/Vq9e7QKL8G5Vqq9QYKEgxctmAAAAIGMjsPBJNRLNmzePeJu6HJ3Nb7/9Zo8//rgbXWnAgAGJvv345MmTx/0+fPjwed0fAAAACEdg4VPp0qXdlfuEUrbg7rvvdn9PmDDBdT9KzO2fjRdQeAEGAAAA4BeBRQpQcbQKn1XjoALqSN2RkpJGh1IxecmSJZP1cQEAAJB+MfN2CgQVd911l8saPP/881a5cuVkfXzNTaH6Co3wFKlwGwAAADgfZCySkRr0ylSo+FlBRZUqVZI9U6ERnjTPRehQsQAAAIBfBBbJ5MiRI64xr4zFTTfdZNu2bXM/oVRLoXkt/Dp9+rQtWLDA/X3q1KngzNtffPGF5ciRw4YPH27Vq1f3/TgAAACAh8AimRw4cMAVbMusWbMirjNp0qRECSxOnDjhJsLzZtTW/Bjly5d3gY0mwkvKSfgAAACQMcUEAoFASu8EMo6Y0aeSbNuBQcTJAAAAKYXibQAAAAC+EVgAAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPjGwP9IVpPzTbUePXpY1qxZOfIAAADpCBkLAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbzGBQCDgfzNAlCfc6FOJcqgCg7JwyAEAAFIRMhYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAADwjcAiGc2bN89q165ta9assZRy5513Wtu2bVPs8QEAAJA+pfpZxtQI79OnT6xlOXPmtNKlS1urVq3spptusixZUv3TOKd9+/bZ9OnTbcWKFbZz507LlCmTlSpVypo2bWo333yz5cmTJ6V3EQAAAIhXmmmRt2zZ0ho2bGiaKHzv3r32wQcf2Lhx4+zXX3+1hx9+2NKyr7/+2gYMGGBHjhyxf/3rXy5YOnPmjAuqXnzxRZfpePbZZ61MmTIpvasAAABA2g4sKleu7DIUns6dO9sNN9xg7733nvXt29cKFixoadFff/1lAwcOtNOnT9vLL79sVatWjfUcly9fboMGDbL777/fZs6caTly5Ih3W9rGyZMnz7pOUlBAlDt37mR9TAAAAKQuabbGQt2hqlWr5jIYv//+e3D5jz/+6BrizZo1swYNGrjG+bRp01yjO5paA3VDUh3E5MmTg8uUOdAyZQ7ef/99u/HGG61+/frWpk0bt+1I3n33XevUqZNb7/rrr7fXX3/d7Ws4dX/6+++/rV+/frGCCk+jRo1cV6ht27bZ3Llz49RrrFq1yl566SVr3769e76LFi1ytx88eNCGDx/ujoO2oef7/fffx3s8N23aFDxu2ueOHTu6QOfUqVMRj5uO+eDBg+2aa66xJk2axLtdAAAAZAxpJmMRiRdQ5MuXL9g4VsNXNRcKKAoXLmyff/6560akgEMNbT/mzJnjaiHatWtnefPmtQ8//NBtu1ixYnbdddcF11MQMXbsWKtUqZILGI4fP24zZsyImFVZsmSJZc2a9awF1R06dHABiNZVN6lQzzzzjGv8ax1lDdRdSv+/55573PFQlueyyy6zH374wWV28ufPH2f7yoo88MADdtFFF1nXrl3d8fzmm29ccKX7jRw5Mtb6R48etbvuusuqV6/utqljAgAAgIwtzQQWapzv378/WGOhRv6WLVvcVX6v9mD06NGuK9Arr7xiFStWdMvUEH/ooYfso48+cgFBnTp1znsfdu/ebW+//XawkFpZAmUtZs2aFQwsDh06ZC+88IKVK1fOpk6dGuyWpMBBXbfCuxDt2rXLKlSocNbuSypUV9Dw008/RTwuCmRC7//OO++4oKJ3794uAPBonxTwFC9ePLjsn3/+sSeeeMJlfyZOnBgshFe2RcdQdSxexsZz4MABd7uCCgAAACBNdYXS1fPmzZvbtddea126dLHZs2e7EZPGjBnjbtdVcxVBN27cOBhUSExMjPXs2dP9vXTpUl/7oOAgdHQmNeaVDfjtt9+Cy1auXOka+8qYhDb2w7MaXmAh0Yz4pMDi8OHDcZYrWAkPSpYtW2aZM2e2W2+9Nc664bUQ6kqlQE3PTdtX8Ob9qFjeWydct27dzrnPAAAAyDjSTMZCXX0UWKibj67cv/baa7Znzx7Lnj17sDZCypcvH+e+ulKv4Vt37Njhax9KliwZZ5m6FukKvsd7jLJly8ZZN3zfvEZ+pIAhnIKQSAGIshnhtA9FihSJs362bNncc1BWxfPLL7+438OGDYv3sRV4hFKXLnUFAwAAANJcYKEGdN26dd3fupJeo0YNu+OOO+zJJ5+0p556KsHbUyYjkvAi71DKAiQmBRYXXnihK8xWliO+7lDbt293gcUVV1wR5za/I0B5BeX9+/d3NSGRFC1aNFEfEwAAAOlPmukKFe7yyy93hckaBWnjxo1WokQJt3zr1q1x1tVcF5oXIjTjoAJljZwULrGyGnrMcJH2Td25VBcyf/78eLepIXW9daPdBw1jG54JOXHiRJzn52U8NMqWArdIP5GyQAAAAEC6CCxEGQtlEVR/UahQITdK0WeffRaryFlX5FXMHd4wV8G3sgDffvttcJmCDxVC+6GGuLpnqQZEWQjPH3/8YQsXLoyz/m233ea6Uz3//PO2efPmOLd/+eWXbv4KBQAatjYaGv5VmRfdL5QKz726Do+GltWxe/XVV2N16fLoOYTfBwAAAEizXaEi0fCoLVq0cMO+rl+/3s3DoOFmNRqSN9yshlJV41yF06EjQqlmQ0PAaphVFYNryNdPPvnkrF2hoqFMyN13323jx493RePKqqhxrpGatL8aySq8m5EK0DVJXo8ePdx+qiBcQc7atWvdPqm7lEZzirYLkka/0jwaU6ZMcRkKBVx63MWLF1upUqViPUdlKoYOHeqOnUZ60n21n6rDUNZFBe+jRo2KNSoUAAAAkK4CC1HjXZmASZMmucyFhnjVb12dP3bsmOsWdO+997r5GUJpuYan1dCwuq+yBgoC1LAOHxY2ofRYarArY6BMhEaE0jIVU0cqkla9iIasVaCjQOjjjz92xeZq4Csrc8stt0Q1cpRHQZIeV3NcfPrpp27+i0svvdQtU8CjIW7Dsxaa6E8/CtI0YZ8CJAUhGlkqdJQtAAAAIJKYQKTpoIEkEjM69kze5yswKM3HxAAAAOlKmq6xAAAAAJA6EFgAAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPjGZABIVpPzTXUzjGsSPwAAAKQfZCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAACCwAAAAAJDyyFgAAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAAAAA4BuBBQAAAADfCCwAAAAA+EZgAQAAAMA3AgsAAAAAvhFYAAAAAPCNwAIAAACAbwQWAAAAAHwjsAAAAADgG4EFAAAAAN+y+N8EEJ1AIGDHjh2zgwcPWtasWTlsAAAAaUTevHktJibmrOvEBNTaA5LBX3/9ZUWLFuVYAwAApDEHDhywfPnynXUdMhZINtmzZ7caNWrYBx98YHny5OHII+jw4cPWunVrzg1ExPmB+HBugHMjeTMW50JggWSj9FnmzJldtEtggVCZMmXi3EC8OD/AuYGE4nMjZVC8DQAAAMA3AgsAAAAAvhFYINlky5bNevfu7X4DnBvgswN8r4A2R/rCqFAAAAAAfCNjAQAAAMA3AgsAAAAAvjHcLBLFr7/+ak8//bR9/fXXljt3bmvVqpX17dv3nDNsa37GadOm2ezZs23//v1WqVIlu//+++2yyy7jlcng54bOiRUrVti3337rzo3//e9/1rx582Tbb6TOc0MTbc6cOdNWrVplv//+uxu6umbNmnbPPfdY8eLFedky+OfGo48+6j4z/vzzT7duhQoVrFevXlavXr1k23ek3vMj1Ouvv25jx461Ro0a2fjx45N0fzMSMhbw7eDBg9anTx87deqUjRo1yr253333XfeGPRcFFZMnT7ZbbrnFxo0bZ0WKFHENBDUYkLHPDU2kqICiYcOGybKvSBvnxvfff29Lly51QeaYMWNswIAB9tNPP1n37t3t77//Trb9R+r83Dh58qTdeuut7twYNmyY5c+f3/r372/r16/nJUsn/JwfoRcopkyZYoUKFUrSfc2QAoBPU6dODTRq1Ciwf//+4LI5c+YE6tSpE9izZ0+89zt+/HigcePGgeeeey647MSJE4E2bdoEnnrqKV6XDHxuyOnTp93vHTt2BK644orAokWLknx/kfrPjYMHDwZOnjwZa9nu3bsDtWvXDkyfPj1J9xmp/3Mj3KlTpwKtWrUKDB8+PAn2FGn1/Hj00UcDjz32WKB3796B/v37J+HeZjxkLODbF198YXXq1HFXhjzXXnutnTlzxlauXBnv/ZTCPHLkSKzuLUpjNm3a1HWBQcY9N7xZU5F+ne+5kTdvXsuSJXYv3mLFilnBggVd9xdk7M+NcJkzZ3bnjDIZSB/8nh8bNmywTz/91O69994k3tOMiW9uJEpfx7Jly8Zapg9ydWvSbWe7n4Tft1y5crZ79247fvw4r04GPTeQ/iXmubFt2zbbt2+f++xA2uf33FDtnrrJqCvl9OnTbfv27daxY8ck3GOklfPj9OnTrjajR48ebn0kPoq3kSj9HfWmDqdluu1s99NkedmzZ49zP30xHDp0yHLkyMErlAHPDaR/iXVu6LNi9OjRVrRoUWvZsmUi7yXS4rkxd+5cGz58uPs7V65c9uSTT1r16tWTZF+Rts4PDQpy7NgxV4eDpEFgAQBIs1588UVbvXq1Pfvss5YzZ86U3h2kAldffbUbYVAZi8WLF9tDDz3kinwZCCJjU1ZTg8UMHTo0QaNHIWEILOBbvnz57PDhw3GWK+Og2852vxMnTtg///wTK2uh+8XExES8IoGMcW4g/UuMc0MjwWhkFw0xqj7XSB/8nhsFChRwP9KgQQN3FfuZZ54hsMjg58ekSZOsYsWKbnhqret1jdKP/q8LE+H1W0g4jiB8U1/H8H6NetNrOLfwfpDh9/P6R+vqkkfbuvDCC+kGlYHPDaR/fs8NDTmruU007GT79u2TcE+R1j83Kleu7Ap+kbHPD91n3bp1boCYcFo2YcIEF4jCHwIL+KY34iuvvOIifi/LoPSzRvU526RE6vOqiW20rhdYqOBODQZS1hn73ED65+fcWLNmjT388MN2/fXX2x133JFMe4y0+rmxceNGK1myZBLsKdLS+TFw4MBgpsKjuS/UY6Jfv34umwH/CCzgW6dOnWzWrFnuTduzZ0/bs2ePSztrFA4VVHruvvtu27Vrl7333nvu/3oza2QG9ZHWUJGaIVWFVQcOHLCuXbvyymTgc0M2bdpkO3fudP2kRbPpis6VK664IgWeDVLDufHLL7/YoEGD7KKLLnKz7X7zzTfBdXVulCpVihcqg54by5cvdxNraiZlDUGsLlAfffSRffnllzZixIgUfEZIDefHJZdcEmdbefLkcQX+tWvX5kVKJAQW8E19GidOnOiK4/RGVxZCVxI1G2Yory9jKM2Wq1FdZsyY4WbNVeZCRZg0DtIHP+fGW2+9ZfPnzw/+X+eI1KpVywWjyJjnhgJMdXvQT69evWKt26ZNGxsyZEiyPQekrnND3xuq23vuuefcBQnVWegqtAp2uRiRfvj5XkHSi9EsecnwOAAAAADSMSbIAwAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAADwjcACAAAAgG8EFgAAAAB8I7AAUsCePXssf/78NmXKlFjLb7/9ditbtiyviQ+aeTkmJsZ+/fXXZDmOr776apzHO3bsmJUoUcKGDh2aaOcG/L9Gy5Yt4zBmcH4/HziXMi6dMzp3dA4lp2XLlrnH1bl3PjZs2GCZMmWyTz/91JIDgQWQAh555BErWrSo9ejRI6r1d+/ebYMGDbJq1apZ3rx5LV++fFaxYkXr0qWLvfPOO7HWvfrqqy1Pnjzn/GJds2ZNxNv//vtvy5kzp1tn+vTp8W5HAZDW8X6yZcvmlt1xxx22fft2y8h0/B588EEbNWqU7dq1K0nPDWRsajToPZ1cgTRSnl5rveZ67ZMT51pc+/fvd69Far5oUaNGDbv++utt4MCBFggEkvzxCCyAZPb777/b1KlT7d5777UsWbKcc/1t27bZ5Zdfbs8//7zVq1fP/ve//9lTTz1lbdq0sc2bN9srr7ySqPs3c+ZM++eff6xcuXJuP8+mVKlSLvjQzzPPPGN169Z199Hvv/76yzKyXr16uYBr7NixSXZuIDrdunVzWaTGjRunu0Omxp4yYwQWGYdea73mKRFYZORzrUyZMu5zRBd/QgMLHZPUHFjIfffdZ2vXrrUFCxZYUuObC0hmkydPdg3Om2++Oar1R48e7brHvPfee9a+ffuI2YzE9PLLL1vTpk3dY+nDaOvWrVa+fPmI66rLTteuXYP/v/vuu+2CCy6w5557zgU8DzzwgGVUuXPnto4dO7r09fDhwy179uyJfm6ktNOnT7sgNFeuXJaaZc6c2f0AwPnSZ3OOHDnS5AG86qqrXI+CSZMmWevWrZP0schYINXz+rR+8sknNmzYMHfVQF1NdFV85cqVbh31HWzUqJFrzBUvXtyeeOKJiNtS958OHTpYkSJFXEPvkksusREjRtipU6dirbd69WpX71CpUiXXaFL3o4YNG9q7774bZ5taT/t34MCBYMNaHz5af9WqVXHWnz17ttWuXdutF40ff/zR/W7WrFnE2y+88EJLLOvWrXNXpbp372633HKLu2p+rqxFuJYtW7rfP/30U7zrfPjhh+6YTZgwIeLt9evXd92BTp48meDXIxLvNYpEy3V7uFmzZrlzSo+lx9T59vbbb1tC/Otf/3KZm6VLl0a1fnznxpkzZ9x5qivuer3V7ax06dLufNu7d2+sq2c69xTQRPLQQw+55xt6pVPn7X/+8x+rUKGCe0/ouCuwUUAZ6X24ePFi9/66+OKL3WO99dZb7vaPP/7YbrrpJheE6v1ZoEABa9GiRbz9eufMmeMycdqGnouu+mnbkfoSK3h58sknrWrVqm59bbtt27a2fv368+4Xn1ifK/qyVvdDvXeuueYa1w2xUKFC7j2kCwKhDh065K526jG8zyAdd3WbO3r0aJxtq9uCam20vrarn8suu8wee+wxd7u6YHhd5nQxwOuWGOl8Dvf111+7z8LChQu7Y3rppZfa008/7YJFP59vZ+t+uWnTJnexQsdS7yl9pm3ZssWtoy6dtWrVcq+BjumLL74YcVsvvfRScD1d2NA5tnz58jjr6T2jzK4yr9pfdSNVNjY+6rKo56dzUe8v1UjdeeedcV7DhIr2OOscilRfF96vX+etXmvRa++95rp/eH/8Z5991n1m6nH1W/+P7/w9V7/+8z3XvPNHn1P6W+e9PlPVNce7KKbXukqVKm4/K1eubHPnzo2znRdeeMG91iVLlnSvj84hXdSKlD3RsdV7Ve9pbbN69eru8zxSfU1Czu/w10LHSOeX6PPLOyZl/9/reLbaiPi+k/Tca9as6fbhoosuskcffTT4PRguIZ+Leix9N3/00Ud2+PBhS0pkLJBm6MtXHxj9+/e3EydO2JgxY9wHzWuvvea6nehL4NZbb3UNHX3x6g0fejX9gw8+cA0ufZGrr6G+/L/88ku3rhpaatR51GBVN6Mbb7zRfTjpQ3HatGnu/vpyUqM7nN60apRpe1pfXWB0ZeCXX35xH6Tyxx9/uC/Sf//731E/bzXgRA0MfSnH10AOF19XpEgNmNBshRovnTp1co0pdbfS81bDS8VfCQmE9AUSH71uaiDrtQs/Frq/GnZanjVr1vN+PfxQ408N+euuu859Qem5ax86d+7ssjH9+vWLajsKkLwvGG3rbM52buh8V72GXhdlkvTafPXVV+71UqNKKW592eqLpV27du7Lad++fe4cD21o6VjpS1Z9bkVfpg0aNLDffvvNevbs6b6g1MDSl7gaswrEdbxDqdZHX3S9e/d2tT4KzkVfnnrM2267zXWR27Fjh2sEqvGowEpXzDz6klfwonP78ccfdwGsXs958+bFee56LB27L774wnVpuueee9x+6/2gL//PPvvMBWMp9bnidWHT89Trc8MNN7ggQwG5jp9eJy+j4x0TrecF7gpe1NBUY2DhwoWxtqvnq9dMr8XDDz/sXl+9DxTg6j2p81+vlxpm//3vf13jLPQzIz7aryZNmrj3l85lvRd17BVgbty4MWIDPJrPt3NRsKXPF+3rn3/+6Y61tqv32ODBg13DTuehzuu77rrLNcIV2Hm0fzpWderUcQ0qBWp67mro6pxv1apVcN3777/fdc9UMD5gwAAXIOi5Rsq+6vzXe1Wvv15zHT9dGJk4caI7d3W8FMQk1Pkc53PR89Hx0/PXuem9r4oVKxZrPQURarjrOOr1eeONN9xni96jes8l1Pmeax69h/W5oPNWx1YXlRRwabvapo67GsdarvfQDz/8EGy0e5l7dQXWc9Dn2rfffuveS0uWLLFvvvnGBW4efUboyrzOC31e6Vzr27dvrO0lxvmtYzBu3Dh3fnnPRc5W43g2+o7RZ4MCE+2HPh+U+VfbJTE+F3WOKyuu74xzfR/5EgBSuVdeeUXVRoGaNWsG/vnnn+DyuXPnuuVZsmQJfPXVV8HlWufCCy8M1KtXL7js2LFjgWLFigWuuuqqwMmTJ2Ntf+zYsW47S5cuDS47fPhwnP04cuRIoFKlSoEqVarEWt69e3d3/7vvvjvW8rfeesstnzRpUnDZkiVL3LJnnnkm4nPVtsqUKRNr2c8//xzIly+fu99FF10UuOWWWwLjxo0LrFmzJuI2mjRp4tY910/oMfOOUYECBdw+eN577z237oIFC+I8jvazcuXKgT///NP9bN26NTB16tRA/vz53WvyzTffBM5m0KBBbtvfffddrOWPPPKIW7527drzej0ef/xxd/9ffvklzmsUiZaHPmc9rpY99NBDcdZt3759IG/evIGDBw/GOT9DHy+UjkWbNm0C53K2c+PMmTOBo0ePxln+0ksvufvMmjUruGz+/Plu2fPPPx9r3cWLF7vlY8aMCS7797//HciRI0dgw4YNsdb99ddf3fMMPS7e89Qx17EPF+k12r17d6Bw4cKBf/3rX8Flev+VKFEicMEFFwT27dsXXH7o0KFAuXLl3GPoscLfnx999FGsbR84cMC9H3S+n4u376Hv8cT4XPHeB1pf78lQ3n4/9dRTsbZx4sSJOPvnnfOrVq0KLtNrqmVdu3YNnD59Otb6of+P9NzOpUGDBoHMmTMHNm7cGOsc69y5s9uWzpXz+XyLj/ee1PtAj+PRua7lOtd+++234PI9e/YEsmfPHujSpUtw2ebNmwMxMTGBhg0bxnq9duzY4T5z9DqcOnUq1rrXXHNNcJn33tby8Pdru3btAkWLFg1s37491n7r9ddx0v6fz/FOyHHWeRz+2S/aT60bug967PD3SfhtefLkifV8dMyuvPJKd16HLtdjRnoPRXqM8znXvPOnb9++sZYPGDAg+J2m97JHx0rLH3zwwXN+vnifaSNHjgwu+/bbb92yli1bxnqffP3114FMmTLF+90Qzfkd6bWItCya1yn8O0nnqY6FPi/1ferZv39/oHTp0onyufj555+7+4wePTqQlOgKhTRDV7N0VdbjXanR1bzQyFzr6IqWd+VcFi1a5K4IK5Wr7iK6mu/9eFe51JXDoyvCoVf4dQVDv9XV4fvvv7eDBw/G2T9dtQildSV0P3TlREKvJJ+LrrDp6pZ3lfz11193j6XnrKvPulodTld+9Jwj/ejqRiTqiqBjo6uKHh0bXcWJrzuUrp7qdv1oP3W1UZkKXT1U14Oz8R5HV4Y9aufPmDHD3VfdHfy8HudLVxGVFdL+hZ4n+lE2QFdJlemKll7raLpTnO3c0P6o64fo6rp3DnvnWGjKXlfedPUy9LiK/q8rYLr67h1rPVddAVX3gtDnqeOtq4Oh74nQ92GkmorQ10ipdr1GqmvQ+zN0/3S+7ty503UFKFiwYHC5rvL16dMnznZ1Pqh7xBVXXBFrH3V1+dprr3VX31RQmRKfKx5lbnRFNJT+r+Wh3fW0DS8Lp+6XGoFNz6V58+ZuWehx8q5m60pteLYw2uxhJDoXdZVT57I+P0LPMWVFJFIXw2g+385FV5tDM67esda+qNuHR58nyoSFblufKTpnldkIfb3UZUmf6xrkwusC4q2rrEVobY0+U3TOhNJV3vnz57t90Odm6DmmK8fKcEd6HyTVcU4sep8rQ+DRMdNrqPMuUmYwqSnbHsp77ZXh1PvEo2Ol/4efV97nizKves30+qgrpTJJoe8bvZaiDGTo+0RdCL1uupEkxvntx9q1a91oijqXQ7P9en6J9bnoZXX8du87F7pCIc0IT2F7jZJI6U3dFtr3XI1PUcM3Pgo8PHrjqTuMvqAivQnVsAv9MIy0f96bOHQ/vC/VhA75pi84dcHRj9LR+tDQSEz6glB3pe+++y5Wg1Rfpl5jJVyk/sii7gf6QteXUWh9hLqFqJuYPrTCuzdpv7z5Frx+yfoijoYXPKgBpbS+vgSUvlU/VnV3CHU+r8f50rmi10cf2tGcK+eibUXTfe1c54a64qjriBpP4X1u1UD1eMGDUvnqTqC+1UeOHHGBo15Lr8uEAhmdm2o06XWPJFIDVtuL5Oeff3YNJnXn0esR6bmJuhaI14UqVKRlej30BRnfPorOzdCGaXJ9roRuI7SxK6qf0PLwWhV1M1M3Db1n1UiK73VUg0b9yMO7uPjlHX91e4vUtUOvefg+R/v5ltjHWsFCNPvtLdN+Kxj09j/Se1jdq0IDBXU/1Ougzz/9RLPfSXmcE4vXVSn8uUtSPm5Svc/U5UndqBREHD9+PN73zbk+X1TfF83+nc/57cfWc5yzifG56H23RNud+nwRWCDNiG9Ul2hGe/HeUOqn7vUvD6dGsbeuGmB64+qqh76odNVAj6P+jsoYhDcIzrYfoQ1F70NA/VzPlxob6uuvHzUgtT8aQi6833dC6MNYfYm1r/E1HHWFJPyqk64ixRfARENXq7RNfWloO7qqruMY+lzO9/UIFd8HaXjRvvd4Wl9fQPG9ppEaC/HRl97ZPvyjOTcUFKgwWlfM1W9cXxa6uqrshfrKhj9/HVcFFjqeGpFK91cWITQb5Z2XOu7q8x2tSNkKbVuZDwUwej11dVD9ktV4UgGtXt/zpf3U9s42bG80xzcpPlcSSs9B9V06n3X1Xp85CkhUe6EMzrnO45QUzefb+W4jMbZ9vrzH0GdO6PsjlJctTEoJ+YxKi4/r57VXnZLeM7popeHWFYx4cy1pLqfEeN8kxTkYc5YGvN/jez6fi953i5/Py2gQWCBD0GRy0TaENYqHuh6peCp85mQVi/nhNUgTK72q7ipqWKth4oca6N4INCoQDadsgbpDhQcWfqmAVUPSqgGsgjMVpSqNq+ApMV8PL5sTXtAc6cqdzhWNnKHRYSJd9UsIZV/0BXKubmHnOjeUnVIgoeAvtGGvrmiRqIuAfhQMqjBWx9cr7Pboy0XL1I3MT3AoGllJ3Zt0joRP7Bc65rt4I6Z4owGFirRMr4eyK+qa4KcLUFLSeaQuCKFZC43YouWhVyD1Our5K2gNfS4638IpwFeGTtmxs2UtEnr10btCrIxJOJ1PaqSdzxX6pObtk/Y7vGBYo02FruP91vOJb12PGqs6hnr9/L4P/BxnfS5F6tYa6TMqmtfcy9Kf7Th5jxvpYsb5Pm5S0HecLqLofROa4dCFjNBsRfjnS/h5HOnzxa+zHZNCId875zq+oedsuPBz9nw/F72eCNF8H/mROj+lgUSmvpUaRk5XOyK9yZVSVN/50CsX4VcqNAqF3z6xasypAekNZxkNjSgUqQ+5vpi8vrKRUqXR0nY0oo+ufmjWbI3IEf6jEXw08oauHCUmHQ8Nyaor6uoSpUZu+FXDxHg9vCyMhjMNpa5F4bwaFI18Ej4kZEK7QXmvs0aG8XNu6BjoCyz0ypyOh7IR8dFxVFcSfSkrY6CMR+gY7PoyUsZLQ/nGN4xutH1x43uN1OUkfMhGZZwUOOqcC20UKOuhLkLhlH3R6DbxXZlLyOuRVHTeqotTKP1fyzWsZvjrGHqcFHjqcymcVwujmoLwK7Kh9/dGoIk2C6rPQY0Eps8OvYdCt6nskmiEm9RGQbGOnbLOoV0B1TVUF0Y0epmG6QxdV+dM6HtYo3WFfwaoy4tqyfQZFOm9p+Pi1T8lREKPsz6j9B2k96NHr7tGHQoXzWuuz1ONVuZR4KRt6RxU99nQx1VjNvTilIJiTch6Po+bFOL7fFEX2vD3hoZbFWV2Q2/T91f4qGuJ4WzHpFy5cq5ravg5p9qb8HNNtRLqhqxzOXRER32GJNbnoh5T+6OLeEmJjAUyBGUqdNVWX/LqZ6laC12pUl9wfajqS0WNVI3nravUauCpn78KhLW++qprmDY1viNdVUoIdWHSVWR9IYZemY+PijdXrFjhPjBVk6BuQPpA0TwA2hcNqednwhs1/lQ0puH+4qMh8DR2t/ogX3nllZaY1AB+//33XRcRPbfQhpgkxuuhwEiBgoZn1OutK0m6ShxpSF49Pz1X/ajbnF4vdVnR6+XNXKov6WhoXdWleOPOn++5oeBOr7euTukLRQ0rTZh4tqGD1TBVo1RFxPqCjdTNQ0Pq6tzSML76UQZMV90VkGjf9WUXaQz2cBoSVENp6jVUlkZfkBrCWVfo9RrpS92jLzad09o/de3Seadlehw18tQtL/QqoLq/adABZbYUIOkYqJ5GQ4QqU+JlclKSroorm6YGpI6ZzhNlb5StCB0+WK+j5hJRMK2hKdVoUODnFXSHnwsKBvW5pSyWGsvqe65zXw0kr7Gq81VBol5LBWr6rFODRsXn8VGjS8GuCmi9YVBV9KrtKosY35w5KUnve50D+hxQtzsdG2+4WQWlakh7DVAddz0v1aTpfNHnl4Jk/V+ZvPBx/jWsrM5hbVfvLwUoes/oqrKyRlrmzV2QEAk5zvps0oUOBRs65/U+VMAfqcuMLiSpq6GCV2UwlXlUIOMVHHsBg84BFf5qXZ1nujCkeRFC+91rmNI333zTZWu0rj7b9L6N1OXxfM61xKBjoqBIAaCOk46NPhOUzQ6v+9N3hdbReaHnpPsqMFSgpNdV783EzLzoM0ttCR1DfQ4UK1bMHRd9XyvoUBdHZdb1HaT2hd7LCh5UpK5MvEfnrp6jPof1uajhvL15pPQY+rwLldDPRQVl+s5T19nzHQ43akk65hSQCM42xF34UKHnGl5UQ6DeeuutbrjLrFmzuiEv69evHxg2bFhg7969sYbbvOGGGwJFihQJ5MyZ0w3T98477/geytQbHlFD/kUa8i3ScLNffvll4P777w/Url3b7a/uq+EVNeylhg49fvx4rPU1zFzu3LkD8fGegzeUpp6n/q/h+M5Gw4zqcb1hT7WfVatWDfilYRALFSrk9uGOO+6IuE5CXo9Iy2TlypVu+EcNY6kh/Xr37h34+++/4z2HNGxrixYtAgULFgxky5YtUKpUqcB1110XmDhxYqz14htuVsMj6nXQsLrROtu58eKLL7qhdbX/GvZU+69zNr79Fw3vqdsrVqwY72Nq6Fid/9WqVXNDz2qYSg0jrNdCxyzaoSY1TKSGeNSQxdqGzsPPPvss3veHhnO87LLL3LHV8IhDhgxxr2n48LneELUamlTvgVy5crmfChUquKGXFy5ceNZjGt++J9bnijdcp4Yybdq0qds3HQMNE6vhdkNpSMknn3wycPHFF7vnrWEkH3jggcCmTZsiDlmp4TKfe+45NySuznsdVx0zHatQr776qjs39Jl2tvMhlIYY1vDJ3vmt11zDdoYOzxrfcz7XcQoX33vybEN1xjf8qt4HNWrUcO8DDVPbvHlzd56F07EbPny4O8Z6fvqsmjFjRrz7oiE+9V7Ve0Xb1med3hMakjl0SOyEDrka7XGWDz74IHD55Ze79YoXLx4YPHiwGzo30jHSujovtK+63RteNHSIU71n9D7R9vR7/PjxEfdR548+33X+lC1b1u3fJ598EnGo1ISea/GdP2cbijXSELjvvvtuoFatWu79pc/vm266KbBt27aI6+rY6j2izxU9d71n9JkycOBA95h//PHHOfdPwp9ffOerhonWd4v2zcxinbcaRrtXr17uO07v4UaNGgVWrFgR7+POmTMneA7oO0dDUX/88ccRj1VCPheXLVvmtqHvtaQWo3+SNnQBEE5XhpQpUJ/P0KuVurqhrk+RZhNF6qQr7aor0JX20JlzdbVSoyR5o/v4PTcyAl2x1YRWGs5X2ZO0QK+5fkJn9QZSis5DZUh1VTyaGdgzEmURdHVfmcKkGJwhNevQoYPrmaCsVVLXylBjAaQADZunYez04Y/0RzUx6jevNHVCgoqMcm6ou0V4/Yq6s6i7gtL+oXOYAEBCRKpJVLcpFX+ry1BGCyrWr1/vuvTpwk1yFOBTYwGkAPWH1SQ/SJ80FKLqJM5HRjg31HdddQYaKlJ9tHWspk2b5rI+6u8ePicEAERLnyWqTVLtoQbFUF2dai70uaILNxlNzf9XM5RcCCwAAMlKX/bq6qSCWxXVqkhRRd7K8qh4EQDOlzKeGoxlwoQJbrQmFa8rU/H4448HRw5D0qHGAgAAAIBv1FgAAAAA8I3AAgAAAIBvBBYAAAAAfCOwAAAAAOAbgQUAAAAA3wgsAAAAAPhGYAEAAADANwILAAAAAL4RWAAAAAAwv/4/JIEmHf2S2zcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x630 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "xgb_model = model.calibrated_classifiers_[0].estimator\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_train_sc)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09132835",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Second Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1c778047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mida del train original: 68195\n",
      "Mida de first_round afegir: 64\n",
      "Mida del nou train: 68259\n",
      "\n",
      "Train actualizat correctament. Llest per la següent fase.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Loser</th>\n",
       "      <th>WRank</th>\n",
       "      <th>LRank</th>\n",
       "      <th>W1</th>\n",
       "      <th>L1</th>\n",
       "      <th>W2</th>\n",
       "      <th>L2</th>\n",
       "      <th>W3</th>\n",
       "      <th>L3</th>\n",
       "      <th>W4</th>\n",
       "      <th>L4</th>\n",
       "      <th>W5</th>\n",
       "      <th>L5</th>\n",
       "      <th>Wsets</th>\n",
       "      <th>Lsets</th>\n",
       "      <th>Comment</th>\n",
       "      <th>CBW</th>\n",
       "      <th>CBL</th>\n",
       "      <th>GBW</th>\n",
       "      <th>GBL</th>\n",
       "      <th>IWW</th>\n",
       "      <th>IWL</th>\n",
       "      <th>SBW</th>\n",
       "      <th>SBL</th>\n",
       "      <th>B365W</th>\n",
       "      <th>B365L</th>\n",
       "      <th>B&amp;WW</th>\n",
       "      <th>B&amp;WL</th>\n",
       "      <th>EXW</th>\n",
       "      <th>EXL</th>\n",
       "      <th>PSW</th>\n",
       "      <th>PSL</th>\n",
       "      <th>WPts</th>\n",
       "      <th>LPts</th>\n",
       "      <th>UBW</th>\n",
       "      <th>UBL</th>\n",
       "      <th>LBW</th>\n",
       "      <th>LBL</th>\n",
       "      <th>SJW</th>\n",
       "      <th>SJL</th>\n",
       "      <th>MaxW</th>\n",
       "      <th>MaxL</th>\n",
       "      <th>AvgW</th>\n",
       "      <th>AvgL</th>\n",
       "      <th>BFEW</th>\n",
       "      <th>BFEL</th>\n",
       "      <th>MaxWin</th>\n",
       "      <th>MaxLoss</th>\n",
       "      <th>AvgWin</th>\n",
       "      <th>AvgLoss</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>RankA</th>\n",
       "      <th>RankB</th>\n",
       "      <th>RankDiff</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>MaxOddsPlayerA</th>\n",
       "      <th>MaxOddsPlayerB</th>\n",
       "      <th>AvgOddsPlayerA</th>\n",
       "      <th>AvgOddsPlayerB</th>\n",
       "      <th>H2H_A_wins</th>\n",
       "      <th>H2H_B_wins</th>\n",
       "      <th>H2H_Diff</th>\n",
       "      <th>WinsA</th>\n",
       "      <th>LossesA</th>\n",
       "      <th>WinsB</th>\n",
       "      <th>LossesB</th>\n",
       "      <th>WinRateA_cum</th>\n",
       "      <th>WinRateB_cum</th>\n",
       "      <th>Form10A</th>\n",
       "      <th>Form10B</th>\n",
       "      <th>RestDaysA</th>\n",
       "      <th>RestDaysB</th>\n",
       "      <th>DiffWR</th>\n",
       "      <th>DiffForm</th>\n",
       "      <th>DiffRest</th>\n",
       "      <th>LogRankDiff</th>\n",
       "      <th>H2HDiff</th>\n",
       "      <th>ProbA_odds</th>\n",
       "      <th>ProbB_odds</th>\n",
       "      <th>OddsProbDiff</th>\n",
       "      <th>WinRateA_x_Rank</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "      <th>SurfaceText</th>\n",
       "      <th>RoundOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>Kopriva V.</td>\n",
       "      <td>44.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.43</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>757.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.43</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.43</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.415</td>\n",
       "      <td>3.015</td>\n",
       "      <td>Kopriva V.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>78.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1.43</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>144</td>\n",
       "      <td>165</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.066019</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.572519</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.699301</td>\n",
       "      <td>-0.400793</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>-0.005463</td>\n",
       "      <td>1435.991656</td>\n",
       "      <td>1514.516010</td>\n",
       "      <td>1494.145626</td>\n",
       "      <td>1495.763161</td>\n",
       "      <td>-78.524353</td>\n",
       "      <td>-1.617535</td>\n",
       "      <td>Grass</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fery A.</td>\n",
       "      <td>Popyrin A.</td>\n",
       "      <td>461.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.24</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.24</td>\n",
       "      <td>4.390</td>\n",
       "      <td>1.230</td>\n",
       "      <td>Fery A.</td>\n",
       "      <td>Popyrin A.</td>\n",
       "      <td>461.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>364</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.450450</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>352</td>\n",
       "      <td>3.042356</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>-0.559028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020475</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>1472.593945</td>\n",
       "      <td>1530.845391</td>\n",
       "      <td>1468.318148</td>\n",
       "      <td>1415.915885</td>\n",
       "      <td>-58.251446</td>\n",
       "      <td>52.402263</td>\n",
       "      <td>Grass</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Quinn E.</td>\n",
       "      <td>Searle H.</td>\n",
       "      <td>89.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2.85</td>\n",
       "      <td>682.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.455</td>\n",
       "      <td>2.825</td>\n",
       "      <td>Quinn E.</td>\n",
       "      <td>Searle H.</td>\n",
       "      <td>89.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>-332.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>363</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-357</td>\n",
       "      <td>-1.553996</td>\n",
       "      <td>0</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.335540</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>1441.475374</td>\n",
       "      <td>1455.118417</td>\n",
       "      <td>1501.137976</td>\n",
       "      <td>1457.990153</td>\n",
       "      <td>-13.643043</td>\n",
       "      <td>43.147824</td>\n",
       "      <td>Grass</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>Rune H.</td>\n",
       "      <td>143.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.30</td>\n",
       "      <td>418.0</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.755</td>\n",
       "      <td>1.295</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>Rune H.</td>\n",
       "      <td>143.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>105</td>\n",
       "      <td>110</td>\n",
       "      <td>157</td>\n",
       "      <td>93</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.139628</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.883403</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>-0.507576</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>-0.075085</td>\n",
       "      <td>1429.372274</td>\n",
       "      <td>1674.031106</td>\n",
       "      <td>1439.398085</td>\n",
       "      <td>1526.815285</td>\n",
       "      <td>-244.658832</td>\n",
       "      <td>-87.417200</td>\n",
       "      <td>Grass</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Struff J.L.</td>\n",
       "      <td>Misolic F.</td>\n",
       "      <td>125.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.36</td>\n",
       "      <td>475.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.62</td>\n",
       "      <td>2.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1.660</td>\n",
       "      <td>2.305</td>\n",
       "      <td>Misolic F.</td>\n",
       "      <td>Struff J.L.</td>\n",
       "      <td>111.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>206</td>\n",
       "      <td>241</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.460850</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>0.060889</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.118784</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>-0.178571</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>1483.741386</td>\n",
       "      <td>1413.543282</td>\n",
       "      <td>1498.500000</td>\n",
       "      <td>1493.836790</td>\n",
       "      <td>70.198104</td>\n",
       "      <td>4.663210</td>\n",
       "      <td>Grass</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATP Location Tournament        Date  Series  Court  Surface      Round  \\\n",
       "0   36   London  Wimbledon  2025-06-30       2      1        2  1st Round   \n",
       "1   36   London  Wimbledon  2025-06-30       2      1        2  1st Round   \n",
       "2   36   London  Wimbledon  2025-06-30       2      1        2  1st Round   \n",
       "3   36   London  Wimbledon  2025-06-30       2      1        2  1st Round   \n",
       "4   36   London  Wimbledon  2025-06-30       2      1        2  1st Round   \n",
       "\n",
       "   Best of       Winner       Loser  WRank  LRank   W1   L1   W2   L2   W3  \\\n",
       "0      5.0  Thompson J.  Kopriva V.   44.0   78.0  3.0  6.0  4.0  6.0  6.0   \n",
       "1      5.0      Fery A.  Popyrin A.  461.0   22.0  6.0  4.0  6.0  1.0  4.0   \n",
       "2      5.0     Quinn E.   Searle H.   89.0  421.0  4.0  6.0  6.0  2.0  7.0   \n",
       "3      5.0     Jarry N.     Rune H.  143.0    8.0  4.0  6.0  4.0  6.0  7.0   \n",
       "4      5.0  Struff J.L.  Misolic F.  125.0  111.0  6.0  2.0  5.0  7.0  6.0   \n",
       "\n",
       "    L3   W4   L4   W5   L5  Wsets  Lsets    Comment  CBW  CBL  GBW  GBL  IWW  \\\n",
       "0  3.0  7.0  6.0  6.0  1.0    3.0    2.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "1  6.0  6.0  4.0  NaN  NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "2  6.0  6.0  2.0  NaN  NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "3  5.0  6.0  3.0  6.0  4.0    3.0    2.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "4  3.0  6.0  3.0  NaN  NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   IWL  SBW  SBL  B365W  B365L  B&WW  B&WL  EXW  EXL   PSW   PSL    WPts  \\\n",
       "0  NaN  NaN  NaN   1.40   3.00   NaN   NaN  NaN  NaN  1.43  3.03  1200.0   \n",
       "1  NaN  NaN  NaN   4.33   1.22   NaN   NaN  NaN  NaN  4.45  1.24    91.0   \n",
       "2  NaN  NaN  NaN   1.44   2.80   NaN   NaN  NaN  NaN  1.47  2.85   682.0   \n",
       "3  NaN  NaN  NaN   3.75   1.29   NaN   NaN  NaN  NaN  3.76  1.30   418.0   \n",
       "4  NaN  NaN  NaN   1.67   2.25   NaN   NaN  NaN  NaN  1.65  2.36   475.0   \n",
       "\n",
       "     LPts  UBW  UBL  LBW  LBL  SJW  SJL  MaxW  MaxL  AvgW  AvgL  BFEW  BFEL  \\\n",
       "0   757.0  NaN  NaN  NaN  NaN  NaN  NaN  1.43  3.35  1.38  3.02   NaN   NaN   \n",
       "1  2140.0  NaN  NaN  NaN  NaN  NaN  NaN  4.50  1.28  4.02  1.24   NaN   NaN   \n",
       "2   106.0  NaN  NaN  NaN  NaN  NaN  NaN  1.48  2.94  1.44  2.75   NaN   NaN   \n",
       "3  3530.0  NaN  NaN  NaN  NaN  NaN  NaN  4.00  1.32  3.65  1.28   NaN   NaN   \n",
       "4   518.0  NaN  NaN  NaN  NaN  NaN  NaN  1.68  2.40  1.62  2.28   NaN   NaN   \n",
       "\n",
       "   MaxWin  MaxLoss  AvgWin  AvgLoss     PlayerA      PlayerB  RankA  RankB  \\\n",
       "0    1.43     3.03   1.415    3.015  Kopriva V.  Thompson J.   78.0   44.0   \n",
       "1    4.45     1.24   4.390    1.230     Fery A.   Popyrin A.  461.0   22.0   \n",
       "2    1.47     2.85   1.455    2.825    Quinn E.    Searle H.   89.0  421.0   \n",
       "3    3.76     1.30   3.755    1.295    Jarry N.      Rune H.  143.0    8.0   \n",
       "4    1.67     2.36   1.660    2.305  Misolic F.  Struff J.L.  111.0  125.0   \n",
       "\n",
       "   RankDiff  WinnerBinary  MaxOddsPlayerA  MaxOddsPlayerB  AvgOddsPlayerA  \\\n",
       "0      34.0             0            3.35            1.43            3.02   \n",
       "1     439.0             1            4.50            1.28            4.02   \n",
       "2    -332.0             1            1.48            2.94            1.44   \n",
       "3     135.0             1            4.00            1.32            3.65   \n",
       "4     -14.0             0            2.40            1.68            2.28   \n",
       "\n",
       "   AvgOddsPlayerB  H2H_A_wins  H2H_B_wins  H2H_Diff  WinsA  LossesA  WinsB  \\\n",
       "0            1.38           0           0         0     10       15    144   \n",
       "1            1.24           0           0         0      0        2    100   \n",
       "2            2.75           0           0         0      8       16      0   \n",
       "3            1.28           0           1        -1    105      110    157   \n",
       "4            1.62           0           0         0     12       11    206   \n",
       "\n",
       "   LossesB  WinRateA_cum  WinRateB_cum  Form10A  Form10B  RestDaysA  \\\n",
       "0      165      0.400000      0.466019      0.5      0.3         33   \n",
       "1      122      0.000000      0.450450      0.0      0.6        364   \n",
       "2        2      0.333333      0.000000      0.4      0.0          6   \n",
       "3       93      0.488372      0.628000      0.3      0.6         18   \n",
       "4      241      0.521739      0.460850      0.5      0.2         30   \n",
       "\n",
       "   RestDaysB    DiffWR  DiffForm  DiffRest  LogRankDiff  H2HDiff  ProbA_odds  \\\n",
       "0         13 -0.066019       0.2        20     0.572519        0    0.298507   \n",
       "1         12 -0.450450      -0.6       352     3.042356        0    0.222222   \n",
       "2        363  0.333333       0.4      -357    -1.553996        0    0.675676   \n",
       "3         10 -0.139628      -0.3         8     2.883403       -1    0.250000   \n",
       "4         13  0.060889       0.3        17    -0.118784        0    0.416667   \n",
       "\n",
       "   ProbB_odds  OddsProbDiff  WinRateA_x_Rank  WinRateB_x_Rank  EfficiencyDiff  \\\n",
       "0    0.699301     -0.400793         0.005128         0.010591       -0.005463   \n",
       "1    0.781250     -0.559028         0.000000         0.020475       -0.020475   \n",
       "2    0.340136      0.335540         0.003745         0.000000        0.003745   \n",
       "3    0.757576     -0.507576         0.003415         0.078500       -0.075085   \n",
       "4    0.595238     -0.178571         0.004700         0.003687        0.001014   \n",
       "\n",
       "   EloA_Global  EloB_Global  EloA_Surface  EloB_Surface  EloDiff_Global  \\\n",
       "0  1435.991656  1514.516010   1494.145626   1495.763161      -78.524353   \n",
       "1  1472.593945  1530.845391   1468.318148   1415.915885      -58.251446   \n",
       "2  1441.475374  1455.118417   1501.137976   1457.990153      -13.643043   \n",
       "3  1429.372274  1674.031106   1439.398085   1526.815285     -244.658832   \n",
       "4  1483.741386  1413.543282   1498.500000   1493.836790       70.198104   \n",
       "\n",
       "   EloDiff_Surface SurfaceText  RoundOrder  \n",
       "0        -1.617535       Grass         1.0  \n",
       "1        52.402263       Grass         1.0  \n",
       "2        43.147824       Grass         1.0  \n",
       "3       -87.417200       Grass         1.0  \n",
       "4         4.663210       Grass         1.0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actualizar el conjunt de entrenament: afegir first_round al train actual\n",
    "train_second_round = pd.concat([first_round, train], ignore_index=True)\n",
    "\n",
    "print(f\"Mida del train original: {len(train_second_round) - len(first_round)}\")\n",
    "print(f\"Mida de first_round afegir: {len(first_round)}\")\n",
    "print(f\"Mida del nou train: {len(train_second_round)}\")\n",
    "print(f\"\\nTrain actualizat correctament. Llest per la següent fase.\")\n",
    "\n",
    "train_second_round.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "15e7fa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ACCURACY FINAL TEST CRONOLÓGIC: 0.6875\n",
      "Brier Score: 0.2218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5556    0.8333    0.6667        12\n",
      "           1     0.8571    0.6000    0.7059        20\n",
      "\n",
      "    accuracy                         0.6875        32\n",
      "   macro avg     0.7063    0.7167    0.6863        32\n",
      "weighted avg     0.7440    0.6875    0.6912        32\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "X_train = train_second_round[features].fillna(0)\n",
    "X_test = second_round[features].fillna(0)\n",
    "y_train = train_second_round['WinnerBinary']\n",
    "y_test = second_round['WinnerBinary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "base_model = XGBClassifier(\n",
    "    n_estimators=500,                    # Nombre total d'arbres (boosting rounds) que es construiran. 500 és un valor força alt, bo per a un bon rendiment si es controla l'overfitting.\n",
    "    max_depth=6,                         # Profunditat màxima de cada arbre. 6 és un valor moderat: permet interaccions complexes sense fer els arbres excessivament profunds.\n",
    "    learning_rate=0.02,                  # Taxa d'aprenentatge (eta). 0.02 és bastant baixa → aprenentatge lent i estable, ideal quan tens molts estimators (500).\n",
    "    subsample=0.85,                      # Percentatge de mostres (files) que s'utilitzen per entrenar cada arbre. 0.85 = 85% → ajuda a reduir overfitting i afegeix variància (com bagging).\n",
    "    colsample_bytree=0.85,               # Percentatge de columnes (variables) que s'agafen aleatòriament per cada arbre. 85% → també redueix overfitting i millora la generalització.\n",
    "    min_child_weight=5,                  # Suma mínima del pes Hessiana en un node fill. Valors >1 fan el model més conservador: evita dividir nodes amb poca informació.\n",
    "    gamma=0.1,                           # Minimització mínima de la funció de pèrdua necessària per fer una partició addicional (regularització per poda). 0.1 afavoreix arbres més simples.\n",
    "    reg_alpha=0.1,                       # Terme de regularització L1 sobre els pesos de les fulles. Ajuda a fer sparseness i és útil quan hi ha moltes variables irrellevants.\n",
    "    reg_lambda=1.0,                      # Terme de regularització L2 (més suau que L1). 1.0 és el valor per defecte i sol funcionar bé en la majoria de casos.\n",
    "    random_state=42,                     # Llavor per a la reproductibilitat dels resultats (aleatorietat controlada).\n",
    "    n_jobs=-1,                           # Utilitza tots els nuclis disponibles del processador per entrenar en paral·lel → molt més ràpid.\n",
    "    eval_metric='logloss'                # Mètrica d'avaluació durant l'entrenament (per classificació binària/multiclasse). 'logloss' = logarithmic loss (cross-entropy).\n",
    ")\n",
    "\n",
    "model = CalibratedClassifierCV(base_model, method='isotonic', cv=5)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "pred = model.predict(X_test_sc)\n",
    "prob = model.predict_proba(X_test_sc)[:, 1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "brier = brier_score_loss(y_test, prob)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ACCURACY FINAL TEST CRONOLÓGIC: {acc:.4f}\")\n",
    "print(f\"Brier Score: {brier:.4f}\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc67dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DETALLADOS POR FILA:\n",
      "====================================================================================================\n",
      "\n",
      "Total de predicciones: 32\n",
      "Correctas: 22 (68.75%)\n",
      "Fallidas: 10 (31.25%)\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68258</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>Mochizuki S.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.880638</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68259</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Diallo G.</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221491</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68260</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Borges N.</td>\n",
       "      <td>Harris B.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584241</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68261</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>Tien L.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.537511</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68263</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>Tiafoe F.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68264</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Bonzi B.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586356</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68265</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Tarvet O.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933136</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68266</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Brooksby J.</td>\n",
       "      <td>Fonseca J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354561</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68267</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Bellucci M.</td>\n",
       "      <td>Lehecka J.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200418</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68268</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Mannarino A.</td>\n",
       "      <td>Royer V.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715499</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68269</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Harris L.</td>\n",
       "      <td>Rublev A.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263423</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68270</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>Quinn E.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.452083</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68271</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Martinez P.</td>\n",
       "      <td>Navone M.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407297</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68272</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Sinner J.</td>\n",
       "      <td>Vukic A.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969123</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68273</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Nakashima B.</td>\n",
       "      <td>Opelka R.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.694549</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68274</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Evans D.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925428</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68275</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Cilic M.</td>\n",
       "      <td>Draper J.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167210</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68276</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Cazaux A.</td>\n",
       "      <td>De Minaur A.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069344</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68277</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Auger-Aliassime F.</td>\n",
       "      <td>Struff J.L.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745191</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68278</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Ofner S.</td>\n",
       "      <td>Paul T.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133531</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68279</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Holmgren A.</td>\n",
       "      <td>Machac T.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136344</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68280</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Dimitrov G.</td>\n",
       "      <td>Moutet C.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619825</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68281</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Giron M.</td>\n",
       "      <td>Mensik J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.401599</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68282</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>Pinnington Jones J.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774223</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68283</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Basilashvili N.</td>\n",
       "      <td>Sonego L.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326791</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68284</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Garin C.</td>\n",
       "      <td>Rinderknech A.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492834</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68285</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Marozsan F.</td>\n",
       "      <td>Munar J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464211</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68286</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Davidovich Fokina A.</td>\n",
       "      <td>Van De Zandschulp B.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729082</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68287</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Darderi L.</td>\n",
       "      <td>Fery A.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.689090</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68288</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>De Jong J.</td>\n",
       "      <td>Kecmanovic M.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327535</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68291</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Fucsovics M.</td>\n",
       "      <td>Monfils G.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466084</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68292</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Hijikata R.</td>\n",
       "      <td>Shelton B.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249222</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date               PlayerA               PlayerB  WinnerBinary  \\\n",
       "68258  2025-07-02          Khachanov K.          Mochizuki S.             1   \n",
       "68259  2025-07-02             Diallo G.              Fritz T.             0   \n",
       "68260  2025-07-02             Borges N.             Harris B.             1   \n",
       "68261  2025-07-02              Jarry N.               Tien L.             1   \n",
       "68263  2025-07-02             Norrie C.             Tiafoe F.             1   \n",
       "68264  2025-07-02              Bonzi B.           Thompson J.             0   \n",
       "68265  2025-07-02            Alcaraz C.             Tarvet O.             1   \n",
       "68266  2025-07-02           Brooksby J.            Fonseca J.             0   \n",
       "68267  2025-07-02           Bellucci M.            Lehecka J.             1   \n",
       "68268  2025-07-02          Mannarino A.              Royer V.             1   \n",
       "68269  2025-07-02             Harris L.             Rublev A.             0   \n",
       "68270  2025-07-02          Majchrzak K.              Quinn E.             1   \n",
       "68271  2025-07-03           Martinez P.             Navone M.             1   \n",
       "68272  2025-07-03             Sinner J.              Vukic A.             1   \n",
       "68273  2025-07-03          Nakashima B.             Opelka R.             1   \n",
       "68274  2025-07-03           Djokovic N.              Evans D.             1   \n",
       "68275  2025-07-03              Cilic M.             Draper J.             1   \n",
       "68276  2025-07-03             Cazaux A.          De Minaur A.             0   \n",
       "68277  2025-07-03    Auger-Aliassime F.           Struff J.L.             0   \n",
       "68278  2025-07-03              Ofner S.               Paul T.             1   \n",
       "68279  2025-07-03           Holmgren A.             Machac T.             1   \n",
       "68280  2025-07-03           Dimitrov G.             Moutet C.             1   \n",
       "68281  2025-07-03              Giron M.             Mensik J.             0   \n",
       "68282  2025-07-03            Cobolli F.   Pinnington Jones J.             1   \n",
       "68283  2025-07-03       Basilashvili N.             Sonego L.             0   \n",
       "68284  2025-07-03              Garin C.        Rinderknech A.             0   \n",
       "68285  2025-07-03           Marozsan F.              Munar J.             0   \n",
       "68286  2025-07-03  Davidovich Fokina A.  Van De Zandschulp B.             1   \n",
       "68287  2025-07-03            Darderi L.               Fery A.             1   \n",
       "68288  2025-07-03            De Jong J.         Kecmanovic M.             0   \n",
       "68291  2025-07-04          Fucsovics M.            Monfils G.             1   \n",
       "68292  2025-07-04           Hijikata R.            Shelton B.             0   \n",
       "\n",
       "       Predicted  Probability     Result  \n",
       "68258          1     0.880638  ✓ Correct  \n",
       "68259          0     0.221491  ✓ Correct  \n",
       "68260          1     0.584241  ✓ Correct  \n",
       "68261          1     0.537511  ✓ Correct  \n",
       "68263          0     0.421631   ✗ Failed  \n",
       "68264          1     0.586356   ✗ Failed  \n",
       "68265          1     0.933136  ✓ Correct  \n",
       "68266          0     0.354561  ✓ Correct  \n",
       "68267          0     0.200418   ✗ Failed  \n",
       "68268          1     0.715499  ✓ Correct  \n",
       "68269          0     0.263423  ✓ Correct  \n",
       "68270          0     0.452083   ✗ Failed  \n",
       "68271          0     0.407297   ✗ Failed  \n",
       "68272          1     0.969123  ✓ Correct  \n",
       "68273          1     0.694549  ✓ Correct  \n",
       "68274          1     0.925428  ✓ Correct  \n",
       "68275          0     0.167210   ✗ Failed  \n",
       "68276          0     0.069344  ✓ Correct  \n",
       "68277          1     0.745191   ✗ Failed  \n",
       "68278          0     0.133531   ✗ Failed  \n",
       "68279          0     0.136344   ✗ Failed  \n",
       "68280          1     0.619825  ✓ Correct  \n",
       "68281          0     0.401599  ✓ Correct  \n",
       "68282          1     0.774223  ✓ Correct  \n",
       "68283          0     0.326791  ✓ Correct  \n",
       "68284          0     0.492834  ✓ Correct  \n",
       "68285          0     0.464211  ✓ Correct  \n",
       "68286          1     0.729082  ✓ Correct  \n",
       "68287          1     0.689090  ✓ Correct  \n",
       "68288          0     0.327535  ✓ Correct  \n",
       "68291          0     0.466084   ✗ Failed  \n",
       "68292          0     0.249222  ✓ Correct  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "PREDICCIONES FALLIDAS:\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68263</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>Tiafoe F.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68264</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Bonzi B.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68267</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Bellucci M.</td>\n",
       "      <td>Lehecka J.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68270</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>Quinn E.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.452083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68271</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Martinez P.</td>\n",
       "      <td>Navone M.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68275</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Cilic M.</td>\n",
       "      <td>Draper J.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68277</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Auger-Aliassime F.</td>\n",
       "      <td>Struff J.L.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68278</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Ofner S.</td>\n",
       "      <td>Paul T.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68279</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>Holmgren A.</td>\n",
       "      <td>Machac T.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68291</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Fucsovics M.</td>\n",
       "      <td>Monfils G.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date             PlayerA      PlayerB  WinnerBinary  Predicted  \\\n",
       "68263  2025-07-02           Norrie C.    Tiafoe F.             1          0   \n",
       "68264  2025-07-02            Bonzi B.  Thompson J.             0          1   \n",
       "68267  2025-07-02         Bellucci M.   Lehecka J.             1          0   \n",
       "68270  2025-07-02        Majchrzak K.     Quinn E.             1          0   \n",
       "68271  2025-07-03         Martinez P.    Navone M.             1          0   \n",
       "68275  2025-07-03            Cilic M.    Draper J.             1          0   \n",
       "68277  2025-07-03  Auger-Aliassime F.  Struff J.L.             0          1   \n",
       "68278  2025-07-03            Ofner S.      Paul T.             1          0   \n",
       "68279  2025-07-03         Holmgren A.    Machac T.             1          0   \n",
       "68291  2025-07-04        Fucsovics M.   Monfils G.             1          0   \n",
       "\n",
       "       Probability  \n",
       "68263     0.421631  \n",
       "68264     0.586356  \n",
       "68267     0.200418  \n",
       "68270     0.452083  \n",
       "68271     0.407297  \n",
       "68275     0.167210  \n",
       "68277     0.745191  \n",
       "68278     0.133531  \n",
       "68279     0.136344  \n",
       "68291     0.466084  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df, failed_df = analyze_predictions(\n",
    "    df=second_round,\n",
    "    y_true=second_round[\"WinnerBinary\"].values,\n",
    "    y_pred=pred,\n",
    "    y_prob=prob,\n",
    "    date_col=\"Date\",\n",
    "    player_a_col=\"PlayerA\",\n",
    "    player_b_col=\"PlayerB\",\n",
    "    true_col_name=\"WinnerBinary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff3441",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Third Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c284d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del train original: 68259\n",
      "Tamaño de first_round añadido: 32\n",
      "Tamaño del nuevo train: 68291\n",
      "\n",
      "Train actualizado correctamente. Listo para la siguiente fase.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Loser</th>\n",
       "      <th>WRank</th>\n",
       "      <th>LRank</th>\n",
       "      <th>W1</th>\n",
       "      <th>L1</th>\n",
       "      <th>W2</th>\n",
       "      <th>L2</th>\n",
       "      <th>W3</th>\n",
       "      <th>L3</th>\n",
       "      <th>W4</th>\n",
       "      <th>L4</th>\n",
       "      <th>W5</th>\n",
       "      <th>L5</th>\n",
       "      <th>Wsets</th>\n",
       "      <th>Lsets</th>\n",
       "      <th>Comment</th>\n",
       "      <th>CBW</th>\n",
       "      <th>CBL</th>\n",
       "      <th>GBW</th>\n",
       "      <th>GBL</th>\n",
       "      <th>IWW</th>\n",
       "      <th>IWL</th>\n",
       "      <th>SBW</th>\n",
       "      <th>SBL</th>\n",
       "      <th>B365W</th>\n",
       "      <th>B365L</th>\n",
       "      <th>B&amp;WW</th>\n",
       "      <th>B&amp;WL</th>\n",
       "      <th>EXW</th>\n",
       "      <th>EXL</th>\n",
       "      <th>PSW</th>\n",
       "      <th>PSL</th>\n",
       "      <th>WPts</th>\n",
       "      <th>LPts</th>\n",
       "      <th>UBW</th>\n",
       "      <th>UBL</th>\n",
       "      <th>LBW</th>\n",
       "      <th>LBL</th>\n",
       "      <th>SJW</th>\n",
       "      <th>SJL</th>\n",
       "      <th>MaxW</th>\n",
       "      <th>MaxL</th>\n",
       "      <th>AvgW</th>\n",
       "      <th>AvgL</th>\n",
       "      <th>BFEW</th>\n",
       "      <th>BFEL</th>\n",
       "      <th>MaxWin</th>\n",
       "      <th>MaxLoss</th>\n",
       "      <th>AvgWin</th>\n",
       "      <th>AvgLoss</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>RankA</th>\n",
       "      <th>RankB</th>\n",
       "      <th>RankDiff</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>MaxOddsPlayerA</th>\n",
       "      <th>MaxOddsPlayerB</th>\n",
       "      <th>AvgOddsPlayerA</th>\n",
       "      <th>AvgOddsPlayerB</th>\n",
       "      <th>H2H_A_wins</th>\n",
       "      <th>H2H_B_wins</th>\n",
       "      <th>H2H_Diff</th>\n",
       "      <th>WinsA</th>\n",
       "      <th>LossesA</th>\n",
       "      <th>WinsB</th>\n",
       "      <th>LossesB</th>\n",
       "      <th>WinRateA_cum</th>\n",
       "      <th>WinRateB_cum</th>\n",
       "      <th>Form10A</th>\n",
       "      <th>Form10B</th>\n",
       "      <th>RestDaysA</th>\n",
       "      <th>RestDaysB</th>\n",
       "      <th>DiffWR</th>\n",
       "      <th>DiffForm</th>\n",
       "      <th>DiffRest</th>\n",
       "      <th>LogRankDiff</th>\n",
       "      <th>H2HDiff</th>\n",
       "      <th>ProbA_odds</th>\n",
       "      <th>ProbB_odds</th>\n",
       "      <th>OddsProbDiff</th>\n",
       "      <th>WinRateA_x_Rank</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "      <th>SurfaceText</th>\n",
       "      <th>RoundOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2nd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>Mochizuki S.</td>\n",
       "      <td>20.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.14</td>\n",
       "      <td>6.76</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.16</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.13</td>\n",
       "      <td>5.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.14</td>\n",
       "      <td>6.76</td>\n",
       "      <td>1.140</td>\n",
       "      <td>6.13</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>Mochizuki S.</td>\n",
       "      <td>20.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-124.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.16</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.13</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>205</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.580777</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.974081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.719212</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>1599.013330</td>\n",
       "      <td>1350.351456</td>\n",
       "      <td>1558.723048</td>\n",
       "      <td>1465.261433</td>\n",
       "      <td>248.661874</td>\n",
       "      <td>93.461615</td>\n",
       "      <td>Grass</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2nd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Diallo G.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.76</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.310</td>\n",
       "      <td>3.68</td>\n",
       "      <td>Diallo G.</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>285</td>\n",
       "      <td>189</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.070654</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>-0.478884</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>0.120253</td>\n",
       "      <td>-0.106988</td>\n",
       "      <td>1579.481871</td>\n",
       "      <td>1687.476858</td>\n",
       "      <td>1528.176432</td>\n",
       "      <td>1648.849603</td>\n",
       "      <td>-107.994986</td>\n",
       "      <td>-120.673171</td>\n",
       "      <td>Grass</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2nd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Borges N.</td>\n",
       "      <td>Harris B.</td>\n",
       "      <td>37.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.555</td>\n",
       "      <td>2.53</td>\n",
       "      <td>Borges N.</td>\n",
       "      <td>Harris B.</td>\n",
       "      <td>37.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-114.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.005116</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.406362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.243321</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>1523.867714</td>\n",
       "      <td>1462.128763</td>\n",
       "      <td>1447.222082</td>\n",
       "      <td>1526.381429</td>\n",
       "      <td>61.738951</td>\n",
       "      <td>-79.159346</td>\n",
       "      <td>Grass</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2nd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>Tien L.</td>\n",
       "      <td>143.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.20</td>\n",
       "      <td>418.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.715</td>\n",
       "      <td>2.20</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>Tien L.</td>\n",
       "      <td>143.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>0.490741</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053241</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.835710</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564972</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.118543</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>-0.003625</td>\n",
       "      <td>1445.362211</td>\n",
       "      <td>1470.563932</td>\n",
       "      <td>1450.908581</td>\n",
       "      <td>1513.345983</td>\n",
       "      <td>-25.201721</td>\n",
       "      <td>-62.437401</td>\n",
       "      <td>Grass</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2nd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>Tiafoe F.</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.59</td>\n",
       "      <td>1.57</td>\n",
       "      <td>952.0</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.59</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.545</td>\n",
       "      <td>1.55</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>Tiafoe F.</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>213</td>\n",
       "      <td>156</td>\n",
       "      <td>215</td>\n",
       "      <td>191</td>\n",
       "      <td>0.577236</td>\n",
       "      <td>0.529557</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.047679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.625967</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>-0.252991</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0.044130</td>\n",
       "      <td>-0.034667</td>\n",
       "      <td>1560.888436</td>\n",
       "      <td>1553.980573</td>\n",
       "      <td>1516.736659</td>\n",
       "      <td>1528.145373</td>\n",
       "      <td>6.907863</td>\n",
       "      <td>-11.408714</td>\n",
       "      <td>Grass</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATP Location Tournament        Date  Series  Court  Surface      Round  \\\n",
       "0   36   London  Wimbledon  2025-07-02       2      1        2  2nd Round   \n",
       "1   36   London  Wimbledon  2025-07-02       2      1        2  2nd Round   \n",
       "2   36   London  Wimbledon  2025-07-02       2      1        2  2nd Round   \n",
       "3   36   London  Wimbledon  2025-07-02       2      1        2  2nd Round   \n",
       "4   36   London  Wimbledon  2025-07-02       2      1        2  2nd Round   \n",
       "\n",
       "   Best of        Winner         Loser  WRank  LRank   W1   L1   W2   L2   W3  \\\n",
       "0      5.0  Khachanov K.  Mochizuki S.   20.0  144.0  1.0  6.0  7.0  6.0  4.0   \n",
       "1      5.0      Fritz T.     Diallo G.    5.0   40.0  3.0  6.0  6.0  3.0  7.0   \n",
       "2      5.0     Borges N.     Harris B.   37.0  151.0  6.0  3.0  6.0  4.0  7.0   \n",
       "3      5.0      Jarry N.       Tien L.  143.0   62.0  6.0  2.0  6.0  2.0  6.0   \n",
       "4      5.0     Norrie C.     Tiafoe F.   61.0   12.0  4.0  6.0  6.0  4.0  6.0   \n",
       "\n",
       "    L3   W4   L4   W5   L5  Wsets  Lsets    Comment  CBW  CBL  GBW  GBL  IWW  \\\n",
       "0  6.0  6.0  3.0  6.0  4.0    3.0    2.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "1  6.0  4.0  6.0  6.0  3.0    3.0    2.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "2  6.0  NaN  NaN  NaN  NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "3  3.0  NaN  NaN  NaN  NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "4  3.0  7.0  5.0  NaN  NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   IWL  SBW  SBL  B365W  B365L  B&WW  B&WL  EXW  EXL   PSW   PSL    WPts  \\\n",
       "0  NaN  NaN  NaN   1.14   5.50   NaN   NaN  NaN  NaN  1.14  6.76  2240.0   \n",
       "1  NaN  NaN  NaN   1.30   3.60   NaN   NaN  NaN  NaN  1.32  3.76  4635.0   \n",
       "2  NaN  NaN  NaN   1.53   2.50   NaN   NaN  NaN  NaN  1.58  2.56  1400.0   \n",
       "3  NaN  NaN  NaN   1.67   2.20   NaN   NaN  NaN  NaN  1.76  2.20   418.0   \n",
       "4  NaN  NaN  NaN   2.50   1.53   NaN   NaN  NaN  NaN  2.59  1.57   952.0   \n",
       "\n",
       "     LPts  UBW  UBL  LBW  LBL  SJW  SJL  MaxW  MaxL  AvgW  AvgL  BFEW  BFEL  \\\n",
       "0   413.0  NaN  NaN  NaN  NaN  NaN  NaN  1.16  7.00  1.13  5.81   NaN   NaN   \n",
       "1  1322.0  NaN  NaN  NaN  NaN  NaN  NaN  1.36  3.90  1.30  3.50   NaN   NaN   \n",
       "2   383.0  NaN  NaN  NaN  NaN  NaN  NaN  1.60  2.62  1.56  2.40   NaN   NaN   \n",
       "3   940.0  NaN  NaN  NaN  NaN  NaN  NaN  1.77  2.24  1.68  2.18   NaN   NaN   \n",
       "4  2990.0  NaN  NaN  NaN  NaN  NaN  NaN  2.66  1.59  2.48  1.54   NaN   NaN   \n",
       "\n",
       "   MaxWin  MaxLoss  AvgWin  AvgLoss       PlayerA       PlayerB  RankA  RankB  \\\n",
       "0    1.14     6.76   1.140     6.13  Khachanov K.  Mochizuki S.   20.0  144.0   \n",
       "1    1.32     3.76   1.310     3.68     Diallo G.      Fritz T.   40.0    5.0   \n",
       "2    1.58     2.56   1.555     2.53     Borges N.     Harris B.   37.0  151.0   \n",
       "3    1.76     2.20   1.715     2.20      Jarry N.       Tien L.  143.0   62.0   \n",
       "4    2.59     1.57   2.545     1.55     Norrie C.     Tiafoe F.   61.0   12.0   \n",
       "\n",
       "   RankDiff  WinnerBinary  MaxOddsPlayerA  MaxOddsPlayerB  AvgOddsPlayerA  \\\n",
       "0    -124.0             1            1.16            7.00            1.13   \n",
       "1      35.0             0            3.90            1.36            3.50   \n",
       "2    -114.0             1            1.60            2.62            1.56   \n",
       "3      81.0             1            1.77            2.24            1.68   \n",
       "4      49.0             1            2.66            1.59            2.48   \n",
       "\n",
       "   AvgOddsPlayerB  H2H_A_wins  H2H_B_wins  H2H_Diff  WinsA  LossesA  WinsB  \\\n",
       "0            5.81           0           0         0    284      205      4   \n",
       "1            1.30           0           0         0     26       23    285   \n",
       "2            2.40           0           0         0     57       64     10   \n",
       "3            2.18           0           0         0    106      110     14   \n",
       "4            1.54           1           2        -1    213      156    215   \n",
       "\n",
       "   LossesB  WinRateA_cum  WinRateB_cum  Form10A  Form10B  RestDaysA  \\\n",
       "0       16      0.580777      0.200000      0.7      0.2          2   \n",
       "1      189      0.530612      0.601266      0.8      0.9          2   \n",
       "2       11      0.471074      0.476190      0.6      0.3          2   \n",
       "3       18      0.490741      0.437500      0.4      0.5          2   \n",
       "4      191      0.577236      0.529557      0.6      0.6          2   \n",
       "\n",
       "   RestDaysB    DiffWR  DiffForm  DiffRest  LogRankDiff  H2HDiff  ProbA_odds  \\\n",
       "0          1  0.380777       0.5         1    -1.974081        0    0.862069   \n",
       "1          1 -0.070654      -0.1         1     2.079442        0    0.256410   \n",
       "2          2 -0.005116       0.3         0    -1.406362        0    0.625000   \n",
       "3          2  0.053241      -0.1         0     0.835710        0    0.564972   \n",
       "4          2  0.047679       0.0         0     1.625967       -1    0.375940   \n",
       "\n",
       "   ProbB_odds  OddsProbDiff  WinRateA_x_Rank  WinRateB_x_Rank  EfficiencyDiff  \\\n",
       "0    0.142857      0.719212         0.029039         0.001389        0.027650   \n",
       "1    0.735294     -0.478884         0.013265         0.120253       -0.106988   \n",
       "2    0.381679      0.243321         0.012732         0.003154        0.009578   \n",
       "3    0.446429      0.118543         0.003432         0.007056       -0.003625   \n",
       "4    0.628931     -0.252991         0.009463         0.044130       -0.034667   \n",
       "\n",
       "   EloA_Global  EloB_Global  EloA_Surface  EloB_Surface  EloDiff_Global  \\\n",
       "0  1599.013330  1350.351456   1558.723048   1465.261433      248.661874   \n",
       "1  1579.481871  1687.476858   1528.176432   1648.849603     -107.994986   \n",
       "2  1523.867714  1462.128763   1447.222082   1526.381429       61.738951   \n",
       "3  1445.362211  1470.563932   1450.908581   1513.345983      -25.201721   \n",
       "4  1560.888436  1553.980573   1516.736659   1528.145373        6.907863   \n",
       "\n",
       "   EloDiff_Surface SurfaceText  RoundOrder  \n",
       "0        93.461615       Grass         2.0  \n",
       "1      -120.673171       Grass         2.0  \n",
       "2       -79.159346       Grass         2.0  \n",
       "3       -62.437401       Grass         2.0  \n",
       "4       -11.408714       Grass         2.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actualizar el conjunto de entrenamiento: añadir first_round al train actual\n",
    "train_third_round = pd.concat([second_round, train_second_round], ignore_index=True)\n",
    "\n",
    "print(f\"Tamaño del train original: {len(train_third_round) - len(second_round)}\")\n",
    "print(f\"Tamaño de first_round añadido: {len(second_round)}\")\n",
    "print(f\"Tamaño del nuevo train: {len(train_third_round)}\")\n",
    "print(f\"\\nTrain actualizado correctamente. Listo para la siguiente fase.\")\n",
    "\n",
    "train_third_round.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "119d90a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ACCURACY FINAL TEST CRONOLÓGIC: 0.7500\n",
      "Brier Score: 0.1413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7778    0.7778    0.7778         9\n",
      "           1     0.7143    0.7143    0.7143         7\n",
      "\n",
      "    accuracy                         0.7500        16\n",
      "   macro avg     0.7460    0.7460    0.7460        16\n",
      "weighted avg     0.7500    0.7500    0.7500        16\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "X_train = train_third_round[features].fillna(0)\n",
    "X_test = third_round[features].fillna(0)\n",
    "y_train = train_third_round['WinnerBinary']\n",
    "y_test = third_round['WinnerBinary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "base_model = XGBClassifier(\n",
    "    n_estimators=500,                    # Nombre total d'arbres (boosting rounds) que es construiran. 500 és un valor força alt, bo per a un bon rendiment si es controla l'overfitting.\n",
    "    max_depth=6,                         # Profunditat màxima de cada arbre. 6 és un valor moderat: permet interaccions complexes sense fer els arbres excessivament profunds.\n",
    "    learning_rate=0.02,                  # Taxa d'aprenentatge (eta). 0.02 és bastant baixa → aprenentatge lent i estable, ideal quan tens molts estimators (500).\n",
    "    subsample=0.85,                      # Percentatge de mostres (files) que s'utilitzen per entrenar cada arbre. 0.85 = 85% → ajuda a reduir overfitting i afegeix variància (com bagging).\n",
    "    colsample_bytree=0.85,               # Percentatge de columnes (variables) que s'agafen aleatòriament per cada arbre. 85% → també redueix overfitting i millora la generalització.\n",
    "    min_child_weight=5,                  # Suma mínima del pes Hessiana en un node fill. Valors >1 fan el model més conservador: evita dividir nodes amb poca informació.\n",
    "    gamma=0.1,                           # Minimització mínima de la funció de pèrdua necessària per fer una partició addicional (regularització per poda). 0.1 afavoreix arbres més simples.\n",
    "    reg_alpha=0.1,                       # Terme de regularització L1 sobre els pesos de les fulles. Ajuda a fer sparseness i és útil quan hi ha moltes variables irrellevants.\n",
    "    reg_lambda=1.0,                      # Terme de regularització L2 (més suau que L1). 1.0 és el valor per defecte i sol funcionar bé en la majoria de casos.\n",
    "    random_state=42,                     # Llavor per a la reproductibilitat dels resultats (aleatorietat controlada).\n",
    "    n_jobs=-1,                           # Utilitza tots els nuclis disponibles del processador per entrenar en paral·lel → molt més ràpid.\n",
    "    eval_metric='logloss'                # Mètrica d'avaluació durant l'entrenament (per classificació binària/multiclasse). 'logloss' = logarithmic loss (cross-entropy).\n",
    ")\n",
    "\n",
    "model = CalibratedClassifierCV(base_model, method='isotonic', cv=5)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "pred = model.predict(X_test_sc)\n",
    "prob = model.predict_proba(X_test_sc)[:, 1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "brier = brier_score_loss(y_test, prob)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ACCURACY FINAL TEST CRONOLÓGIC: {acc:.4f}\")\n",
    "print(f\"Brier Score: {brier:.4f}\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c3af78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DETALLADOS POR FILA:\n",
      "====================================================================================================\n",
      "\n",
      "Total de predicciones: 16\n",
      "Correctas: 12 (75.00%)\n",
      "Fallidas: 4 (25.00%)\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68289</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Mannarino A.</td>\n",
       "      <td>Rublev A.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288673</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68290</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>Rinderknech A.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.474551</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68293</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Borges N.</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288052</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68294</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Bellucci M.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383733</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68295</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Struff J.L.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948323</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68296</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Davidovich Fokina A.</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234247</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68297</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Darderi L.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453224</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68298</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Fonseca J.</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.710543</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68299</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>Cilic M.</td>\n",
       "      <td>Munar J.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735884</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68300</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Kecmanovic M.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964464</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68301</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>Martinez P.</td>\n",
       "      <td>Sinner J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021205</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68302</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>Dimitrov G.</td>\n",
       "      <td>Ofner S.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.764123</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68303</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>Fucsovics M.</td>\n",
       "      <td>Shelton B.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240784</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68304</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>Mensik J.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445961</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68305</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>De Minaur A.</td>\n",
       "      <td>Holmgren A.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857472</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68306</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>Nakashima B.</td>\n",
       "      <td>Sonego L.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625038</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date               PlayerA         PlayerB  WinnerBinary  \\\n",
       "68289  2025-07-04          Mannarino A.       Rublev A.             0   \n",
       "68290  2025-07-04          Majchrzak K.  Rinderknech A.             1   \n",
       "68293  2025-07-04             Borges N.    Khachanov K.             0   \n",
       "68294  2025-07-04           Bellucci M.       Norrie C.             0   \n",
       "68295  2025-07-04            Alcaraz C.     Struff J.L.             1   \n",
       "68296  2025-07-04  Davidovich Fokina A.        Fritz T.             0   \n",
       "68297  2025-07-04            Darderi L.     Thompson J.             0   \n",
       "68298  2025-07-04            Fonseca J.        Jarry N.             0   \n",
       "68299  2025-07-05              Cilic M.        Munar J.             1   \n",
       "68300  2025-07-05           Djokovic N.   Kecmanovic M.             1   \n",
       "68301  2025-07-05           Martinez P.       Sinner J.             0   \n",
       "68302  2025-07-05           Dimitrov G.        Ofner S.             1   \n",
       "68303  2025-07-05          Fucsovics M.      Shelton B.             0   \n",
       "68304  2025-07-05            Cobolli F.       Mensik J.             1   \n",
       "68305  2025-07-05          De Minaur A.     Holmgren A.             1   \n",
       "68306  2025-07-05          Nakashima B.       Sonego L.             0   \n",
       "\n",
       "       Predicted  Probability     Result  \n",
       "68289          0     0.288673  ✓ Correct  \n",
       "68290          0     0.474551   ✗ Failed  \n",
       "68293          0     0.288052  ✓ Correct  \n",
       "68294          0     0.383733  ✓ Correct  \n",
       "68295          1     0.948323  ✓ Correct  \n",
       "68296          0     0.234247  ✓ Correct  \n",
       "68297          0     0.453224  ✓ Correct  \n",
       "68298          1     0.710543   ✗ Failed  \n",
       "68299          1     0.735884  ✓ Correct  \n",
       "68300          1     0.964464  ✓ Correct  \n",
       "68301          0     0.021205  ✓ Correct  \n",
       "68302          1     0.764123  ✓ Correct  \n",
       "68303          0     0.240784  ✓ Correct  \n",
       "68304          0     0.445961   ✗ Failed  \n",
       "68305          1     0.857472  ✓ Correct  \n",
       "68306          1     0.625038   ✗ Failed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "PREDICCIONES FALLIDAS:\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68290</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>Rinderknech A.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.474551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68298</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Fonseca J.</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.710543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68304</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>Mensik J.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68306</th>\n",
       "      <td>2025-07-05</td>\n",
       "      <td>Nakashima B.</td>\n",
       "      <td>Sonego L.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date       PlayerA         PlayerB  WinnerBinary  Predicted  \\\n",
       "68290  2025-07-04  Majchrzak K.  Rinderknech A.             1          0   \n",
       "68298  2025-07-04    Fonseca J.        Jarry N.             0          1   \n",
       "68304  2025-07-05    Cobolli F.       Mensik J.             1          0   \n",
       "68306  2025-07-05  Nakashima B.       Sonego L.             0          1   \n",
       "\n",
       "       Probability  \n",
       "68290     0.474551  \n",
       "68298     0.710543  \n",
       "68304     0.445961  \n",
       "68306     0.625038  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df, failed_df = analyze_predictions(\n",
    "    df=third_round,\n",
    "    y_true=third_round[\"WinnerBinary\"].values,\n",
    "    y_pred=pred,\n",
    "    y_prob=prob,\n",
    "    date_col=\"Date\",\n",
    "    player_a_col=\"PlayerA\",\n",
    "    player_b_col=\"PlayerB\",\n",
    "    true_col_name=\"WinnerBinary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1652bc",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Fourth Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e6df5b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del train original: 68291\n",
      "Tamaño de first_round añadido: 16\n",
      "Tamaño del nuevo train: 68307\n",
      "\n",
      "Train actualizado correctamente. Listo para la siguiente fase.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Loser</th>\n",
       "      <th>WRank</th>\n",
       "      <th>LRank</th>\n",
       "      <th>W1</th>\n",
       "      <th>L1</th>\n",
       "      <th>W2</th>\n",
       "      <th>L2</th>\n",
       "      <th>W3</th>\n",
       "      <th>L3</th>\n",
       "      <th>W4</th>\n",
       "      <th>L4</th>\n",
       "      <th>W5</th>\n",
       "      <th>L5</th>\n",
       "      <th>Wsets</th>\n",
       "      <th>Lsets</th>\n",
       "      <th>Comment</th>\n",
       "      <th>CBW</th>\n",
       "      <th>CBL</th>\n",
       "      <th>GBW</th>\n",
       "      <th>GBL</th>\n",
       "      <th>IWW</th>\n",
       "      <th>IWL</th>\n",
       "      <th>SBW</th>\n",
       "      <th>SBL</th>\n",
       "      <th>B365W</th>\n",
       "      <th>B365L</th>\n",
       "      <th>B&amp;WW</th>\n",
       "      <th>B&amp;WL</th>\n",
       "      <th>EXW</th>\n",
       "      <th>EXL</th>\n",
       "      <th>PSW</th>\n",
       "      <th>PSL</th>\n",
       "      <th>WPts</th>\n",
       "      <th>LPts</th>\n",
       "      <th>UBW</th>\n",
       "      <th>UBL</th>\n",
       "      <th>LBW</th>\n",
       "      <th>LBL</th>\n",
       "      <th>SJW</th>\n",
       "      <th>SJL</th>\n",
       "      <th>MaxW</th>\n",
       "      <th>MaxL</th>\n",
       "      <th>AvgW</th>\n",
       "      <th>AvgL</th>\n",
       "      <th>BFEW</th>\n",
       "      <th>BFEL</th>\n",
       "      <th>MaxWin</th>\n",
       "      <th>MaxLoss</th>\n",
       "      <th>AvgWin</th>\n",
       "      <th>AvgLoss</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>RankA</th>\n",
       "      <th>RankB</th>\n",
       "      <th>RankDiff</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>MaxOddsPlayerA</th>\n",
       "      <th>MaxOddsPlayerB</th>\n",
       "      <th>AvgOddsPlayerA</th>\n",
       "      <th>AvgOddsPlayerB</th>\n",
       "      <th>H2H_A_wins</th>\n",
       "      <th>H2H_B_wins</th>\n",
       "      <th>H2H_Diff</th>\n",
       "      <th>WinsA</th>\n",
       "      <th>LossesA</th>\n",
       "      <th>WinsB</th>\n",
       "      <th>LossesB</th>\n",
       "      <th>WinRateA_cum</th>\n",
       "      <th>WinRateB_cum</th>\n",
       "      <th>Form10A</th>\n",
       "      <th>Form10B</th>\n",
       "      <th>RestDaysA</th>\n",
       "      <th>RestDaysB</th>\n",
       "      <th>DiffWR</th>\n",
       "      <th>DiffForm</th>\n",
       "      <th>DiffRest</th>\n",
       "      <th>LogRankDiff</th>\n",
       "      <th>H2HDiff</th>\n",
       "      <th>ProbA_odds</th>\n",
       "      <th>ProbB_odds</th>\n",
       "      <th>OddsProbDiff</th>\n",
       "      <th>WinRateA_x_Rank</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "      <th>SurfaceText</th>\n",
       "      <th>RoundOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3rd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Rublev A.</td>\n",
       "      <td>Mannarino A.</td>\n",
       "      <td>14.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.31</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.27</td>\n",
       "      <td>3.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1.275</td>\n",
       "      <td>3.855</td>\n",
       "      <td>Mannarino A.</td>\n",
       "      <td>Rublev A.</td>\n",
       "      <td>123.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.31</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>298</td>\n",
       "      <td>344</td>\n",
       "      <td>336</td>\n",
       "      <td>188</td>\n",
       "      <td>0.464174</td>\n",
       "      <td>0.641221</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.177047</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.173127</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>-0.519456</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>-0.042028</td>\n",
       "      <td>1412.322544</td>\n",
       "      <td>1600.606579</td>\n",
       "      <td>1545.683690</td>\n",
       "      <td>1554.029660</td>\n",
       "      <td>-188.284035</td>\n",
       "      <td>-8.345970</td>\n",
       "      <td>Grass</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3rd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>Rinderknech A.</td>\n",
       "      <td>109.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.85</td>\n",
       "      <td>527.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.990</td>\n",
       "      <td>1.875</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>Rinderknech A.</td>\n",
       "      <td>109.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>81</td>\n",
       "      <td>95</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.460227</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.053448</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414682</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>-0.050125</td>\n",
       "      <td>0.003732</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>-0.002660</td>\n",
       "      <td>1441.038574</td>\n",
       "      <td>1468.420628</td>\n",
       "      <td>1500.291002</td>\n",
       "      <td>1482.169575</td>\n",
       "      <td>-27.382054</td>\n",
       "      <td>18.121427</td>\n",
       "      <td>Grass</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3rd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>Borges N.</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.48</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.420</td>\n",
       "      <td>3.015</td>\n",
       "      <td>Borges N.</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>285</td>\n",
       "      <td>205</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.106223</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615186</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>-0.347807</td>\n",
       "      <td>0.012849</td>\n",
       "      <td>0.029082</td>\n",
       "      <td>-0.016233</td>\n",
       "      <td>1540.239490</td>\n",
       "      <td>1602.223693</td>\n",
       "      <td>1471.208116</td>\n",
       "      <td>1564.824598</td>\n",
       "      <td>-61.984204</td>\n",
       "      <td>-93.616482</td>\n",
       "      <td>Grass</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3rd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>Bellucci M.</td>\n",
       "      <td>61.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>952.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.585</td>\n",
       "      <td>2.400</td>\n",
       "      <td>Bellucci M.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>73.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>214</td>\n",
       "      <td>156</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.578378</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.137202</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.613497</td>\n",
       "      <td>-0.222872</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.009482</td>\n",
       "      <td>-0.003438</td>\n",
       "      <td>1471.831789</td>\n",
       "      <td>1585.578375</td>\n",
       "      <td>1493.135817</td>\n",
       "      <td>1542.046522</td>\n",
       "      <td>-113.746586</td>\n",
       "      <td>-48.910705</td>\n",
       "      <td>Grass</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3rd Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Struff J.L.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.04</td>\n",
       "      <td>11.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.05</td>\n",
       "      <td>15.53</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.05</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1.03</td>\n",
       "      <td>12.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.05</td>\n",
       "      <td>15.53</td>\n",
       "      <td>1.045</td>\n",
       "      <td>13.265</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Struff J.L.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.05</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1.03</td>\n",
       "      <td>12.61</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>236</td>\n",
       "      <td>59</td>\n",
       "      <td>208</td>\n",
       "      <td>241</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.463252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336748</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.135167</td>\n",
       "      <td>2</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.396294</td>\n",
       "      <td>1922.092396</td>\n",
       "      <td>1457.114874</td>\n",
       "      <td>1727.158193</td>\n",
       "      <td>1529.553850</td>\n",
       "      <td>464.977522</td>\n",
       "      <td>197.604343</td>\n",
       "      <td>Grass</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATP Location Tournament        Date  Series  Court  Surface      Round  \\\n",
       "0   36   London  Wimbledon  2025-07-04       2      1        2  3rd Round   \n",
       "1   36   London  Wimbledon  2025-07-04       2      1        2  3rd Round   \n",
       "2   36   London  Wimbledon  2025-07-04       2      1        2  3rd Round   \n",
       "3   36   London  Wimbledon  2025-07-04       2      1        2  3rd Round   \n",
       "4   36   London  Wimbledon  2025-07-04       2      1        2  3rd Round   \n",
       "\n",
       "   Best of        Winner           Loser  WRank  LRank   W1   L1   W2   L2  \\\n",
       "0      5.0     Rublev A.    Mannarino A.   14.0  123.0  7.0  5.0  6.0  2.0   \n",
       "1      5.0  Majchrzak K.  Rinderknech A.  109.0   72.0  6.0  3.0  7.0  6.0   \n",
       "2      5.0  Khachanov K.       Borges N.   20.0   37.0  7.0  6.0  4.0  6.0   \n",
       "3      5.0     Norrie C.     Bellucci M.   61.0   73.0  7.0  6.0  6.0  4.0   \n",
       "4      5.0    Alcaraz C.     Struff J.L.    2.0  125.0  6.0  1.0  3.0  6.0   \n",
       "\n",
       "    W3   L3   W4   L4   W5   L5  Wsets  Lsets    Comment  CBW  CBL  GBW  GBL  \\\n",
       "0  6.0  3.0  NaN  NaN  NaN  NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN   \n",
       "1  7.0  6.0  NaN  NaN  NaN  NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN   \n",
       "2  4.0  6.0  6.0  3.0  7.0  6.0    3.0    2.0  Completed  NaN  NaN  NaN  NaN   \n",
       "3  6.0  3.0  NaN  NaN  NaN  NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN   \n",
       "4  6.0  3.0  6.0  4.0  NaN  NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   IWW  IWL  SBW  SBL  B365W  B365L  B&WW  B&WL  EXW  EXL   PSW    PSL  \\\n",
       "0  NaN  NaN  NaN  NaN   1.25   3.75   NaN   NaN  NaN  NaN  1.30   3.96   \n",
       "1  NaN  NaN  NaN  NaN   1.91   1.90   NaN   NaN  NaN  NaN  2.07   1.85   \n",
       "2  NaN  NaN  NaN  NaN   1.40   3.00   NaN   NaN  NaN  NaN  1.44   3.03   \n",
       "3  NaN  NaN  NaN  NaN   1.57   2.30   NaN   NaN  NaN  NaN  1.60   2.50   \n",
       "4  NaN  NaN  NaN  NaN   1.04  11.00   NaN   NaN  NaN  NaN  1.05  15.53   \n",
       "\n",
       "     WPts    LPts  UBW  UBL  LBW  LBL  SJW  SJL  MaxW   MaxL  AvgW   AvgL  \\\n",
       "0  2920.0   477.0  NaN  NaN  NaN  NaN  NaN  NaN  1.31   4.10  1.27   3.77   \n",
       "1   527.0   873.0  NaN  NaN  NaN  NaN  NaN  NaN  2.10   1.90  2.00   1.80   \n",
       "2  2240.0  1400.0  NaN  NaN  NaN  NaN  NaN  NaN  1.48   3.05  1.41   2.89   \n",
       "3   952.0   864.0  NaN  NaN  NaN  NaN  NaN  NaN  1.63   2.56  1.56   2.41   \n",
       "4  9300.0   475.0  NaN  NaN  NaN  NaN  NaN  NaN  1.05  18.00  1.03  12.61   \n",
       "\n",
       "   BFEW  BFEL  MaxWin  MaxLoss  AvgWin  AvgLoss       PlayerA         PlayerB  \\\n",
       "0   NaN   NaN    1.30     3.96   1.275    3.855  Mannarino A.       Rublev A.   \n",
       "1   NaN   NaN    2.07     1.90   1.990    1.875  Majchrzak K.  Rinderknech A.   \n",
       "2   NaN   NaN    1.44     3.03   1.420    3.015     Borges N.    Khachanov K.   \n",
       "3   NaN   NaN    1.60     2.50   1.585    2.400   Bellucci M.       Norrie C.   \n",
       "4   NaN   NaN    1.05    15.53   1.045   13.265    Alcaraz C.     Struff J.L.   \n",
       "\n",
       "   RankA  RankB  RankDiff  WinnerBinary  MaxOddsPlayerA  MaxOddsPlayerB  \\\n",
       "0  123.0   14.0     109.0             0            4.10            1.31   \n",
       "1  109.0   72.0      37.0             1            2.10            1.90   \n",
       "2   37.0   20.0      17.0             0            3.05            1.48   \n",
       "3   73.0   61.0      12.0             0            2.56            1.63   \n",
       "4    2.0  125.0    -123.0             1            1.05           18.00   \n",
       "\n",
       "   AvgOddsPlayerA  AvgOddsPlayerB  H2H_A_wins  H2H_B_wins  H2H_Diff  WinsA  \\\n",
       "0            3.77            1.27           1           3        -2    298   \n",
       "1            2.00            1.80           0           0         0     24   \n",
       "2            2.89            1.41           0           1        -1     58   \n",
       "3            2.41            1.56           0           0         0     15   \n",
       "4            1.03           12.61           3           1         2    236   \n",
       "\n",
       "   LossesA  WinsB  LossesB  WinRateA_cum  WinRateB_cum  Form10A  Form10B  \\\n",
       "0      344    336      188      0.464174      0.641221      0.4      0.7   \n",
       "1       35     81       95      0.406780      0.460227      0.5      0.6   \n",
       "2       64    285      205      0.475410      0.581633      0.6      0.7   \n",
       "3       19    214      156      0.441176      0.578378      0.4      0.6   \n",
       "4       59    208      241      0.800000      0.463252      1.0      0.4   \n",
       "\n",
       "   RestDaysA  RestDaysB    DiffWR  DiffForm  DiffRest  LogRankDiff  H2HDiff  \\\n",
       "0          2          2 -0.177047      -0.3         0     2.173127       -2   \n",
       "1          2          1 -0.053448      -0.1         1     0.414682        0   \n",
       "2          2          2 -0.106223      -0.1         0     0.615186       -1   \n",
       "3          2          2 -0.137202      -0.2         0     0.179586        0   \n",
       "4          2          1  0.336748       0.6         1    -4.135167        2   \n",
       "\n",
       "   ProbA_odds  ProbB_odds  OddsProbDiff  WinRateA_x_Rank  WinRateB_x_Rank  \\\n",
       "0    0.243902    0.763359     -0.519456         0.003774         0.045802   \n",
       "1    0.476190    0.526316     -0.050125         0.003732         0.006392   \n",
       "2    0.327869    0.675676     -0.347807         0.012849         0.029082   \n",
       "3    0.390625    0.613497     -0.222872         0.006044         0.009482   \n",
       "4    0.952381    0.055556      0.896825         0.400000         0.003706   \n",
       "\n",
       "   EfficiencyDiff  EloA_Global  EloB_Global  EloA_Surface  EloB_Surface  \\\n",
       "0       -0.042028  1412.322544  1600.606579   1545.683690   1554.029660   \n",
       "1       -0.002660  1441.038574  1468.420628   1500.291002   1482.169575   \n",
       "2       -0.016233  1540.239490  1602.223693   1471.208116   1564.824598   \n",
       "3       -0.003438  1471.831789  1585.578375   1493.135817   1542.046522   \n",
       "4        0.396294  1922.092396  1457.114874   1727.158193   1529.553850   \n",
       "\n",
       "   EloDiff_Global  EloDiff_Surface SurfaceText  RoundOrder  \n",
       "0     -188.284035        -8.345970       Grass         3.0  \n",
       "1      -27.382054        18.121427       Grass         3.0  \n",
       "2      -61.984204       -93.616482       Grass         3.0  \n",
       "3     -113.746586       -48.910705       Grass         3.0  \n",
       "4      464.977522       197.604343       Grass         3.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actualizar el conjunto de entrenamiento: añadir first_round al train actual\n",
    "train_fourth_round = pd.concat([third_round, train_third_round], ignore_index=True)\n",
    "\n",
    "print(f\"Tamaño del train original: {len(train_fourth_round) - len(third_round)}\")\n",
    "print(f\"Tamaño de first_round añadido: {len(third_round)}\")\n",
    "print(f\"Tamaño del nuevo train: {len(train_fourth_round)}\")\n",
    "print(f\"\\nTrain actualizado correctamente. Listo para la siguiente fase.\")\n",
    "\n",
    "train_fourth_round.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1ea33fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ACCURACY FINAL TEST CRONOLÓGIC: 0.8750\n",
      "Brier Score: 0.0792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7500    0.8571         4\n",
      "           1     0.8000    1.0000    0.8889         4\n",
      "\n",
      "    accuracy                         0.8750         8\n",
      "   macro avg     0.9000    0.8750    0.8730         8\n",
      "weighted avg     0.9000    0.8750    0.8730         8\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "X_train = train_fourth_round[features].fillna(0)\n",
    "X_test = fourth_round[features].fillna(0)\n",
    "y_train = train_fourth_round['WinnerBinary']\n",
    "y_test = fourth_round['WinnerBinary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "base_model = XGBClassifier(\n",
    "    n_estimators=500,                    # Nombre total d'arbres (boosting rounds) que es construiran. 500 és un valor força alt, bo per a un bon rendiment si es controla l'overfitting.\n",
    "    max_depth=6,                         # Profunditat màxima de cada arbre. 6 és un valor moderat: permet interaccions complexes sense fer els arbres excessivament profunds.\n",
    "    learning_rate=0.02,                  # Taxa d'aprenentatge (eta). 0.02 és bastant baixa → aprenentatge lent i estable, ideal quan tens molts estimators (500).\n",
    "    subsample=0.85,                      # Percentatge de mostres (files) que s'utilitzen per entrenar cada arbre. 0.85 = 85% → ajuda a reduir overfitting i afegeix variància (com bagging).\n",
    "    colsample_bytree=0.85,               # Percentatge de columnes (variables) que s'agafen aleatòriament per cada arbre. 85% → també redueix overfitting i millora la generalització.\n",
    "    min_child_weight=5,                  # Suma mínima del pes Hessiana en un node fill. Valors >1 fan el model més conservador: evita dividir nodes amb poca informació.\n",
    "    gamma=0.1,                           # Minimització mínima de la funció de pèrdua necessària per fer una partició addicional (regularització per poda). 0.1 afavoreix arbres més simples.\n",
    "    reg_alpha=0.1,                       # Terme de regularització L1 sobre els pesos de les fulles. Ajuda a fer sparseness i és útil quan hi ha moltes variables irrellevants.\n",
    "    reg_lambda=1.0,                      # Terme de regularització L2 (més suau que L1). 1.0 és el valor per defecte i sol funcionar bé en la majoria de casos.\n",
    "    random_state=42,                     # Llavor per a la reproductibilitat dels resultats (aleatorietat controlada).\n",
    "    n_jobs=-1,                           # Utilitza tots els nuclis disponibles del processador per entrenar en paral·lel → molt més ràpid.\n",
    "    eval_metric='logloss'                # Mètrica d'avaluació durant l'entrenament (per classificació binària/multiclasse). 'logloss' = logarithmic loss (cross-entropy).\n",
    ")\n",
    "\n",
    "model = CalibratedClassifierCV(base_model, method='isotonic', cv=5)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "pred = model.predict(X_test_sc)\n",
    "prob = model.predict_proba(X_test_sc)[:, 1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "brier = brier_score_loss(y_test, prob)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ACCURACY FINAL TEST CRONOLÓGIC: {acc:.4f}\")\n",
    "print(f\"Brier Score: {brier:.4f}\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "59f30df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DETALLADOS POR FILA:\n",
      "====================================================================================================\n",
      "\n",
      "Total de predicciones: 8\n",
      "Correctas: 7 (87.50%)\n",
      "Fallidas: 1 (12.50%)\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68307</th>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884897</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68308</th>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386972</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68309</th>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.725209</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68310</th>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Rublev A.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915370</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68311</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>Cilic M.</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549291</td>\n",
       "      <td>✗ Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68312</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>Shelton B.</td>\n",
       "      <td>Sonego L.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744875</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68313</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>Dimitrov G.</td>\n",
       "      <td>Sinner J.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057033</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68314</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>De Minaur A.</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133952</td>\n",
       "      <td>✓ Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date       PlayerA       PlayerB  WinnerBinary  Predicted  \\\n",
       "68307  2025-07-06      Fritz T.   Thompson J.             1          1   \n",
       "68308  2025-07-06      Jarry N.     Norrie C.             0          0   \n",
       "68309  2025-07-06  Khachanov K.  Majchrzak K.             1          1   \n",
       "68310  2025-07-06    Alcaraz C.     Rublev A.             1          1   \n",
       "68311  2025-07-07      Cilic M.    Cobolli F.             0          1   \n",
       "68312  2025-07-07    Shelton B.     Sonego L.             1          1   \n",
       "68313  2025-07-07   Dimitrov G.     Sinner J.             0          0   \n",
       "68314  2025-07-07  De Minaur A.   Djokovic N.             0          0   \n",
       "\n",
       "       Probability     Result  \n",
       "68307     0.884897  ✓ Correct  \n",
       "68308     0.386972  ✓ Correct  \n",
       "68309     0.725209  ✓ Correct  \n",
       "68310     0.915370  ✓ Correct  \n",
       "68311     0.549291   ✗ Failed  \n",
       "68312     0.744875  ✓ Correct  \n",
       "68313     0.057033  ✓ Correct  \n",
       "68314     0.133952  ✓ Correct  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "PREDICCIONES FALLIDAS:\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68311</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>Cilic M.</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date   PlayerA     PlayerB  WinnerBinary  Predicted  Probability\n",
       "68311  2025-07-07  Cilic M.  Cobolli F.             0          1     0.549291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df, failed_df = analyze_predictions(\n",
    "    df=fourth_round,\n",
    "    y_true=fourth_round[\"WinnerBinary\"].values,\n",
    "    y_pred=pred,\n",
    "    y_prob=prob,\n",
    "    date_col=\"Date\",\n",
    "    player_a_col=\"PlayerA\",\n",
    "    player_b_col=\"PlayerB\",\n",
    "    true_col_name=\"WinnerBinary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b06bb4d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quarter Finals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3de37251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del train original: 68307\n",
      "Tamaño de first_round añadido: 8\n",
      "Tamaño del nuevo train: 68315\n",
      "\n",
      "Train actualizado correctamente. Listo para la siguiente fase.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Loser</th>\n",
       "      <th>WRank</th>\n",
       "      <th>LRank</th>\n",
       "      <th>W1</th>\n",
       "      <th>L1</th>\n",
       "      <th>W2</th>\n",
       "      <th>L2</th>\n",
       "      <th>W3</th>\n",
       "      <th>L3</th>\n",
       "      <th>W4</th>\n",
       "      <th>L4</th>\n",
       "      <th>W5</th>\n",
       "      <th>L5</th>\n",
       "      <th>Wsets</th>\n",
       "      <th>Lsets</th>\n",
       "      <th>Comment</th>\n",
       "      <th>CBW</th>\n",
       "      <th>CBL</th>\n",
       "      <th>GBW</th>\n",
       "      <th>GBL</th>\n",
       "      <th>IWW</th>\n",
       "      <th>IWL</th>\n",
       "      <th>SBW</th>\n",
       "      <th>SBL</th>\n",
       "      <th>B365W</th>\n",
       "      <th>B365L</th>\n",
       "      <th>B&amp;WW</th>\n",
       "      <th>B&amp;WL</th>\n",
       "      <th>EXW</th>\n",
       "      <th>EXL</th>\n",
       "      <th>PSW</th>\n",
       "      <th>PSL</th>\n",
       "      <th>WPts</th>\n",
       "      <th>LPts</th>\n",
       "      <th>UBW</th>\n",
       "      <th>UBL</th>\n",
       "      <th>LBW</th>\n",
       "      <th>LBL</th>\n",
       "      <th>SJW</th>\n",
       "      <th>SJL</th>\n",
       "      <th>MaxW</th>\n",
       "      <th>MaxL</th>\n",
       "      <th>AvgW</th>\n",
       "      <th>AvgL</th>\n",
       "      <th>BFEW</th>\n",
       "      <th>BFEL</th>\n",
       "      <th>MaxWin</th>\n",
       "      <th>MaxLoss</th>\n",
       "      <th>AvgWin</th>\n",
       "      <th>AvgLoss</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>RankA</th>\n",
       "      <th>RankB</th>\n",
       "      <th>RankDiff</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>MaxOddsPlayerA</th>\n",
       "      <th>MaxOddsPlayerB</th>\n",
       "      <th>AvgOddsPlayerA</th>\n",
       "      <th>AvgOddsPlayerB</th>\n",
       "      <th>H2H_A_wins</th>\n",
       "      <th>H2H_B_wins</th>\n",
       "      <th>H2H_Diff</th>\n",
       "      <th>WinsA</th>\n",
       "      <th>LossesA</th>\n",
       "      <th>WinsB</th>\n",
       "      <th>LossesB</th>\n",
       "      <th>WinRateA_cum</th>\n",
       "      <th>WinRateB_cum</th>\n",
       "      <th>Form10A</th>\n",
       "      <th>Form10B</th>\n",
       "      <th>RestDaysA</th>\n",
       "      <th>RestDaysB</th>\n",
       "      <th>DiffWR</th>\n",
       "      <th>DiffForm</th>\n",
       "      <th>DiffRest</th>\n",
       "      <th>LogRankDiff</th>\n",
       "      <th>H2HDiff</th>\n",
       "      <th>ProbA_odds</th>\n",
       "      <th>ProbB_odds</th>\n",
       "      <th>OddsProbDiff</th>\n",
       "      <th>WinRateA_x_Rank</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "      <th>SurfaceText</th>\n",
       "      <th>RoundOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.16</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.145</td>\n",
       "      <td>5.930</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.16</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>189</td>\n",
       "      <td>147</td>\n",
       "      <td>165</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.131787</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.174752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.715010</td>\n",
       "      <td>0.120588</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>0.109880</td>\n",
       "      <td>1707.852520</td>\n",
       "      <td>1550.642850</td>\n",
       "      <td>1664.423582</td>\n",
       "      <td>1538.487318</td>\n",
       "      <td>157.209671</td>\n",
       "      <td>125.936264</td>\n",
       "      <td>Grass</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>61.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.04</td>\n",
       "      <td>952.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.850</td>\n",
       "      <td>1.975</td>\n",
       "      <td>Jarry N.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>143.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>110</td>\n",
       "      <td>215</td>\n",
       "      <td>156</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.579515</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.084102</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851971</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>1486.922241</td>\n",
       "      <td>1595.447958</td>\n",
       "      <td>1489.777273</td>\n",
       "      <td>1553.909340</td>\n",
       "      <td>-108.525717</td>\n",
       "      <td>-64.132067</td>\n",
       "      <td>Grass</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>20.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.370</td>\n",
       "      <td>3.280</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>Majchrzak K.</td>\n",
       "      <td>20.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>286</td>\n",
       "      <td>205</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>0.582485</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.165818</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.695616</td>\n",
       "      <td>3</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.029124</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>1618.542071</td>\n",
       "      <td>1462.742738</td>\n",
       "      <td>1578.571698</td>\n",
       "      <td>1518.487098</td>\n",
       "      <td>155.799333</td>\n",
       "      <td>60.084600</td>\n",
       "      <td>Grass</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Rublev A.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.08</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>8.57</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.11</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1.09</td>\n",
       "      <td>7.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>8.57</td>\n",
       "      <td>1.090</td>\n",
       "      <td>7.785</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Rublev A.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1.09</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>237</td>\n",
       "      <td>59</td>\n",
       "      <td>337</td>\n",
       "      <td>188</td>\n",
       "      <td>0.800676</td>\n",
       "      <td>0.641905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158771</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.945910</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.794518</td>\n",
       "      <td>0.400338</td>\n",
       "      <td>0.045850</td>\n",
       "      <td>0.354487</td>\n",
       "      <td>1922.469509</td>\n",
       "      <td>1605.061432</td>\n",
       "      <td>1730.475794</td>\n",
       "      <td>1562.615703</td>\n",
       "      <td>317.408077</td>\n",
       "      <td>167.860091</td>\n",
       "      <td>Grass</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>Cilic M.</td>\n",
       "      <td>24.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.855</td>\n",
       "      <td>2.015</td>\n",
       "      <td>Cilic M.</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>83.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>556</td>\n",
       "      <td>323</td>\n",
       "      <td>58</td>\n",
       "      <td>49</td>\n",
       "      <td>0.632537</td>\n",
       "      <td>0.542056</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.090481</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.240787</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.529101</td>\n",
       "      <td>-0.052910</td>\n",
       "      <td>0.007621</td>\n",
       "      <td>0.022586</td>\n",
       "      <td>-0.014965</td>\n",
       "      <td>1544.024883</td>\n",
       "      <td>1644.050776</td>\n",
       "      <td>1701.441745</td>\n",
       "      <td>1539.204396</td>\n",
       "      <td>-100.025893</td>\n",
       "      <td>162.237350</td>\n",
       "      <td>Grass</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATP Location Tournament        Date  Series  Court  Surface      Round  \\\n",
       "0   36   London  Wimbledon  2025-07-06       2      1        2  4th Round   \n",
       "1   36   London  Wimbledon  2025-07-06       2      1        2  4th Round   \n",
       "2   36   London  Wimbledon  2025-07-06       2      1        2  4th Round   \n",
       "3   36   London  Wimbledon  2025-07-06       2      1        2  4th Round   \n",
       "4   36   London  Wimbledon  2025-07-07       2      1        2  4th Round   \n",
       "\n",
       "   Best of        Winner         Loser  WRank  LRank   W1   L1   W2   L2   W3  \\\n",
       "0      5.0      Fritz T.   Thompson J.    5.0   44.0  6.0  1.0  3.0  0.0  NaN   \n",
       "1      5.0     Norrie C.      Jarry N.   61.0  143.0  6.0  3.0  7.0  6.0  6.0   \n",
       "2      5.0  Khachanov K.  Majchrzak K.   20.0  109.0  6.0  4.0  6.0  2.0  6.0   \n",
       "3      5.0    Alcaraz C.     Rublev A.    2.0   14.0  6.0  7.0  6.0  3.0  6.0   \n",
       "4      5.0    Cobolli F.      Cilic M.   24.0   83.0  6.0  4.0  6.0  4.0  6.0   \n",
       "\n",
       "    L3   W4   L4   W5   L5  Wsets  Lsets    Comment  CBW  CBL  GBW  GBL  IWW  \\\n",
       "0  NaN  NaN  NaN  NaN  NaN    1.0    0.0    Retired  NaN  NaN  NaN  NaN  NaN   \n",
       "1  7.0  6.0  7.0  6.0  3.0    3.0    2.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "2  3.0  NaN  NaN  NaN  NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "3  4.0  6.0  4.0  NaN  NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "4  7.0  7.0  6.0  NaN  NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   IWL  SBW  SBL  B365W  B365L  B&WW  B&WL  EXW  EXL   PSW   PSL    WPts  \\\n",
       "0  NaN  NaN  NaN   1.14   5.50   NaN   NaN  NaN  NaN  1.15  6.36  4635.0   \n",
       "1  NaN  NaN  NaN   1.83   1.91   NaN   NaN  NaN  NaN  1.87  2.04   952.0   \n",
       "2  NaN  NaN  NaN   1.36   3.20   NaN   NaN  NaN  NaN  1.38  3.36  2240.0   \n",
       "3  NaN  NaN  NaN   1.08   7.00   NaN   NaN  NaN  NaN  1.10  8.57  9300.0   \n",
       "4  NaN  NaN  NaN   1.83   2.00   NaN   NaN  NaN  NaN  1.88  2.03  2035.0   \n",
       "\n",
       "     LPts  UBW  UBL  LBW  LBL  SJW  SJL  MaxW  MaxL  AvgW  AvgL  BFEW  BFEL  \\\n",
       "0  1200.0  NaN  NaN  NaN  NaN  NaN  NaN  1.16  6.80  1.14  5.64   NaN   NaN   \n",
       "1   418.0  NaN  NaN  NaN  NaN  NaN  NaN  2.10  2.08  1.84  1.96   NaN   NaN   \n",
       "2   527.0  NaN  NaN  NaN  NaN  NaN  NaN  1.40  3.40  1.35  3.19   NaN   NaN   \n",
       "3  2920.0  NaN  NaN  NaN  NaN  NaN  NaN  1.11  9.40  1.09  7.50   NaN   NaN   \n",
       "4   722.0  NaN  NaN  NaN  NaN  NaN  NaN  1.89  2.10  1.79  2.01   NaN   NaN   \n",
       "\n",
       "   MaxWin  MaxLoss  AvgWin  AvgLoss       PlayerA       PlayerB  RankA  RankB  \\\n",
       "0    1.15     6.36   1.145    5.930      Fritz T.   Thompson J.    5.0   44.0   \n",
       "1    1.87     2.04   1.850    1.975      Jarry N.     Norrie C.  143.0   61.0   \n",
       "2    1.38     3.36   1.370    3.280  Khachanov K.  Majchrzak K.   20.0  109.0   \n",
       "3    1.10     8.57   1.090    7.785    Alcaraz C.     Rublev A.    2.0   14.0   \n",
       "4    1.88     2.03   1.855    2.015      Cilic M.    Cobolli F.   83.0   24.0   \n",
       "\n",
       "   RankDiff  WinnerBinary  MaxOddsPlayerA  MaxOddsPlayerB  AvgOddsPlayerA  \\\n",
       "0     -39.0             1            1.16            6.80            1.14   \n",
       "1      82.0             0            2.08            2.10            1.96   \n",
       "2     -89.0             1            1.40            3.40            1.35   \n",
       "3     -12.0             1            1.11            9.40            1.09   \n",
       "4      59.0             0            2.10            1.89            2.01   \n",
       "\n",
       "   AvgOddsPlayerB  H2H_A_wins  H2H_B_wins  H2H_Diff  WinsA  LossesA  WinsB  \\\n",
       "0            5.64           1           1         0    287      189    147   \n",
       "1            1.84           1           0         1    108      110    215   \n",
       "2            3.19           3           0         3    286      205     25   \n",
       "3            7.50           2           1         1    237       59    337   \n",
       "4            1.79           0           2        -2    556      323     58   \n",
       "\n",
       "   LossesB  WinRateA_cum  WinRateB_cum  Form10A  Form10B  RestDaysA  \\\n",
       "0      165      0.602941      0.471154      0.9      0.5          2   \n",
       "1      156      0.495413      0.579515      0.5      0.6          2   \n",
       "2       35      0.582485      0.416667      0.7      0.6          2   \n",
       "3      188      0.800676      0.641905      1.0      0.7          2   \n",
       "4       49      0.632537      0.542056      0.5      0.7          2   \n",
       "\n",
       "   RestDaysB    DiffWR  DiffForm  DiffRest  LogRankDiff  H2HDiff  ProbA_odds  \\\n",
       "0          2  0.131787       0.4         0    -2.174752        0    0.862069   \n",
       "1          2 -0.084102      -0.1         0     0.851971        1    0.480769   \n",
       "2          2  0.165818       0.1         0    -1.695616        3    0.714286   \n",
       "3          2  0.158771       0.3         0    -1.945910        1    0.900901   \n",
       "4          2  0.090481      -0.2         0     1.240787       -2    0.476190   \n",
       "\n",
       "   ProbB_odds  OddsProbDiff  WinRateA_x_Rank  WinRateB_x_Rank  EfficiencyDiff  \\\n",
       "0    0.147059      0.715010         0.120588         0.010708        0.109880   \n",
       "1    0.476190      0.004579         0.003464         0.009500       -0.006036   \n",
       "2    0.294118      0.420168         0.029124         0.003823        0.025302   \n",
       "3    0.106383      0.794518         0.400338         0.045850        0.354487   \n",
       "4    0.529101     -0.052910         0.007621         0.022586       -0.014965   \n",
       "\n",
       "   EloA_Global  EloB_Global  EloA_Surface  EloB_Surface  EloDiff_Global  \\\n",
       "0  1707.852520  1550.642850   1664.423582   1538.487318      157.209671   \n",
       "1  1486.922241  1595.447958   1489.777273   1553.909340     -108.525717   \n",
       "2  1618.542071  1462.742738   1578.571698   1518.487098      155.799333   \n",
       "3  1922.469509  1605.061432   1730.475794   1562.615703      317.408077   \n",
       "4  1544.024883  1644.050776   1701.441745   1539.204396     -100.025893   \n",
       "\n",
       "   EloDiff_Surface SurfaceText  RoundOrder  \n",
       "0       125.936264       Grass         4.0  \n",
       "1       -64.132067       Grass         4.0  \n",
       "2        60.084600       Grass         4.0  \n",
       "3       167.860091       Grass         4.0  \n",
       "4       162.237350       Grass         4.0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actualizar el conjunto de entrenamiento: añadir first_round al train actual\n",
    "train_quarter_finals = pd.concat([fourth_round, train_fourth_round], ignore_index=True)\n",
    "\n",
    "print(f\"Tamaño del train original: {len(train_quarter_finals) - len(fourth_round)}\")\n",
    "print(f\"Tamaño de first_round añadido: {len(fourth_round)}\")\n",
    "print(f\"Tamaño del nuevo train: {len(train_quarter_finals)}\")\n",
    "print(f\"\\nTrain actualizado correctamente. Listo para la siguiente fase.\")\n",
    "\n",
    "train_quarter_finals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bfb91536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ACCURACY FINAL TEST CRONOLÓGIC: 1.0000\n",
      "Brier Score: 0.0355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000         2\n",
      "           1     1.0000    1.0000    1.0000         2\n",
      "\n",
      "    accuracy                         1.0000         4\n",
      "   macro avg     1.0000    1.0000    1.0000         4\n",
      "weighted avg     1.0000    1.0000    1.0000         4\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "X_train = train_quarter_finals[features].fillna(0)\n",
    "X_test = quarter_finals[features].fillna(0)\n",
    "y_train = train_quarter_finals['WinnerBinary']\n",
    "y_test = quarter_finals['WinnerBinary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "base_model = XGBClassifier(\n",
    "    n_estimators=500,                    # Nombre total d'arbres (boosting rounds) que es construiran. 500 és un valor força alt, bo per a un bon rendiment si es controla l'overfitting.\n",
    "    max_depth=6,                         # Profunditat màxima de cada arbre. 6 és un valor moderat: permet interaccions complexes sense fer els arbres excessivament profunds.\n",
    "    learning_rate=0.02,                  # Taxa d'aprenentatge (eta). 0.02 és bastant baixa → aprenentatge lent i estable, ideal quan tens molts estimators (500).\n",
    "    subsample=0.85,                      # Percentatge de mostres (files) que s'utilitzen per entrenar cada arbre. 0.85 = 85% → ajuda a reduir overfitting i afegeix variància (com bagging).\n",
    "    colsample_bytree=0.85,               # Percentatge de columnes (variables) que s'agafen aleatòriament per cada arbre. 85% → també redueix overfitting i millora la generalització.\n",
    "    min_child_weight=5,                  # Suma mínima del pes Hessiana en un node fill. Valors >1 fan el model més conservador: evita dividir nodes amb poca informació.\n",
    "    gamma=0.1,                           # Minimització mínima de la funció de pèrdua necessària per fer una partició addicional (regularització per poda). 0.1 afavoreix arbres més simples.\n",
    "    reg_alpha=0.1,                       # Terme de regularització L1 sobre els pesos de les fulles. Ajuda a fer sparseness i és útil quan hi ha moltes variables irrellevants.\n",
    "    reg_lambda=1.0,                      # Terme de regularització L2 (més suau que L1). 1.0 és el valor per defecte i sol funcionar bé en la majoria de casos.\n",
    "    random_state=42,                     # Llavor per a la reproductibilitat dels resultats (aleatorietat controlada).\n",
    "    n_jobs=-1,                           # Utilitza tots els nuclis disponibles del processador per entrenar en paral·lel → molt més ràpid.\n",
    "    eval_metric='logloss'                # Mètrica d'avaluació durant l'entrenament (per classificació binària/multiclasse). 'logloss' = logarithmic loss (cross-entropy).\n",
    ")\n",
    "\n",
    "model = CalibratedClassifierCV(base_model, method='isotonic', cv=5)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "pred = model.predict(X_test_sc)\n",
    "prob = model.predict_proba(X_test_sc)[:, 1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "brier = brier_score_loss(y_test, prob)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ACCURACY FINAL TEST CRONOLÓGIC: {acc:.4f}\")\n",
    "print(f\"Brier Score: {brier:.4f}\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368ebf0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Semi Finals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "db67b73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del train original: 68315\n",
      "Tamaño de first_round añadido: 4\n",
      "Tamaño del nuevo train: 68319\n",
      "\n",
      "Train actualizado correctamente. Listo para la siguiente fase.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Loser</th>\n",
       "      <th>WRank</th>\n",
       "      <th>LRank</th>\n",
       "      <th>W1</th>\n",
       "      <th>L1</th>\n",
       "      <th>W2</th>\n",
       "      <th>L2</th>\n",
       "      <th>W3</th>\n",
       "      <th>L3</th>\n",
       "      <th>W4</th>\n",
       "      <th>L4</th>\n",
       "      <th>W5</th>\n",
       "      <th>L5</th>\n",
       "      <th>Wsets</th>\n",
       "      <th>Lsets</th>\n",
       "      <th>Comment</th>\n",
       "      <th>CBW</th>\n",
       "      <th>CBL</th>\n",
       "      <th>GBW</th>\n",
       "      <th>GBL</th>\n",
       "      <th>IWW</th>\n",
       "      <th>IWL</th>\n",
       "      <th>SBW</th>\n",
       "      <th>SBL</th>\n",
       "      <th>B365W</th>\n",
       "      <th>B365L</th>\n",
       "      <th>B&amp;WW</th>\n",
       "      <th>B&amp;WL</th>\n",
       "      <th>EXW</th>\n",
       "      <th>EXL</th>\n",
       "      <th>PSW</th>\n",
       "      <th>PSL</th>\n",
       "      <th>WPts</th>\n",
       "      <th>LPts</th>\n",
       "      <th>UBW</th>\n",
       "      <th>UBL</th>\n",
       "      <th>LBW</th>\n",
       "      <th>LBL</th>\n",
       "      <th>SJW</th>\n",
       "      <th>SJL</th>\n",
       "      <th>MaxW</th>\n",
       "      <th>MaxL</th>\n",
       "      <th>AvgW</th>\n",
       "      <th>AvgL</th>\n",
       "      <th>BFEW</th>\n",
       "      <th>BFEL</th>\n",
       "      <th>MaxWin</th>\n",
       "      <th>MaxLoss</th>\n",
       "      <th>AvgWin</th>\n",
       "      <th>AvgLoss</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>RankA</th>\n",
       "      <th>RankB</th>\n",
       "      <th>RankDiff</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>MaxOddsPlayerA</th>\n",
       "      <th>MaxOddsPlayerB</th>\n",
       "      <th>AvgOddsPlayerA</th>\n",
       "      <th>AvgOddsPlayerB</th>\n",
       "      <th>H2H_A_wins</th>\n",
       "      <th>H2H_B_wins</th>\n",
       "      <th>H2H_Diff</th>\n",
       "      <th>WinsA</th>\n",
       "      <th>LossesA</th>\n",
       "      <th>WinsB</th>\n",
       "      <th>LossesB</th>\n",
       "      <th>WinRateA_cum</th>\n",
       "      <th>WinRateB_cum</th>\n",
       "      <th>Form10A</th>\n",
       "      <th>Form10B</th>\n",
       "      <th>RestDaysA</th>\n",
       "      <th>RestDaysB</th>\n",
       "      <th>DiffWR</th>\n",
       "      <th>DiffForm</th>\n",
       "      <th>DiffRest</th>\n",
       "      <th>LogRankDiff</th>\n",
       "      <th>H2HDiff</th>\n",
       "      <th>ProbA_odds</th>\n",
       "      <th>ProbB_odds</th>\n",
       "      <th>OddsProbDiff</th>\n",
       "      <th>WinRateA_x_Rank</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "      <th>SurfaceText</th>\n",
       "      <th>RoundOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06</td>\n",
       "      <td>9.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.07</td>\n",
       "      <td>10.89</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.07</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.05</td>\n",
       "      <td>9.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.07</td>\n",
       "      <td>10.89</td>\n",
       "      <td>1.065</td>\n",
       "      <td>9.945</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.05</td>\n",
       "      <td>9.96</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>238</td>\n",
       "      <td>59</td>\n",
       "      <td>216</td>\n",
       "      <td>156</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.220702</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.417727</td>\n",
       "      <td>2</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.860505</td>\n",
       "      <td>0.400673</td>\n",
       "      <td>0.009519</td>\n",
       "      <td>0.391155</td>\n",
       "      <td>1924.389264</td>\n",
       "      <td>1605.524476</td>\n",
       "      <td>1734.472534</td>\n",
       "      <td>1565.095386</td>\n",
       "      <td>318.864788</td>\n",
       "      <td>169.377148</td>\n",
       "      <td>Grass</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.31</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.27</td>\n",
       "      <td>3.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1.290</td>\n",
       "      <td>3.905</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.31</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.27</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>288</td>\n",
       "      <td>189</td>\n",
       "      <td>287</td>\n",
       "      <td>205</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.525264</td>\n",
       "      <td>0.120755</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.091588</td>\n",
       "      <td>1712.986620</td>\n",
       "      <td>1623.755498</td>\n",
       "      <td>1669.539504</td>\n",
       "      <td>1585.603677</td>\n",
       "      <td>89.231123</td>\n",
       "      <td>83.935828</td>\n",
       "      <td>Grass</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.33</td>\n",
       "      <td>4630.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.12</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.09</td>\n",
       "      <td>7.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1.105</td>\n",
       "      <td>7.665</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>1.12</td>\n",
       "      <td>7.53</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>1093</td>\n",
       "      <td>215</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.835627</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.289331</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>-0.776578</td>\n",
       "      <td>0.022762</td>\n",
       "      <td>0.139271</td>\n",
       "      <td>-0.116509</td>\n",
       "      <td>1654.452037</td>\n",
       "      <td>1812.107149</td>\n",
       "      <td>1560.040292</td>\n",
       "      <td>1799.287697</td>\n",
       "      <td>-157.655113</td>\n",
       "      <td>-239.247405</td>\n",
       "      <td>Grass</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sinner J.</td>\n",
       "      <td>Shelton B.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.60</td>\n",
       "      <td>10430.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.285</td>\n",
       "      <td>3.600</td>\n",
       "      <td>Shelton B.</td>\n",
       "      <td>Sinner J.</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-4</td>\n",
       "      <td>93</td>\n",
       "      <td>65</td>\n",
       "      <td>272</td>\n",
       "      <td>86</td>\n",
       "      <td>0.588608</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.171169</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>-0.489858</td>\n",
       "      <td>0.058861</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>-0.700916</td>\n",
       "      <td>1636.090372</td>\n",
       "      <td>1905.275862</td>\n",
       "      <td>1531.208843</td>\n",
       "      <td>1610.036055</td>\n",
       "      <td>-269.185490</td>\n",
       "      <td>-78.827212</td>\n",
       "      <td>Grass</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4th Round</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.16</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.145</td>\n",
       "      <td>5.930</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Thompson J.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.16</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>189</td>\n",
       "      <td>147</td>\n",
       "      <td>165</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.131787</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.174752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.715010</td>\n",
       "      <td>0.120588</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>0.109880</td>\n",
       "      <td>1707.852520</td>\n",
       "      <td>1550.642850</td>\n",
       "      <td>1664.423582</td>\n",
       "      <td>1538.487318</td>\n",
       "      <td>157.209671</td>\n",
       "      <td>125.936264</td>\n",
       "      <td>Grass</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATP Location Tournament        Date  Series  Court  Surface          Round  \\\n",
       "0   36   London  Wimbledon  2025-07-08       2      1        2  Quarterfinals   \n",
       "1   36   London  Wimbledon  2025-07-08       2      1        2  Quarterfinals   \n",
       "2   36   London  Wimbledon  2025-07-09       2      1        2  Quarterfinals   \n",
       "3   36   London  Wimbledon  2025-07-09       2      1        2  Quarterfinals   \n",
       "4   36   London  Wimbledon  2025-07-06       2      1        2      4th Round   \n",
       "\n",
       "   Best of       Winner         Loser  WRank LRank   W1   L1   W2   L2   W3  \\\n",
       "0      5.0   Alcaraz C.     Norrie C.    2.0  61.0  6.0  2.0  6.0  3.0  6.0   \n",
       "1      5.0     Fritz T.  Khachanov K.    5.0  20.0  6.0  3.0  6.0  4.0  1.0   \n",
       "2      5.0  Djokovic N.    Cobolli F.    6.0  24.0  6.0  7.0  6.0  2.0  7.0   \n",
       "3      5.0    Sinner J.    Shelton B.    1.0  10.0  7.0  6.0  6.0  4.0  6.0   \n",
       "4      5.0     Fritz T.   Thompson J.    5.0  44.0  6.0  1.0  3.0  0.0  NaN   \n",
       "\n",
       "    L3   W4   L4  W5  L5  Wsets  Lsets    Comment  CBW  CBL  GBW  GBL  IWW  \\\n",
       "0  3.0  NaN  NaN NaN NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "1  6.0  7.0  6.0 NaN NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "2  5.0  6.0  4.0 NaN NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "3  4.0  NaN  NaN NaN NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "4  NaN  NaN  NaN NaN NaN    1.0    0.0    Retired  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   IWL  SBW  SBL  B365W  B365L  B&WW  B&WL  EXW  EXL   PSW    PSL     WPts  \\\n",
       "0  NaN  NaN  NaN   1.06   9.00   NaN   NaN  NaN  NaN  1.07  10.89   9300.0   \n",
       "1  NaN  NaN  NaN   1.29   3.75   NaN   NaN  NaN  NaN  1.29   4.06   4635.0   \n",
       "2  NaN  NaN  NaN   1.10   7.00   NaN   NaN  NaN  NaN  1.11   8.33   4630.0   \n",
       "3  NaN  NaN  NaN   1.25   3.60   NaN   NaN  NaN  NaN  1.32   3.60  10430.0   \n",
       "4  NaN  NaN  NaN   1.14   5.50   NaN   NaN  NaN  NaN  1.15   6.36   4635.0   \n",
       "\n",
       "     LPts  UBW  UBL  LBW  LBL  SJW  SJL  MaxW  MaxL  AvgW  AvgL  BFEW  BFEL  \\\n",
       "0   952.0  NaN  NaN  NaN  NaN  NaN  NaN  1.07  13.5  1.05  9.96   NaN   NaN   \n",
       "1  2240.0  NaN  NaN  NaN  NaN  NaN  NaN  1.31   4.2  1.27  3.76   NaN   NaN   \n",
       "2  2035.0  NaN  NaN  NaN  NaN  NaN  NaN  1.12   8.6  1.09  7.53   NaN   NaN   \n",
       "3  3130.0  NaN  NaN  NaN  NaN  NaN  NaN  1.34   3.9  1.29  3.58   NaN   NaN   \n",
       "4  1200.0  NaN  NaN  NaN  NaN  NaN  NaN  1.16   6.8  1.14  5.64   NaN   NaN   \n",
       "\n",
       "   MaxWin  MaxLoss  AvgWin  AvgLoss     PlayerA       PlayerB  RankA  RankB  \\\n",
       "0    1.07    10.89   1.065    9.945  Alcaraz C.     Norrie C.    2.0   61.0   \n",
       "1    1.29     4.06   1.290    3.905    Fritz T.  Khachanov K.    5.0   20.0   \n",
       "2    1.11     8.33   1.105    7.665  Cobolli F.   Djokovic N.   24.0    6.0   \n",
       "3    1.32     3.60   1.285    3.600  Shelton B.     Sinner J.   10.0    1.0   \n",
       "4    1.15     6.36   1.145    5.930    Fritz T.   Thompson J.    5.0   44.0   \n",
       "\n",
       "   RankDiff  WinnerBinary  MaxOddsPlayerA  MaxOddsPlayerB  AvgOddsPlayerA  \\\n",
       "0     -59.0             1            1.07           13.50            1.05   \n",
       "1     -15.0             1            1.31            4.20            1.27   \n",
       "2      18.0             0            8.60            1.12            7.53   \n",
       "3       9.0             0            3.90            1.34            3.58   \n",
       "4     -39.0             1            1.16            6.80            1.14   \n",
       "\n",
       "   AvgOddsPlayerB  H2H_A_wins  H2H_B_wins  H2H_Diff  WinsA  LossesA  WinsB  \\\n",
       "0            9.96           4           2         2    238       59    216   \n",
       "1            3.76           0           1        -1    288      189    287   \n",
       "2            1.09           0           1        -1     59       49   1093   \n",
       "3            1.29           1           5        -4     93       65    272   \n",
       "4            5.64           1           1         0    287      189    147   \n",
       "\n",
       "   LossesB  WinRateA_cum  WinRateB_cum  Form10A  Form10B  RestDaysA  \\\n",
       "0      156      0.801347      0.580645      1.0      0.7          2   \n",
       "1      205      0.603774      0.583333      0.9      0.8          2   \n",
       "2      215      0.546296      0.835627      0.7      0.9          2   \n",
       "3       86      0.588608      0.759777      0.6      0.8          2   \n",
       "4      165      0.602941      0.471154      0.9      0.5          2   \n",
       "\n",
       "   RestDaysB    DiffWR  DiffForm  DiffRest  LogRankDiff  H2HDiff  ProbA_odds  \\\n",
       "0          2  0.220702       0.3         0    -3.417727        2    0.934579   \n",
       "1          2  0.020440       0.1         0    -1.386294       -1    0.763359   \n",
       "2          2 -0.289331      -0.2         0     1.386294       -1    0.116279   \n",
       "3          2 -0.171169      -0.2         0     2.302585       -4    0.256410   \n",
       "4          2  0.131787       0.4         0    -2.174752        0    0.862069   \n",
       "\n",
       "   ProbB_odds  OddsProbDiff  WinRateA_x_Rank  WinRateB_x_Rank  EfficiencyDiff  \\\n",
       "0    0.074074      0.860505         0.400673         0.009519        0.391155   \n",
       "1    0.238095      0.525264         0.120755         0.029167        0.091588   \n",
       "2    0.892857     -0.776578         0.022762         0.139271       -0.116509   \n",
       "3    0.746269     -0.489858         0.058861         0.759777       -0.700916   \n",
       "4    0.147059      0.715010         0.120588         0.010708        0.109880   \n",
       "\n",
       "   EloA_Global  EloB_Global  EloA_Surface  EloB_Surface  EloDiff_Global  \\\n",
       "0  1924.389264  1605.524476   1734.472534   1565.095386      318.864788   \n",
       "1  1712.986620  1623.755498   1669.539504   1585.603677       89.231123   \n",
       "2  1654.452037  1812.107149   1560.040292   1799.287697     -157.655113   \n",
       "3  1636.090372  1905.275862   1531.208843   1610.036055     -269.185490   \n",
       "4  1707.852520  1550.642850   1664.423582   1538.487318      157.209671   \n",
       "\n",
       "   EloDiff_Surface SurfaceText  RoundOrder  \n",
       "0       169.377148       Grass         6.0  \n",
       "1        83.935828       Grass         6.0  \n",
       "2      -239.247405       Grass         6.0  \n",
       "3       -78.827212       Grass         6.0  \n",
       "4       125.936264       Grass         4.0  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actualizar el conjunto de entrenamiento: añadir first_round al train actual\n",
    "train_semi_finals = pd.concat([quarter_finals, train_quarter_finals], ignore_index=True)\n",
    "\n",
    "print(f\"Tamaño del train original: {len(train_semi_finals) - len(quarter_finals)}\")\n",
    "print(f\"Tamaño de first_round añadido: {len(quarter_finals)}\")\n",
    "print(f\"Tamaño del nuevo train: {len(train_semi_finals)}\")\n",
    "print(f\"\\nTrain actualizado correctamente. Listo para la siguiente fase.\")\n",
    "\n",
    "train_semi_finals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "70e0033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ACCURACY FINAL TEST CRONOLÓGIC: 1.0000\n",
      "Brier Score: 0.0355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000         2\n",
      "           1     1.0000    1.0000    1.0000         2\n",
      "\n",
      "    accuracy                         1.0000         4\n",
      "   macro avg     1.0000    1.0000    1.0000         4\n",
      "weighted avg     1.0000    1.0000    1.0000         4\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "base_model = XGBClassifier(\n",
    "    n_estimators=500,                    # Nombre total d'arbres (boosting rounds) que es construiran. 500 és un valor força alt, bo per a un bon rendiment si es controla l'overfitting.\n",
    "    max_depth=6,                         # Profunditat màxima de cada arbre. 6 és un valor moderat: permet interaccions complexes sense fer els arbres excessivament profunds.\n",
    "    learning_rate=0.02,                  # Taxa d'aprenentatge (eta). 0.02 és bastant baixa → aprenentatge lent i estable, ideal quan tens molts estimators (500).\n",
    "    subsample=0.85,                      # Percentatge de mostres (files) que s'utilitzen per entrenar cada arbre. 0.85 = 85% → ajuda a reduir overfitting i afegeix variància (com bagging).\n",
    "    colsample_bytree=0.85,               # Percentatge de columnes (variables) que s'agafen aleatòriament per cada arbre. 85% → també redueix overfitting i millora la generalització.\n",
    "    min_child_weight=5,                  # Suma mínima del pes Hessiana en un node fill. Valors >1 fan el model més conservador: evita dividir nodes amb poca informació.\n",
    "    gamma=0.1,                           # Minimització mínima de la funció de pèrdua necessària per fer una partició addicional (regularització per poda). 0.1 afavoreix arbres més simples.\n",
    "    reg_alpha=0.1,                       # Terme de regularització L1 sobre els pesos de les fulles. Ajuda a fer sparseness i és útil quan hi ha moltes variables irrellevants.\n",
    "    reg_lambda=1.0,                      # Terme de regularització L2 (més suau que L1). 1.0 és el valor per defecte i sol funcionar bé en la majoria de casos.\n",
    "    random_state=42,                     # Llavor per a la reproductibilitat dels resultats (aleatorietat controlada).\n",
    "    n_jobs=-1,                           # Utilitza tots els nuclis disponibles del processador per entrenar en paral·lel → molt més ràpid.\n",
    "    eval_metric='logloss'                # Mètrica d'avaluació durant l'entrenament (per classificació binària/multiclasse). 'logloss' = logarithmic loss (cross-entropy).\n",
    ")\n",
    "\n",
    "model = CalibratedClassifierCV(base_model, method='isotonic', cv=5)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "pred = model.predict(X_test_sc)\n",
    "prob = model.predict_proba(X_test_sc)[:, 1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "brier = brier_score_loss(y_test, prob)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ACCURACY FINAL TEST CRONOLÓGIC: {acc:.4f}\")\n",
    "print(f\"Brier Score: {brier:.4f}\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2f5d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ac08be2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del train original: 2\n",
      "Tamaño de first_round añadido: 68319\n",
      "Tamaño del nuevo train: 68321\n",
      "\n",
      "Train actualizado correctamente. Listo para la siguiente fase.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Loser</th>\n",
       "      <th>WRank</th>\n",
       "      <th>LRank</th>\n",
       "      <th>W1</th>\n",
       "      <th>L1</th>\n",
       "      <th>W2</th>\n",
       "      <th>L2</th>\n",
       "      <th>W3</th>\n",
       "      <th>L3</th>\n",
       "      <th>W4</th>\n",
       "      <th>L4</th>\n",
       "      <th>W5</th>\n",
       "      <th>L5</th>\n",
       "      <th>Wsets</th>\n",
       "      <th>Lsets</th>\n",
       "      <th>Comment</th>\n",
       "      <th>CBW</th>\n",
       "      <th>CBL</th>\n",
       "      <th>GBW</th>\n",
       "      <th>GBL</th>\n",
       "      <th>IWW</th>\n",
       "      <th>IWL</th>\n",
       "      <th>SBW</th>\n",
       "      <th>SBL</th>\n",
       "      <th>B365W</th>\n",
       "      <th>B365L</th>\n",
       "      <th>B&amp;WW</th>\n",
       "      <th>B&amp;WL</th>\n",
       "      <th>EXW</th>\n",
       "      <th>EXL</th>\n",
       "      <th>PSW</th>\n",
       "      <th>PSL</th>\n",
       "      <th>WPts</th>\n",
       "      <th>LPts</th>\n",
       "      <th>UBW</th>\n",
       "      <th>UBL</th>\n",
       "      <th>LBW</th>\n",
       "      <th>LBL</th>\n",
       "      <th>SJW</th>\n",
       "      <th>SJL</th>\n",
       "      <th>MaxW</th>\n",
       "      <th>MaxL</th>\n",
       "      <th>AvgW</th>\n",
       "      <th>AvgL</th>\n",
       "      <th>BFEW</th>\n",
       "      <th>BFEL</th>\n",
       "      <th>MaxWin</th>\n",
       "      <th>MaxLoss</th>\n",
       "      <th>AvgWin</th>\n",
       "      <th>AvgLoss</th>\n",
       "      <th>PlayerA</th>\n",
       "      <th>PlayerB</th>\n",
       "      <th>RankA</th>\n",
       "      <th>RankB</th>\n",
       "      <th>RankDiff</th>\n",
       "      <th>WinnerBinary</th>\n",
       "      <th>MaxOddsPlayerA</th>\n",
       "      <th>MaxOddsPlayerB</th>\n",
       "      <th>AvgOddsPlayerA</th>\n",
       "      <th>AvgOddsPlayerB</th>\n",
       "      <th>H2H_A_wins</th>\n",
       "      <th>H2H_B_wins</th>\n",
       "      <th>H2H_Diff</th>\n",
       "      <th>WinsA</th>\n",
       "      <th>LossesA</th>\n",
       "      <th>WinsB</th>\n",
       "      <th>LossesB</th>\n",
       "      <th>WinRateA_cum</th>\n",
       "      <th>WinRateB_cum</th>\n",
       "      <th>Form10A</th>\n",
       "      <th>Form10B</th>\n",
       "      <th>RestDaysA</th>\n",
       "      <th>RestDaysB</th>\n",
       "      <th>DiffWR</th>\n",
       "      <th>DiffForm</th>\n",
       "      <th>DiffRest</th>\n",
       "      <th>LogRankDiff</th>\n",
       "      <th>H2HDiff</th>\n",
       "      <th>ProbA_odds</th>\n",
       "      <th>ProbB_odds</th>\n",
       "      <th>OddsProbDiff</th>\n",
       "      <th>WinRateA_x_Rank</th>\n",
       "      <th>WinRateB_x_Rank</th>\n",
       "      <th>EfficiencyDiff</th>\n",
       "      <th>EloA_Global</th>\n",
       "      <th>EloB_Global</th>\n",
       "      <th>EloA_Surface</th>\n",
       "      <th>EloB_Surface</th>\n",
       "      <th>EloDiff_Global</th>\n",
       "      <th>EloDiff_Surface</th>\n",
       "      <th>SurfaceText</th>\n",
       "      <th>RoundOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.17</td>\n",
       "      <td>4.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.20</td>\n",
       "      <td>5.13</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.24</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.17</td>\n",
       "      <td>4.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.20</td>\n",
       "      <td>5.13</td>\n",
       "      <td>1.185</td>\n",
       "      <td>4.940</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.24</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.17</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>239</td>\n",
       "      <td>59</td>\n",
       "      <td>289</td>\n",
       "      <td>189</td>\n",
       "      <td>0.802013</td>\n",
       "      <td>0.604603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.197411</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.615975</td>\n",
       "      <td>0.401007</td>\n",
       "      <td>0.120921</td>\n",
       "      <td>0.280086</td>\n",
       "      <td>1926.287312</td>\n",
       "      <td>1723.803600</td>\n",
       "      <td>1738.429118</td>\n",
       "      <td>1679.760957</td>\n",
       "      <td>202.483711</td>\n",
       "      <td>58.668161</td>\n",
       "      <td>Grass</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Semifinals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sinner J.</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2.93</td>\n",
       "      <td>10430.0</td>\n",
       "      <td>4630.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.47</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.42</td>\n",
       "      <td>2.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.435</td>\n",
       "      <td>2.865</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Sinner J.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.42</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1094</td>\n",
       "      <td>215</td>\n",
       "      <td>273</td>\n",
       "      <td>86</td>\n",
       "      <td>0.835752</td>\n",
       "      <td>0.760446</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.075307</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.680272</td>\n",
       "      <td>-0.352403</td>\n",
       "      <td>0.139292</td>\n",
       "      <td>0.760446</td>\n",
       "      <td>-0.621154</td>\n",
       "      <td>1817.178196</td>\n",
       "      <td>1907.964530</td>\n",
       "      <td>1801.674504</td>\n",
       "      <td>1616.498027</td>\n",
       "      <td>-90.786334</td>\n",
       "      <td>185.176478</td>\n",
       "      <td>Grass</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06</td>\n",
       "      <td>9.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.07</td>\n",
       "      <td>10.89</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.07</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.05</td>\n",
       "      <td>9.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.07</td>\n",
       "      <td>10.89</td>\n",
       "      <td>1.065</td>\n",
       "      <td>9.945</td>\n",
       "      <td>Alcaraz C.</td>\n",
       "      <td>Norrie C.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.05</td>\n",
       "      <td>9.96</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>238</td>\n",
       "      <td>59</td>\n",
       "      <td>216</td>\n",
       "      <td>156</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.220702</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.417727</td>\n",
       "      <td>2</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.860505</td>\n",
       "      <td>0.400673</td>\n",
       "      <td>0.009519</td>\n",
       "      <td>0.391155</td>\n",
       "      <td>1924.389264</td>\n",
       "      <td>1605.524476</td>\n",
       "      <td>1734.472534</td>\n",
       "      <td>1565.095386</td>\n",
       "      <td>318.864788</td>\n",
       "      <td>169.377148</td>\n",
       "      <td>Grass</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.31</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.27</td>\n",
       "      <td>3.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1.290</td>\n",
       "      <td>3.905</td>\n",
       "      <td>Fritz T.</td>\n",
       "      <td>Khachanov K.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.31</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.27</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>288</td>\n",
       "      <td>189</td>\n",
       "      <td>287</td>\n",
       "      <td>205</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.525264</td>\n",
       "      <td>0.120755</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.091588</td>\n",
       "      <td>1712.986620</td>\n",
       "      <td>1623.755498</td>\n",
       "      <td>1669.539504</td>\n",
       "      <td>1585.603677</td>\n",
       "      <td>89.231123</td>\n",
       "      <td>83.935828</td>\n",
       "      <td>Grass</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>London</td>\n",
       "      <td>Wimbledon</td>\n",
       "      <td>2025-07-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Quarterfinals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.33</td>\n",
       "      <td>4630.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.12</td>\n",
       "      <td>8.60</td>\n",
       "      <td>1.09</td>\n",
       "      <td>7.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1.105</td>\n",
       "      <td>7.665</td>\n",
       "      <td>Cobolli F.</td>\n",
       "      <td>Djokovic N.</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>1.12</td>\n",
       "      <td>7.53</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>1093</td>\n",
       "      <td>215</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.835627</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.289331</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>-0.776578</td>\n",
       "      <td>0.022762</td>\n",
       "      <td>0.139271</td>\n",
       "      <td>-0.116509</td>\n",
       "      <td>1654.452037</td>\n",
       "      <td>1812.107149</td>\n",
       "      <td>1560.040292</td>\n",
       "      <td>1799.287697</td>\n",
       "      <td>-157.655113</td>\n",
       "      <td>-239.247405</td>\n",
       "      <td>Grass</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATP Location Tournament        Date  Series  Court  Surface          Round  \\\n",
       "0   36   London  Wimbledon  2025-07-11       2      1        2     Semifinals   \n",
       "1   36   London  Wimbledon  2025-07-11       2      1        2     Semifinals   \n",
       "2   36   London  Wimbledon  2025-07-08       2      1        2  Quarterfinals   \n",
       "3   36   London  Wimbledon  2025-07-08       2      1        2  Quarterfinals   \n",
       "4   36   London  Wimbledon  2025-07-09       2      1        2  Quarterfinals   \n",
       "\n",
       "   Best of       Winner         Loser  WRank LRank   W1   L1   W2   L2   W3  \\\n",
       "0      5.0   Alcaraz C.      Fritz T.    2.0   5.0  6.0  4.0  5.0  7.0  6.0   \n",
       "1      5.0    Sinner J.   Djokovic N.    1.0   6.0  6.0  3.0  6.0  3.0  6.0   \n",
       "2      5.0   Alcaraz C.     Norrie C.    2.0  61.0  6.0  2.0  6.0  3.0  6.0   \n",
       "3      5.0     Fritz T.  Khachanov K.    5.0  20.0  6.0  3.0  6.0  4.0  1.0   \n",
       "4      5.0  Djokovic N.    Cobolli F.    6.0  24.0  6.0  7.0  6.0  2.0  7.0   \n",
       "\n",
       "    L3   W4   L4  W5  L5  Wsets  Lsets    Comment  CBW  CBL  GBW  GBL  IWW  \\\n",
       "0  3.0  7.0  6.0 NaN NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "1  4.0  NaN  NaN NaN NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "2  3.0  NaN  NaN NaN NaN    3.0    0.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "3  6.0  7.0  6.0 NaN NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "4  5.0  6.0  4.0 NaN NaN    3.0    1.0  Completed  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   IWL  SBW  SBL  B365W  B365L  B&WW  B&WL  EXW  EXL   PSW    PSL     WPts  \\\n",
       "0  NaN  NaN  NaN   1.17   4.75   NaN   NaN  NaN  NaN  1.20   5.13   9300.0   \n",
       "1  NaN  NaN  NaN   1.40   2.80   NaN   NaN  NaN  NaN  1.47   2.93  10430.0   \n",
       "2  NaN  NaN  NaN   1.06   9.00   NaN   NaN  NaN  NaN  1.07  10.89   9300.0   \n",
       "3  NaN  NaN  NaN   1.29   3.75   NaN   NaN  NaN  NaN  1.29   4.06   4635.0   \n",
       "4  NaN  NaN  NaN   1.10   7.00   NaN   NaN  NaN  NaN  1.11   8.33   4630.0   \n",
       "\n",
       "     LPts  UBW  UBL  LBW  LBL  SJW  SJL  MaxW   MaxL  AvgW  AvgL  BFEW  BFEL  \\\n",
       "0  4635.0  NaN  NaN  NaN  NaN  NaN  NaN  1.24   5.25  1.17  4.98   NaN   NaN   \n",
       "1  4630.0  NaN  NaN  NaN  NaN  NaN  NaN  1.47   3.05  1.42  2.85   NaN   NaN   \n",
       "2   952.0  NaN  NaN  NaN  NaN  NaN  NaN  1.07  13.50  1.05  9.96   NaN   NaN   \n",
       "3  2240.0  NaN  NaN  NaN  NaN  NaN  NaN  1.31   4.20  1.27  3.76   NaN   NaN   \n",
       "4  2035.0  NaN  NaN  NaN  NaN  NaN  NaN  1.12   8.60  1.09  7.53   NaN   NaN   \n",
       "\n",
       "   MaxWin  MaxLoss  AvgWin  AvgLoss      PlayerA       PlayerB  RankA  RankB  \\\n",
       "0    1.20     5.13   1.185    4.940   Alcaraz C.      Fritz T.    2.0    5.0   \n",
       "1    1.47     2.93   1.435    2.865  Djokovic N.     Sinner J.    6.0    1.0   \n",
       "2    1.07    10.89   1.065    9.945   Alcaraz C.     Norrie C.    2.0   61.0   \n",
       "3    1.29     4.06   1.290    3.905     Fritz T.  Khachanov K.    5.0   20.0   \n",
       "4    1.11     8.33   1.105    7.665   Cobolli F.   Djokovic N.   24.0    6.0   \n",
       "\n",
       "   RankDiff  WinnerBinary  MaxOddsPlayerA  MaxOddsPlayerB  AvgOddsPlayerA  \\\n",
       "0      -3.0             1            1.24            5.25            1.17   \n",
       "1       5.0             0            3.05            1.47            2.85   \n",
       "2     -59.0             1            1.07           13.50            1.05   \n",
       "3     -15.0             1            1.31            4.20            1.27   \n",
       "4      18.0             0            8.60            1.12            7.53   \n",
       "\n",
       "   AvgOddsPlayerB  H2H_A_wins  H2H_B_wins  H2H_Diff  WinsA  LossesA  WinsB  \\\n",
       "0            4.98           1           0         1    239       59    289   \n",
       "1            1.42           4           4         0   1094      215    273   \n",
       "2            9.96           4           2         2    238       59    216   \n",
       "3            3.76           0           1        -1    288      189    287   \n",
       "4            1.09           0           1        -1     59       49   1093   \n",
       "\n",
       "   LossesB  WinRateA_cum  WinRateB_cum  Form10A  Form10B  RestDaysA  \\\n",
       "0      189      0.802013      0.604603      1.0      0.9          3   \n",
       "1       86      0.835752      0.760446      0.9      0.8          2   \n",
       "2      156      0.801347      0.580645      1.0      0.7          2   \n",
       "3      205      0.603774      0.583333      0.9      0.8          2   \n",
       "4      215      0.546296      0.835627      0.7      0.9          2   \n",
       "\n",
       "   RestDaysB    DiffWR  DiffForm  DiffRest  LogRankDiff  H2HDiff  ProbA_odds  \\\n",
       "0          3  0.197411       0.1         0    -0.916291        1    0.806452   \n",
       "1          2  0.075307       0.1         0     1.791759        0    0.327869   \n",
       "2          2  0.220702       0.3         0    -3.417727        2    0.934579   \n",
       "3          2  0.020440       0.1         0    -1.386294       -1    0.763359   \n",
       "4          2 -0.289331      -0.2         0     1.386294       -1    0.116279   \n",
       "\n",
       "   ProbB_odds  OddsProbDiff  WinRateA_x_Rank  WinRateB_x_Rank  EfficiencyDiff  \\\n",
       "0    0.190476      0.615975         0.401007         0.120921        0.280086   \n",
       "1    0.680272     -0.352403         0.139292         0.760446       -0.621154   \n",
       "2    0.074074      0.860505         0.400673         0.009519        0.391155   \n",
       "3    0.238095      0.525264         0.120755         0.029167        0.091588   \n",
       "4    0.892857     -0.776578         0.022762         0.139271       -0.116509   \n",
       "\n",
       "   EloA_Global  EloB_Global  EloA_Surface  EloB_Surface  EloDiff_Global  \\\n",
       "0  1926.287312  1723.803600   1738.429118   1679.760957      202.483711   \n",
       "1  1817.178196  1907.964530   1801.674504   1616.498027      -90.786334   \n",
       "2  1924.389264  1605.524476   1734.472534   1565.095386      318.864788   \n",
       "3  1712.986620  1623.755498   1669.539504   1585.603677       89.231123   \n",
       "4  1654.452037  1812.107149   1560.040292   1799.287697     -157.655113   \n",
       "\n",
       "   EloDiff_Surface SurfaceText  RoundOrder  \n",
       "0        58.668161       Grass         7.0  \n",
       "1       185.176478       Grass         7.0  \n",
       "2       169.377148       Grass         6.0  \n",
       "3        83.935828       Grass         6.0  \n",
       "4      -239.247405       Grass         6.0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actualizar el conjunto de entrenamiento: añadir first_round al train actual\n",
    "train_final = pd.concat([semi_finals, train_semi_finals], ignore_index=True)\n",
    "\n",
    "print(f\"Tamaño del train original: {len(train_final) - len(train_semi_finals)}\")\n",
    "print(f\"Tamaño de first_round añadido: {len(train_semi_finals)}\")\n",
    "print(f\"Tamaño del nuevo train: {len(train_final)}\")\n",
    "print(f\"\\nTrain actualizado correctamente. Listo para la siguiente fase.\")\n",
    "\n",
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1a391565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ACCURACY FINAL TEST CRONOLÓGIC: 0.0000\n",
      "Brier Score: 0.4231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       1.0\n",
      "           1     0.0000    0.0000    0.0000       0.0\n",
      "\n",
      "    accuracy                         0.0000       1.0\n",
      "   macro avg     0.0000    0.0000    0.0000       1.0\n",
      "weighted avg     0.0000    0.0000    0.0000       1.0\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iker/Code/TFG/Me-vs.-IBM/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/iker/Code/TFG/Me-vs.-IBM/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/iker/Code/TFG/Me-vs.-IBM/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/iker/Code/TFG/Me-vs.-IBM/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/iker/Code/TFG/Me-vs.-IBM/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/iker/Code/TFG/Me-vs.-IBM/.venv/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "X_train = train_final[features].fillna(0)\n",
    "X_test = finals[features].fillna(0)\n",
    "y_train = train_final['WinnerBinary']\n",
    "y_test = finals['WinnerBinary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "base_model = XGBClassifier(\n",
    "    n_estimators=500,                    # Nombre total d'arbres (boosting rounds) que es construiran. 500 és un valor força alt, bo per a un bon rendiment si es controla l'overfitting.\n",
    "    max_depth=6,                         # Profunditat màxima de cada arbre. 6 és un valor moderat: permet interaccions complexes sense fer els arbres excessivament profunds.\n",
    "    learning_rate=0.02,                  # Taxa d'aprenentatge (eta). 0.02 és bastant baixa → aprenentatge lent i estable, ideal quan tens molts estimators (500).\n",
    "    subsample=0.85,                      # Percentatge de mostres (files) que s'utilitzen per entrenar cada arbre. 0.85 = 85% → ajuda a reduir overfitting i afegeix variància (com bagging).\n",
    "    colsample_bytree=0.85,               # Percentatge de columnes (variables) que s'agafen aleatòriament per cada arbre. 85% → també redueix overfitting i millora la generalització.\n",
    "    min_child_weight=5,                  # Suma mínima del pes Hessiana en un node fill. Valors >1 fan el model més conservador: evita dividir nodes amb poca informació.\n",
    "    gamma=0.1,                           # Minimització mínima de la funció de pèrdua necessària per fer una partició addicional (regularització per poda). 0.1 afavoreix arbres més simples.\n",
    "    reg_alpha=0.1,                       # Terme de regularització L1 sobre els pesos de les fulles. Ajuda a fer sparseness i és útil quan hi ha moltes variables irrellevants.\n",
    "    reg_lambda=1.0,                      # Terme de regularització L2 (més suau que L1). 1.0 és el valor per defecte i sol funcionar bé en la majoria de casos.\n",
    "    random_state=42,                     # Llavor per a la reproductibilitat dels resultats (aleatorietat controlada).\n",
    "    n_jobs=-1,                           # Utilitza tots els nuclis disponibles del processador per entrenar en paral·lel → molt més ràpid.\n",
    "    eval_metric='logloss'                # Mètrica d'avaluació durant l'entrenament (per classificació binària/multiclasse). 'logloss' = logarithmic loss (cross-entropy).\n",
    ")\n",
    "\n",
    "model = CalibratedClassifierCV(base_model, method='isotonic', cv=5)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "pred = model.predict(X_test_sc)\n",
    "prob = model.predict_proba(X_test_sc)[:, 1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "brier = brier_score_loss(y_test, prob)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ACCURACY FINAL TEST CRONOLÓGIC: {acc:.4f}\")\n",
    "print(f\"Brier Score: {brier:.4f}\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
